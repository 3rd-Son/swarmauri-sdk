[
    {
        "document_name": "swarmauri/core/__init__.py",
        "content": "```swarmauri/core/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/models/__init__.py",
        "content": "```swarmauri/core/models/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/models/IPredict.py",
        "content": "```swarmauri/core/models/IPredict.py\nfrom abc import ABC, abstractmethod\n\nclass IPredict(ABC):\n    \"\"\"\n    Interface for making predictions with models.\n    \"\"\"\n\n    @abstractmethod\n    def predict(self, input_data) -> any:\n        \"\"\"\n        Generate predictions based on the input data provided to the model.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/models/IFit.py",
        "content": "```swarmauri/core/models/IFit.py\nfrom abc import ABC, abstractmethod\n\nclass IFit(ABC):\n    \"\"\"\n    Interface for training models.\n    \"\"\"\n\n    @abstractmethod\n    def fit(self, X_train, y_train, epochs: int, batch_size: int) -> None:\n        \"\"\"\n        Train the model on the provided dataset.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/models/IModel.py",
        "content": "```swarmauri/core/models/IModel.py\nfrom abc import ABC, abstractmethod\n\nclass IModel(ABC):\n    \"\"\"\n    Interface focusing on the basic properties and settings essential for defining models.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def model_name(self) -> str:\n        \"\"\"\n        Get the name of the model.\n        \"\"\"\n        pass\n\n    @model_name.setter\n    @abstractmethod\n    def model_name(self, value: str) -> None:\n        \"\"\"\n        Set the name of the model.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agent_apis/__init__.py",
        "content": "```swarmauri/core/agent_apis/__init__.py\nfrom .IAgentCommands import IAgentCommands\nfrom .IAgentRouterCRUD import IAgentRouterCRUD\n\n__all__ = ['IAgentCommands', 'IAgentRouterCRUD']\n```"
    },
    {
        "document_name": "swarmauri/core/agent_apis/IAgentCommands.py",
        "content": "```swarmauri/core/agent_apis/IAgentCommands.py\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Any, List\n\nclass IAgentCommands(ABC):\n    \"\"\"\n    Interface for the API object that enables a SwarmAgent to host various API routes.\n    \"\"\"\n\n\n    @abstractmethod\n    def invoke(self, request: Any) -> Any:\n        \"\"\"\n        Handles invocation requests synchronously.\n        \n        Parameters:\n            request (Any): The incoming request payload.\n\n        Returns:\n            Any: The response payload.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def ainvoke(self, request: Any) -> Any:\n        \"\"\"\n        Handles invocation requests asynchronously.\n        \n        Parameters:\n            request (Any): The incoming request payload.\n\n        Returns:\n            Any: The response payload.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def batch(self, requests: List[Any]) -> List[Any]:\n        \"\"\"\n        Handles batched invocation requests synchronously.\n        \n        Parameters:\n            requests (List[Any]): A list of incoming request payloads.\n\n        Returns:\n            List[Any]: A list of responses.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def abatch(self, requests: List[Any]) -> List[Any]:\n        \"\"\"\n        Handles batched invocation requests asynchronously.\n        \n        Parameters:\n            requests (List[Any]): A list of incoming request payloads.\n\n        Returns:\n            List[Any]: A list of responses.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def stream(self, request: Any) -> Any:\n        \"\"\"\n        Handles streaming requests.\n        \n        Parameters:\n            request (Any): The incoming request payload.\n        \n        Returns:\n            Any: A streaming response.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_schema_config(self) -> dict:\n        \"\"\"\n        Retrieves the schema configuration for the API.\n\n        Returns:\n            dict: The schema configuration.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agent_apis/IAgentRouterCRUD.py",
        "content": "```swarmauri/core/agent_apis/IAgentRouterCRUD.py\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Any, Dict\n\nclass IAgentRouterCRUD(ABC):\n    \"\"\"\n    Interface for managing API routes within a SwarmAgent.\n    \"\"\"\n    \n    @abstractmethod\n    def create_route(self, path: str, method: str, handler: Callable[[Any], Any]) -> None:\n        \"\"\"\n        Create a new route for the API.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method (e.g., 'GET', 'POST').\n        - handler (Callable[[Any], Any]): The function that handles requests to this route.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def read_route(self, path: str, method: str) -> Dict:\n        \"\"\"\n        Retrieve information about a specific route.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method.\n        \n        Returns:\n        - Dict: Information about the route, including path, method, and handler.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def update_route(self, path: str, method: str, new_handler: Callable[[Any], Any]) -> None:\n        \"\"\"\n        Update the handler function for an existing route.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method.\n        - new_handler (Callable[[Any], Any]): The new function that handles requests to this route.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def delete_route(self, path: str, method: str) -> None:\n        \"\"\"\n        Delete a specific route from the API.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/__init__.py",
        "content": "```swarmauri/core/conversations/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/IMaxSize.py",
        "content": "```swarmauri/core/conversations/IMaxSize.py\nfrom abc import ABC, abstractmethod\n\nclass IMaxSize(ABC):\n\n    @property\n    @abstractmethod\n    def max_size(self) -> int:\n        \"\"\"\n        \"\"\"\n        pass\n\n    @max_size.setter\n    @abstractmethod\n    def max_size(self, new_max_size: int) -> None:\n        \"\"\" \n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/IConversation.py",
        "content": "```swarmauri/core/conversations/IConversation.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom ..messages.IMessage import IMessage\n\nclass IConversation(ABC):\n    \"\"\"\n    Interface for managing conversations, defining abstract methods for\n    adding messages, retrieving the latest message, getting all messages, and clearing history.\n    \"\"\"\n\n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_message(self, message: IMessage):\n        \"\"\"\n        Adds a message to the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_last(self) -> Optional[IMessage]:\n        \"\"\"\n        Retrieves the latest message from the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def clear_history(self) -> None:\n        \"\"\"\n        Clears the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def as_dict(self) -> List[dict]:\n        \"\"\"\n        Returns all messages from the conversation history as a list of dictionaries.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/ISystemContext.py",
        "content": "```swarmauri/core/conversations/ISystemContext.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional\nfrom ..messages.IMessage import IMessage\n\nclass ISystemContext(ABC):\n\n    @property\n    @abstractmethod\n    def system_context(self) -> Optional[IMessage]:\n        \"\"\"\n        An abstract property to get the system context message.\n        Subclasses must provide an implementation for storing and retrieving system context.\n        \"\"\"\n        pass\n\n    @system_context.setter\n    @abstractmethod\n    def system_context(self, new_system_message: Optional[IMessage]) -> None:\n        \"\"\"\n        An abstract property setter to update the system context.\n        Subclasses must provide an implementation for how the system context is updated.\n        This might be a direct string, which is converted to an IMessage instance, or directly an IMessage instance.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/documents/__init__.py",
        "content": "```swarmauri/core/documents/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/documents/IDocument.py",
        "content": "```swarmauri/core/documents/IDocument.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\n\nclass IDocument(ABC):\n    @abstractmethod\n    def __init__(self, id: str, content: str, metadata: Dict):\n        pass\n\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"\n        Get the document's ID.\n        \"\"\"\n        pass\n\n    @id.setter\n    @abstractmethod\n    def id(self, value: str) -> None:\n        \"\"\"\n        Set the document's ID.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def content(self) -> str:\n        \"\"\"\n        Get the document's content.\n        \"\"\"\n        pass\n\n    @content.setter\n    @abstractmethod\n    def content(self, value: str) -> None:\n        \"\"\"\n        Set the document's content.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def metadata(self) -> Dict:\n        \"\"\"\n        Get the document's metadata.\n        \"\"\"\n        pass\n\n    @metadata.setter\n    @abstractmethod\n    def metadata(self, value: Dict) -> None:\n        \"\"\"\n        Set the document's metadata.\n        \"\"\"\n        pass\n\n    # Including the abstract methods __str__ and __repr__ definitions for completeness.\n    @abstractmethod\n    def __str__(self) -> str:\n        pass\n\n    @abstractmethod\n    def __repr__(self) -> str:\n        pass\n    \n    def __setitem__(self, key, value):\n        \"\"\"Allow setting items like a dict for metadata.\"\"\"\n        self.metadata[key] = value\n\n    def __getitem__(self, key):\n        \"\"\"Allow getting items like a dict for metadata.\"\"\"\n        return self.metadata.get(key)\n```"
    },
    {
        "document_name": "swarmauri/core/documents/IEmbed.py",
        "content": "```swarmauri/core/documents/IEmbed.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass IEmbed(ABC):\n    @property\n    @abstractmethod\n    def embedding(self) -> IVector:\n        \"\"\"\n        Get the document's embedding.\n        \"\"\"\n        pass\n\n    @embedding.setter\n    @abstractmethod\n    def embedding(self, value: IVector) -> None:\n        \"\"\"\n        Set the document's embedding.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/documents/IExperimentDocument.py",
        "content": "```swarmauri/core/documents/IExperimentDocument.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional\nfrom datetime import datetime\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IExperimentDocument(IDocument, ABC):\n    \"\"\"\n    Interface for an Experiment Document, extending the general IDocument interface\n    with additional properties and methods specific to experimental data.\n    \"\"\"\n    @property\n    @abstractmethod\n    def parameters(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the parameters used in the experiment.\n        \"\"\"\n        pass\n\n    @parameters.setter\n    @abstractmethod\n    def parameters(self, value: Dict[str, Any]) -> None:\n        \"\"\"\n        Set the parameters used in the experiment.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def results(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the results obtained from the experiment.\n        \"\"\"\n        pass\n\n    @results.setter\n    @abstractmethod\n    def results(self, value: Dict[str, Any]) -> None:\n        \"\"\"\n        Set the results obtained from the experiment.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def instruction(self) -> str:\n        \"\"\"\n        An instructional or descriptive text about what the experiment aims to achieve or how.\n        \"\"\"\n        pass\n\n    @instruction.setter\n    @abstractmethod\n    def instruction(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def feature_set(self) -> List[Any]:\n        \"\"\"\n        Description of the set of features or data used in the experiment.\n        \"\"\"\n        pass\n\n    @feature_set.setter\n    @abstractmethod\n    def feature_set(self, value: List[Any]) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def version(self) -> str:\n        \"\"\"\n        The version of the experiment, useful for tracking iterations and changes over time.\n        \"\"\"\n        pass\n\n    @version.setter\n    @abstractmethod\n    def version(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def artifacts(self) -> List[str]:\n        \"\"\"\n        A list of paths or identifiers for any artifacts generated by the experiment,\n        such as models, charts, or data dumps.\n        \"\"\"\n        pass\n\n    @artifacts.setter\n    @abstractmethod\n    def artifacts(self, value: List[str]) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def datetime_created(self) -> datetime:\n        \"\"\"\n        Timestamp marking when the experiment was initiated or created.\n        \"\"\"\n        pass\n\n    @datetime_created.setter\n    @abstractmethod\n    def datetime_created(self, value: datetime) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def datetime_completed(self) -> Optional[datetime]:\n        \"\"\"\n        Timestamp of when the experiment was completed. None if the experiment is still running.\n        \"\"\"\n        pass\n\n    @datetime_completed.setter\n    @abstractmethod\n    def datetime_completed(self, value: Optional[datetime]) -> None:\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/messages/IMessage.py",
        "content": "```swarmauri/core/messages/IMessage.py\nfrom abc import ABC, abstractmethod\n\nclass IMessage(ABC):\n    \"\"\"\n    An abstract interface representing a general message structure.\n\n    This interface defines the basic attributes that all\n    messages should have, including type, name, and content, \n    and requires subclasses to implement representation and formatting methods.\n    \"\"\"\n    @property\n    @abstractmethod\n    def role(self) -> str:\n        pass\n    \n    @property\n    @abstractmethod\n    def content(self) -> str:\n        pass\n\n    @abstractmethod\n    def as_dict(self) -> dict:\n        \"\"\"\n        An abstract method that subclasses must implement to return a dictionary representation of the object.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/messages/__init__.py",
        "content": "```swarmauri/core/messages/__init__.py\nfrom .IMessage import IMessage\n```"
    },
    {
        "document_name": "swarmauri/core/parsers/__init__.py",
        "content": "```swarmauri/core/parsers/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/parsers/IParser.py",
        "content": "```swarmauri/core/parsers/IParser.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union, Any\nfrom ..documents.IDocument import IDocument\n\nclass IParser(ABC):\n    \"\"\"\n    Abstract base class for parsers. It defines a public method to parse input data (str or Message) into documents,\n    and relies on subclasses to implement the specific parsing logic through protected and private methods.\n    \"\"\"\n\n    @abstractmethod\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Public method to parse input data (either a str or a Message) into a list of Document instances.\n        \n        This method leverages the abstract _parse_data method which must be\n        implemented by subclasses to define specific parsing logic.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/prompts/__init__.py",
        "content": "```swarmauri/core/prompts/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/prompts/IPrompt.py",
        "content": "```swarmauri/core/prompts/IPrompt.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Any\n\nclass IPrompt(ABC):\n    \"\"\"\n    A base abstract class representing a prompt system.\n\n    Methods:\n        __call__: Abstract method that subclasses must implement to enable the instance to be called directly.\n    \"\"\"\n\n    @abstractmethod\n    def __call__(self, prompt: Optional[Any]) -> str:\n        \"\"\"\n        Abstract method that subclasses must implement to define the behavior of the prompt when called.\n\n        \"\"\"\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/prompts/ITemplate.py",
        "content": "```swarmauri/core/prompts/ITemplate.py\nfrom typing import Dict, List\nfrom abc import ABC, abstractmethod\n\n\nclass ITemplate(ABC):\n    \"\"\"\n    Interface for template-based prompt generation within the SwarmAURI framework.\n    Defines standard operations and attributes for managing and utilizing templates.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def template(self) -> str:\n        \"\"\"\n        Abstract property to get the current template string.\n        \"\"\"\n        pass\n\n    @template.setter\n    @abstractmethod\n    def template(self, value: str) -> None:\n        \"\"\"\n        Abstract property setter to set or update the current template string.\n\n        Args:\n            value (str): The new template string to be used for generating prompts.\n        \"\"\"\n        pass\n\n\n    @property\n    @abstractmethod\n    def variables(self) -> List[Dict[str, str]]:\n        \"\"\"\n        Abstract property to get the current set of variables for the template.\n        \"\"\"\n        pass\n\n    @variables.setter\n    @abstractmethod\n    def variables(self, value: List[Dict[str, str]]) -> None:\n        \"\"\"\n        Abstract property setter to set or update the variables for the template.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_template(self, template: str) -> None:\n        \"\"\"\n        Sets or updates the current template string.\n\n        Args:\n            template (str): The new template string to be used for generating prompts.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_variables(self, variables: List[Dict[str, str]]) -> None:\n        \"\"\"\n        Sets or updates the variables to be substituted into the template.\n\n        Args:\n            variables (List[Dict[str, str]]): A dictionary of variables where each key-value \n                                        pair corresponds to a placeholder name and its \n                                        replacement value in the template.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_prompt(self, **kwargs) -> str:\n        \"\"\"\n        Generates a prompt string based on the current template and provided keyword arguments.\n\n        Args:\n            **kwargs: Keyword arguments containing variables for template substitution. \n\n        Returns:\n            str: The generated prompt string with template variables replaced by their\n                 corresponding values provided in `kwargs`.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/__init__.py",
        "content": "```swarmauri/core/agents/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentToolkit.py",
        "content": "```swarmauri/core/agents/IAgentToolkit.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\n\n\nclass IAgentToolkit(ABC):\n\n\n    @property\n    @abstractmethod\n    def toolkit(self) -> IToolkit:\n        pass\n    \n    @toolkit.setter\n    @abstractmethod\n    def toolkit(self) -> IToolkit:\n        pass\n    \n\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentConversation.py",
        "content": "```swarmauri/core/agents/IAgentConversation.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nclass IAgentConversation(ABC):\n    \n    @property\n    @abstractmethod\n    def conversation(self) -> IConversation:\n        \"\"\"\n        The conversation property encapsulates the agent's ongoing dialogue or interaction context.\n        \"\"\"\n        pass\n\n    @conversation.setter\n    @abstractmethod\n    def conversation(self) -> IConversation:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentRetriever.py",
        "content": "```swarmauri/core/agents/IAgentRetriever.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.document_stores.IDocumentRetrieve import IDocumentRetrieve\n\nclass IAgentRetriever(ABC):\n    \n    @property\n    @abstractmethod\n    def retriever(self) -> IDocumentRetrieve:\n        pass\n\n    @retriever.setter\n    @abstractmethod\n    def retriever(self) -> IDocumentRetrieve:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentParser.py",
        "content": "```swarmauri/core/agents/IAgentParser.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.parsers.IParser import IParser \n\nclass IAgentParser(ABC):\n    \n    @property\n    @abstractmethod\n    def parser(self) -> IParser:\n        pass\n\n    @parser.setter\n    @abstractmethod\n    def parser(self) -> IParser:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentName.py",
        "content": "```swarmauri/core/agents/IAgentName.py\nfrom abc import ABC, abstractmethod\n\nclass IAgentName(ABC):\n    \n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"\n        The conversation property encapsulates the agent's ongoing dialogue or interaction context.\n        \"\"\"\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self) -> str:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgent.py",
        "content": "```swarmauri/core/agents/IAgent.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Optional\nfrom swarmauri.core.models.IModel import IModel\n\nclass IAgent(ABC):\n\n    @abstractmethod\n    def exec(self, input_data: Optional[Any]) -> Any:\n        \"\"\"\n        Executive method that triggers the agent's action based on the input data.\n        \"\"\"\n        pass\n    \n    @property\n    @abstractmethod\n    def model(self) -> IModel:\n        \"\"\"\n        The model property describes the computational model used by the agent.\n        \"\"\"\n        pass\n    \n    @model.setter\n    @abstractmethod\n    def model(self) -> IModel:\n\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentVectorStore.py",
        "content": "```swarmauri/core/agents/IAgentVectorStore.py\nfrom abc import ABC, abstractmethod\n\nclass IAgentVectorStore(ABC):\n    \n    @property\n    @abstractmethod\n    def vector_store(self):\n        pass\n\n    @vector_store.setter\n    @abstractmethod\n    def vector_store(self):\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/__init__.py",
        "content": "```swarmauri/core/swarms/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarm.py",
        "content": "```swarmauri/core/swarms/ISwarm.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, List, Dict\nfrom datetime import datetime\nfrom swarmauri.core.agents.IAgent import IAgent\nfrom swarmauri.core.chains.ICallableChain import ICallableChain\n\nclass ISwarm(ABC):\n    \"\"\"\n    Interface for a Swarm, representing a collective of agents capable of performing tasks, executing callable chains, and adaptable configurations.\n    \"\"\"\n\n    # Abstract properties and setters\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"Unique identifier for the factory instance.\"\"\"\n        pass\n\n    @id.setter\n    @abstractmethod\n    def id(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def type(self) -> str:\n        pass\n\n    @type.setter\n    @abstractmethod\n    def type(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def date_created(self) -> datetime:\n        pass\n\n    @property\n    @abstractmethod\n    def last_modified(self) -> datetime:\n        pass\n\n    @last_modified.setter\n    @abstractmethod\n    def last_modified(self, value: datetime) -> None:\n        pass\n\n    def __hash__(self):\n        \"\"\"\n        The __hash__ method allows objects of this class to be used in sets and as dictionary keys.\n        __hash__ should return an integer and be defined based on immutable properties.\n        This is generally implemented directly in concrete classes rather than in the interface,\n        but it's declared here to indicate that implementing classes must provide it.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmComponent.py",
        "content": "```swarmauri/core/swarms/ISwarmComponent.py\nfrom abc import ABC, abstractmethod\n\nclass ISwarmComponent(ABC):\n    \"\"\"\n    Interface for defining a general component within a swarm system.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, key: str, name: str):\n        \"\"\"\n        Initializes a swarm component with a unique key and name.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmConfigurationExporter.py",
        "content": "```swarmauri/core/swarms/ISwarmConfigurationExporter.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nclass ISwarmConfigurationExporter(ABC):\n\n    @abstractmethod\n    def to_dict(self) -> Dict:\n        \"\"\"\n        Serializes the swarm configuration to a dictionary.\n\n        Returns:\n            Dict: The serialized configuration as a dictionary.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_json(self) -> str:\n        \"\"\"\n        Serializes the swarm configuration to a JSON string.\n\n        Returns:\n            str: The serialized configuration as a JSON string.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_pickle(self) -> bytes:\n        \"\"\"\n        Serializes the swarm configuration to a Pickle byte stream.\n\n        Returns:\n            bytes: The serialized configuration as a Pickle byte stream.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmFactory.py",
        "content": "```swarmauri/core/swarms/ISwarmFactory.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Callable, Dict, List, NamedTuple, Optional, Type, Union\nfrom swarmauri.core.swarms.ISwarm import ISwarm\nfrom swarmauri.core.chains.ICallableChain import ICallableChain \nfrom swarmauri.core.agents.IAgent import IAgent \n\nclass Step(NamedTuple):\n    description: str\n    callable: Callable  # Reference to the function to execute\n    args: Optional[List[Any]] = None\n    kwargs: Optional[Dict[str, Any]] = None\n\nclass CallableChainItem(NamedTuple):\n    key: str  # Unique identifier for the item within the chain\n    execution_context: Dict[str, Any]  # Execution context and metadata\n    steps: List[Step]\n\nclass AgentDefinition(NamedTuple):\n    type: str\n    configuration: Dict[str, Any]\n    capabilities: List[str]\n    dependencies: List[str]\n    execution_context: Dict[str, Any]\n\nclass FunctionParameter(NamedTuple):\n    name: str\n    type: Type\n    default: Optional[Any] = None\n    required: bool = True\n\nclass FunctionDefinition(NamedTuple):\n    identifier: str\n    parameters: List[FunctionParameter]\n    return_type: Type\n    execution_context: Dict[str, Any]\n    callable_source: Callable\n    \nclass ISwarmFactory(ABC):\n\n    @abstractmethod\n    def create_swarm(self, *args, **kwargs) -> ISwarm:\n        \"\"\"\n        Creates and returns a new swarm instance configured with the provided arguments.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_agent(self, agent_definition: AgentDefinition) -> IAgent:\n        \"\"\"\n        Creates a new agent based on the provided enhanced agent definition.\n        \n        Args:\n            agent_definition: An instance of AgentDefinition detailing the agent's setup.\n        \n        Returns:\n            An instance or identifier of the newly created agent.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def create_callable_chain(self, chain_definition: List[CallableChainItem]) -> ICallableChain:\n        \"\"\"\n        Creates a new callable chain based on the provided definition.\n\n        Args:\n            chain_definition: Details required to build the chain, such as sequence of functions and arguments.\n\n        Returns:\n            ICallableChain: The constructed callable chain instance.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def register_function(self, function_definition: FunctionDefinition) -> None:\n        \"\"\"\n        Registers a function within the factory ecosystem, making it available for callable chains and agents.\n\n        Args:\n            function_definition: An instance of FunctionDefinition detailing the function's specification.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def export_callable_chains(self, format_type: str = 'json') -> Union[dict, str, bytes]:\n        \"\"\"\n        Exports configurations of all callable chains in the specified format.\n        Supported formats: 'json', 'pickle'.\n\n        Args:\n            format_type (str): The format for exporting the configurations.\n\n        Returns:\n            Union[dict, str, bytes]: The callable chain configurations in the specified format.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_callable_chains(self, chains_data, format_type: str = 'json'):\n        \"\"\"\n        Loads callable chain configurations from given data.\n\n        Args:\n            chains_data (Union[dict, str, bytes]): Data containing callable chain configurations.\n            format_type (str): The format of the provided chains data.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def export_configuration(self, format_type: str = 'json') -> Union[dict, str, bytes]:\n        \"\"\"\n        Exports the swarm's and agents' configurations in the specified format.\n        Supported formats: 'json', 'pickle'. Default is 'json'.\n\n        Args:\n            format_type (str): The format for exporting the configurations.\n\n        Returns:\n            Union[dict, str, bytes]: The configurations in the specified format.\n        \"\"\"\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmAgentRegistration.py",
        "content": "```swarmauri/core/swarms/ISwarmAgentRegistration.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Optional\nfrom swarmauri.core.agents.IAgent import IAgent\n\nclass ISwarmAgentRegistration(ABC):\n    \"\"\"\n    Interface for registering agents with the swarm, designed to support CRUD operations on IAgent instances.\n    \"\"\"\n\n    @id.setter\n    @abstractmethod\n    def registry(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def registry(self) -> List[IAgent]:\n        pass\n\n    @abstractmethod\n    def register_agent(self, agent: IAgent) -> bool:\n        \"\"\"\n        Register a new agent with the swarm.\n\n        Parameters:\n            agent (IAgent): An instance of IAgent representing the agent to register.\n\n        Returns:\n            bool: True if the registration succeeded; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_agent(self, agent_id: str, updated_agent: IAgent) -> bool:\n        \"\"\"\n        Update the details of an existing agent. This could include changing the agent's configuration,\n        task assignment, or any other mutable attribute.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent.\n            updated_agent (IAgent): An updated IAgent instance to replace the existing one.\n\n        Returns:\n            bool: True if the update was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_agent(self, agent_id: str) -> bool:\n        \"\"\"\n        Remove an agent from the swarm based on its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent to be removed.\n\n        Returns:\n            bool: True if the removal was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_agent(self, agent_id: str) -> Optional[IAgent]:\n        \"\"\"\n        Retrieve an agent's instance from its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent of interest.\n\n        Returns:\n            Optional[IAgent]: The IAgent instance if found; None otherwise.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmChainCRUD.py",
        "content": "```swarmauri/core/swarms/ISwarmChainCRUD.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any\n\nclass ISwarmChainCRUD(ABC):\n    \"\"\"\n    Interface to provide CRUD operations for ICallableChain within swarms.\n    \"\"\"\n\n    @abstractmethod\n    def create_chain(self, chain_id: str, chain_definition: Dict[str, Any]) -> None:\n        \"\"\"\n        Creates a callable chain with the provided definition.\n\n        Parameters:\n        - chain_id (str): A unique identifier for the callable chain.\n        - chain_definition (Dict[str, Any]): The definition of the callable chain including steps and their configurations.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def read_chain(self, chain_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Retrieves the definition of a callable chain by its identifier.\n\n        Parameters:\n        - chain_id (str): The unique identifier of the callable chain to be retrieved.\n\n        Returns:\n        - Dict[str, Any]: The definition of the callable chain.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_chain(self, chain_id: str, new_definition: Dict[str, Any]) -> None:\n        \"\"\"\n        Updates an existing callable chain with a new definition.\n\n        Parameters:\n        - chain_id (str): The unique identifier of the callable chain to be updated.\n        - new_definition (Dict[str, Any]): The new definition of the callable chain including updated steps and configurations.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_chain(self, chain_id: str) -> None:\n        \"\"\"\n        Removes a callable chain from the swarm.\n\n        Parameters:\n        - chain_id (str): The unique identifier of the callable chain to be removed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_chains(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Lists all callable chains currently managed by the swarm.\n\n        Returns:\n        - List[Dict[str, Any]]: A list of callable chain definitions.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/toolkits/__init__.py",
        "content": "```swarmauri/core/toolkits/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/toolkits/IToolkit.py",
        "content": "```swarmauri/core/toolkits/IToolkit.py\nfrom typing import Dict\nfrom abc import ABC, abstractmethod\nfrom ..tools.ITool import ITool  # Ensure Tool is correctly imported from your tools package\n\nclass IToolkit(ABC):\n    \"\"\"\n    A class representing a toolkit used by Swarm Agents.\n    Tools are maintained in a dictionary keyed by the tool's name.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def tools(self) -> Dict[str, ITool]:\n        \"\"\"\n        An abstract property that should be implemented by subclasses to return the tools dictionary\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_tools(self, tools: Dict[str, ITool]):\n        \"\"\"\n        An abstract method that should be implemented by subclasses to add multiple tools to the toolkit.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_tool(self, tool: ITool):\n        \"\"\"\n        An abstract method that should be implemented by subclasses to add a single tool to the toolkit.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_tool(self, tool_name: str):\n        \"\"\"\n        An abstract method that should be implemented by subclasses to remove a tool from the toolkit by name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_tool_by_name(self, tool_name: str) -> ITool:\n        \"\"\"\n        An abstract method that should be implemented by subclasses to retrieve a tool from the toolkit by name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def __len__(self) -> int:\n        \"\"\"\n        An abstract method that should be implemented by subclasses to return the number of tools in the toolkit.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tools/__init__.py",
        "content": "```swarmauri/core/tools/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/tools/ITool.py",
        "content": "```swarmauri/core/tools/ITool.py\nfrom abc import ABC, abstractmethod\n\nclass ITool(ABC):\n    \n    @property\n    @abstractmethod\n    def name(self):\n        pass\n    \n    @property\n    @abstractmethod\n    def description(self):\n        pass\n    \n    @property\n    @abstractmethod\n    def parameters(self):\n        pass\n    \n    @abstractmethod\n    def as_dict(self):\n        pass\n\n    @abstractmethod\n    def to_json(obj):\n        pass\n\n    @abstractmethod\n    def __call__(self, *args, **kwargs):\n        pass\n\n\n\n\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/tools/IParameter.py",
        "content": "```swarmauri/core/tools/IParameter.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, List, Any\n\nclass IParameter(ABC):\n    \"\"\"\n    An abstract class to represent a parameter for a tool.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"\n        Abstract property for getting the name of the parameter.\n        \"\"\"\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self, value: str):\n        \"\"\"\n        Abstract setter for setting the name of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def type(self) -> str:\n        \"\"\"\n        Abstract property for getting the type of the parameter.\n        \"\"\"\n        pass\n\n    @type.setter\n    @abstractmethod\n    def type(self, value: str):\n        \"\"\"\n        Abstract setter for setting the type of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def description(self) -> str:\n        \"\"\"\n        Abstract property for getting the description of the parameter.\n        \"\"\"\n        pass\n\n    @description.setter\n    @abstractmethod\n    def description(self, value: str):\n        \"\"\"\n        Abstract setter for setting the description of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def required(self) -> bool:\n        \"\"\"\n        Abstract property for getting the required status of the parameter.\n        \"\"\"\n        pass\n\n    @required.setter\n    @abstractmethod\n    def required(self, value: bool):\n        \"\"\"\n        Abstract setter for setting the required status of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def enum(self) -> Optional[List[Any]]:\n        \"\"\"\n        Abstract property for getting the enum list of the parameter.\n        \"\"\"\n        pass\n\n    @enum.setter\n    @abstractmethod\n    def enum(self, value: Optional[List[Any]]):\n        \"\"\"\n        Abstract setter for setting the enum list of the parameter.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/utils/__init__.py",
        "content": "```swarmauri/core/utils/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/utils/ITransactional.py",
        "content": "```swarmauri/core/utils/ITransactional.py\nfrom abc import ABC, abstractmethod\n\nclass ITransactional(ABC):\n\n    @abstractmethod\n    def begin_transaction(self):\n        \"\"\"\n        Initiates a transaction for a series of vector store operations.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def commit_transaction(self):\n        \"\"\"\n        Commits the current transaction, making all operations within the transaction permanent.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def abort_transaction(self):\n        \"\"\"\n        Aborts the current transaction, reverting all operations performed within the transaction.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/ISimiliarityQuery.py",
        "content": "```swarmauri/core/vector_stores/ISimiliarityQuery.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict\n\nclass ISimilarityQuery(ABC):\n    \n    @abstractmethod\n    def search_by_similarity_threshold(self, query_vector: List[float], similarity_threshold: float, space_name: str = None) -> List[Dict]:\n        \"\"\"\n        Search vectors exceeding a similarity threshold to a query vector within an optional vector space.\n\n        Args:\n            query_vector (List[float]): The high-dimensional query vector.\n            similarity_threshold (float): The similarity threshold for filtering results.\n            space_name (str, optional): The name of the vector space to search within.\n\n        Returns:\n            List[Dict]: A list of dictionaries with vector IDs, similarity scores, and optional metadata that meet the similarity threshold.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IGradient.py",
        "content": "```swarmauri/core/vector_stores/IGradient.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Callable\n\nclass IGradient(ABC):\n    \"\"\"\n    Interface for calculating the gradient of a scalar field.\n    \"\"\"\n\n    @abstractmethod\n    def calculate_gradient(self, scalar_field: Callable[[List[float]], float], point: List[float]) -> List[float]:\n        \"\"\"\n        Calculate the gradient of a scalar field at a specific point.\n\n        Parameters:\n        - scalar_field (Callable[[List[float]], float]): The scalar field represented as a function\n                                                         that takes a point and returns a scalar value.\n        - point (List[float]): The point at which the gradient is to be calculated.\n\n        Returns:\n        - List[float]: The gradient vector at the specified point.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IAngleBetweenVectors.py",
        "content": "```swarmauri/core/vector_stores/IAngleBetweenVectors.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IAngleBetweenVectors(ABC):\n    \"\"\"\n    Interface for calculating the angle between two vectors.\n    \"\"\"\n\n    @abstractmethod\n    def angle_between(self, vector_a: List[float], vector_b: List[float]) -> float:\n        \"\"\"\n        Method to calculate and return the angle in radians between two vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector as a list of floats.\n        - vector_b (List[float]): The second vector as a list of floats.\n\n        Returns:\n        - float: The angle between vector_a and vector_b in radians.\n\n        Note: Implementations should handle the vectors' dimensionality and throw appropriate exceptions for incompatible vectors.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IDecompose.py",
        "content": "```swarmauri/core/vector_stores/IDecompose.py\nfrom abc import ABC, abstractmethod\nfrom typing import Tuple, List\nfrom swarmauri.core.vectors.IVector import IVector  # Assuming there's a base IVector interface for vector representations\n\nclass IDecompose(ABC):\n    \"\"\"\n    Interface for decomposing a vector into components along specified basis vectors.\n    This operation is essential in expressing a vector in different coordinate systems or reference frames.\n    \"\"\"\n\n    @abstractmethod\n    def decompose(self, vector: IVector, basis_vectors: List[IVector]) -> List[IVector]:\n        \"\"\"\n        Decompose the given vector into components along the specified basis vectors.\n\n        Parameters:\n        - vector (IVector): The vector to be decomposed.\n        - basis_vectors (List[IVector]): A list of basis vectors along which to decompose the given vector.\n\n        Returns:\n        - List[IVector]: A list of vectors, each representing the component of the decomposed vector along \n                         the corresponding basis vector in the `basis_vectors` list.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IDivergence.py",
        "content": "```swarmauri/core/vector_stores/IDivergence.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IDivergence(ABC):\n    \"\"\"\n    Interface for calculating the divergence of a vector field.\n    \"\"\"\n\n    @abstractmethod\n    def calculate_divergence(self, vector_field: List[List[float]], point: List[float]) -> float:\n        \"\"\"\n        Calculate the divergence of a vector field at a specific point.\n\n        Parameters:\n        - vector_field (List[List[float]]): A representation of the vector field as a list of vectors.\n        - point (List[float]): The point at which the divergence is to be calculated.\n\n        Returns:\n        - float: The divergence value at the specified point.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IOrthogonalProject.py",
        "content": "```swarmauri/core/vector_stores/IOrthogonalProject.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IOrthogonalProject(ABC):\n    \"\"\"\n    Interface for calculating the orthogonal projection of one vector onto another.\n    \"\"\"\n\n    @abstractmethod\n    def orthogonal_project(self, vector_a: List[float], vector_b: List[float]) -> List[float]:\n        \"\"\"\n        Calculates the orthogonal projection of vector_a onto vector_b.\n        \n        Args:\n            vector_a (List[float]): The vector to be projected.\n            vector_b (List[float]): The vector onto which vector_a is orthogonally projected.\n        \n        Returns:\n            List[float]: The orthogonal projection of vector_a onto vector_b.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IProject.py",
        "content": "```swarmauri/core/vector_stores/IProject.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IProject(ABC):\n    \"\"\"\n    Interface for projecting one vector onto another.\n    \"\"\"\n\n    @abstractmethod\n    def project(self, vector_a: List[float], vector_b: List[float]) -> List[float]:\n        \"\"\"\n        Projects vector_a onto vector_b.\n        \n        Args:\n            vector_a (List[float]): The vector to be projected.\n            vector_b (List[float]): The vector onto which vector_a is projected.\n        \n        Returns:\n            List[float]: The projection of vector_a onto vector_b.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IReflect.py",
        "content": "```swarmauri/core/vector_stores/IReflect.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IReflect(ABC):\n    \"\"\"\n    Interface for reflecting a vector across a specified plane or axis.\n    \"\"\"\n\n    @abstractmethod\n    def reflect_vector(self, vector: List[float], normal: List[float]) -> List[float]:\n        \"\"\"\n        Reflects a vector across a plane or axis defined by a normal vector.\n\n        Parameters:\n        - vector (List[float]): The vector to be reflected.\n        - normal (List[float]): The normal vector of the plane across which the vector will be reflected.\n\n        Returns:\n        - List[float]: The reflected vector.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/ISimilarity.py",
        "content": "```swarmauri/core/vector_stores/ISimilarity.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass ISimilarity(ABC):\n    \"\"\"\n    Interface to define operations for computing similarity and distance between vectors.\n    This interface is crucial for systems that need to perform similarity searches, clustering,\n    or any operations where vector similarity plays a key role.\n    \"\"\"\n\n    @abstractmethod\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the similarity between two vectors. The definition of similarity (e.g., cosine similarity)\n        should be implemented in concrete classes.\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector to compare with the first vector.\n\n        Returns:\n            float: A similarity score between vector_a and vector_b.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorSpan.py",
        "content": "```swarmauri/core/vector_stores/IVectorSpan.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass IVectorSpan(ABC):\n    \"\"\"\n    Interface for determining if a vector is within the span of a set of vectors.\n    \"\"\"\n\n    @abstractmethod\n    def in_span(self, vector: Any, basis_vectors: List[Any]) -> bool:\n        \"\"\"\n        Checks if the given vector is in the span of the provided basis vectors.\n\n        Parameters:\n        - vector (Any): The vector to check.\n        - basis_vectors (List[Any]): A list of vectors that might span the vector.\n\n        Returns:\n        - bool: True if the vector is in the span of the basis_vectors, False otherwise.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorArithmetic.py",
        "content": "```swarmauri/core/vector_stores/IVectorArithmetic.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IVectorArithmetic(ABC):\n    @abstractmethod\n    def add(self, vector1: List[float], vector2: List[float]) -> List[float]:\n        \"\"\"\n        Vector addition of 'vector1' and 'vector2'.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def subtract(self, vector1: List[float], vector2: List[float]) -> List[float]:\n        \"\"\"\n        Vector subtraction of 'vector1' - 'vector2'.\n        \"\"\"\n        pass\n   \n    @abstractmethod\n    def multiply(self, vector: List[float], scalar: float) -> List[float]:\n        \"\"\"\n        Scalar multiplication of 'vector' by 'scalar'.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def divide(self, vector: List[float], scalar: float) -> List[float]:\n        \"\"\"\n        Scalar division of 'vector' by 'scalar'.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorLinearCombination.py",
        "content": "```swarmauri/core/vector_stores/IVectorLinearCombination.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass ILinearCombination(ABC):\n    \"\"\"\n    Interface for creating a vector as a linear combination of a set of vectors.\n    \"\"\"\n\n    @abstractmethod\n    def linear_combination(self, coefficients: List[float], vectors: List[Any]) -> Any:\n        \"\"\"\n        Computes the linear combination of the given vectors with the specified coefficients.\n\n        Parameters:\n        - coefficients (List[float]): A list of coefficients for the linear combination.\n        - vectors (List[Any]): A list of vectors to be combined.\n\n        Returns:\n        - Any: The resulting vector from the linear combination.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorNorm.py",
        "content": "```swarmauri/core/vector_stores/IVectorNorm.py\n# core/vectors/IVectorNorm.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union\n\nclass IVectorNorm(ABC):\n    \"\"\"\n    Interface for calculating vector norms.\n    Supports L1 norm, L2 norm, and Max norm calculations.\n    \"\"\"\n\n    @abstractmethod\n    def l1_norm(self, vector: List[Union[int, float]]) -> float:\n        \"\"\"\n        Calculate the L1 norm (Manhattan norm) of a vector.\n\n        Parameters:\n        - vector (List[Union[int, float]]): The vector for which to calculate the L1 norm.\n\n        Returns:\n        - float: The L1 norm of the vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def l2_norm(self, vector: List[Union[int, float]]) -> float:\n        \"\"\"\n        Calculate the L2 norm (Euclidean norm) of a vector.\n\n        Parameters:\n        - vector (List[Union[int, float]]): The vector for which to calculate the L2 norm.\n\n        Returns:\n        - float: The L2 norm of the vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def max_norm(self, vector: List[Union[int, float]]) -> float:\n        \"\"\"\n        Calculate the Max norm (infinity norm) of a vector.\n\n        Parameters:\n        - vector (List[Union[int, float]]): The vector for which to calculate the Max norm.\n\n        Returns:\n        - float: The Max norm of the vector.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorRotate.py",
        "content": "```swarmauri/core/vector_stores/IVectorRotate.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IRotate(ABC):\n    \"\"\"\n    Interface for rotating a vector.\n    \"\"\"\n    \n    @abstractmethod\n    def rotate(self, vector: List[float], angle: float, axis: List[float] = None) -> List[float]:\n        \"\"\"\n        Rotate the given vector by a specified angle around an axis (for 3D) or in a plane (for 2D).\n\n        For 2D vectors, the axis parameter can be omitted.\n\n        Args:\n            vector (List[float]): The vector to rotate.\n            angle (float): The angle of rotation in degrees.\n            axis (List[float], optional): The axis of rotation (applicable in 3D).\n\n        Returns:\n            List[float]: The rotated vector.\n        \"\"\"\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorBasisCheck.py",
        "content": "```swarmauri/core/vector_stores/IVectorBasisCheck.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass IVectorBasisCheck(ABC):\n    \"\"\"\n    Interface for checking if a given set of vectors forms a basis of the vector space.\n    \"\"\"\n\n    @abstractmethod\n    def is_basis(self, vectors: List[Any]) -> bool:\n        \"\"\"\n        Determines whether the given set of vectors forms a basis for their vector space.\n\n        Parameters:\n        - vectors (List[Any]): A list of vectors to be checked.\n\n        Returns:\n        - bool: True if the vectors form a basis, False otherwise.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/__init__.py",
        "content": "```swarmauri/core/vector_stores/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/ISaveLoadStore.py",
        "content": "```swarmauri/core/vector_stores/ISaveLoadStore.py\nfrom abc import ABC, abstractmethod\n\nclass ISaveLoadStore(ABC):\n    \"\"\"\n    Interface to abstract the ability to save and load the state of a vector store.\n    This includes saving/loading the vectorizer's model as well as the documents or vectors.\n    \"\"\"\n\n    @abstractmethod\n    def save_store(self, directory_path: str) -> None:\n        \"\"\"\n        Saves the state of the vector store to the specified directory. This includes\n        both the vectorizer's model and the stored documents or vectors.\n\n        Parameters:\n        - directory_path (str): The directory path where the store's state will be saved.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_store(self, directory_path: str) -> None:\n        \"\"\"\n        Loads the state of the vector store from the specified directory. This includes\n        both the vectorizer's model and the stored documents or vectors.\n\n        Parameters:\n        - directory_path (str): The directory path from where the store's state will be loaded.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def save_parts(self, directory_path: str, chunk_size: int=10485760) -> None:\n        \"\"\"\n        Save the model in parts to handle large files by splitting them.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_parts(self, directory_path: str, file_pattern: str) -> None:\n        \"\"\"\n        Load and combine model parts from a directory.\n\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorStore.py",
        "content": "```swarmauri/core/vector_stores/IVectorStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Union\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IVectorStore(ABC):\n    \"\"\"\n    Interface for a Document Store responsible for storing, indexing, and retrieving documents.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Stores a single document in the document store.\n\n        Parameters:\n        - document (IDocument): The document to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Stores multiple documents in the document store.\n\n        Parameters:\n        - documents (List[IDocument]): The list of documents to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Union[IDocument, None]:\n        \"\"\"\n        Retrieves a document by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document.\n\n        Returns:\n        - Union[IDocument, None]: The requested document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieves all documents stored in the document store.\n\n        Returns:\n        - List[IDocument]: A list of all documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Deletes a document from the document store by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Updates a document in the document store.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document to update.\n        - updated_document (IDocument): The updated document object.\n\n        Note: It's assumed that the updated_document will retain the same doc_id but may have different content or metadata.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def document_count(self) -> int:\n        pass \n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorRetrieve.py",
        "content": "```swarmauri/core/vector_stores/IVectorRetrieve.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IVectorRetrieve(ABC):\n    \"\"\"\n    Abstract base class for document retrieval operations.\n    \n    This class defines the interface for retrieving documents based on a query or other criteria.\n    Implementations may use various indexing or search technologies to fulfill these retrievals.\n    \"\"\"\n\n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the most relevant documents based on the given query.\n        \n        Parameters:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n            \n        Returns:\n            List[Document]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/document_stores/IDocumentStore.py",
        "content": "```swarmauri/core/document_stores/IDocumentStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IDocumentStore(ABC):\n    \"\"\"\n    Interface for a Document Store responsible for storing, indexing, and retrieving documents.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Stores a single document in the document store.\n\n        Parameters:\n        - document (IDocument): The document to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Stores multiple documents in the document store.\n\n        Parameters:\n        - documents (List[IDocument]): The list of documents to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Union[IDocument, None]:\n        \"\"\"\n        Retrieves a document by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document.\n\n        Returns:\n        - Union[IDocument, None]: The requested document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieves all documents stored in the document store.\n\n        Returns:\n        - List[IDocument]: A list of all documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Deletes a document from the document store by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Updates a document in the document store.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document to update.\n        - updated_document (IDocument): The updated document object.\n\n        Note: It's assumed that the updated_document will retain the same doc_id but may have different content or metadata.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def document_count(self) -> int:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/document_stores/__init__.py",
        "content": "```swarmauri/core/document_stores/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/document_stores/IDocumentRetrieve.py",
        "content": "```swarmauri/core/document_stores/IDocumentRetrieve.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IDocumentRetrieve(ABC):\n    \"\"\"\n    Abstract base class for document retrieval operations.\n    \n    This class defines the interface for retrieving documents based on a query or other criteria.\n    Implementations may use various indexing or search technologies to fulfill these retrievals.\n    \"\"\"\n\n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the most relevant documents based on the given query.\n        \n        Parameters:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n            \n        Returns:\n            List[Document]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chunkers/__init__.py",
        "content": "```swarmauri/core/chunkers/__init__.py\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Feb 28 20:35:27 2024\n\n@author: bigman\n\"\"\"\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/chunkers/IChunker.py",
        "content": "```swarmauri/core/chunkers/IChunker.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union, Any\n\nclass IChunker(ABC):\n    \"\"\"\n    Interface for chunking text into smaller pieces.\n\n    This interface defines abstract methods for chunking texts. Implementing classes\n    should provide concrete implementations for these methods tailored to their specific\n    chunking algorithms.\n    \"\"\"\n\n    @abstractmethod\n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[Any]:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVectorMeta.py",
        "content": "```swarmauri/core/vectors/IVectorMeta.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\n\nclass IVectorMeta(ABC):\n    \"\"\"\n    Interface for a high-dimensional data vector. This interface defines the\n    basic structure and operations for interacting with vectors in various applications,\n    such as machine learning, information retrieval, and similarity search.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"\n        Unique identifier for the vector. This ID can be used to reference the vector\n        in a database or a vector store.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def metadata(self) -> Dict[str, Any]:\n        \"\"\"\n        Optional metadata associated with the vector. Metadata can include additional information\n        useful for retrieval, categorization, or description of the vector data.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVectorTransform.py",
        "content": "```swarmauri/core/vectors/IVectorTransform.py\nfrom abc import ABC, abstractmethod\nfrom .IVector import IVector\n\nclass IVectorTransform(ABC):\n    \"\"\"\n    Interface for performing various transformations on vectors.\n    \"\"\"\n\n    @abstractmethod\n    def translate(self, translation_vector: IVector) -> IVector:\n        \"\"\"\n        Translate a vector by a given translation vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def rotate(self, angle: float, axis: IVector) -> IVector:\n        \"\"\"\n        Rotate a vector around a given axis by a certain angle.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def reflect(self, plane_normal: IVector) -> IVector:\n        \"\"\"\n        Reflect a vector across a plane defined by its normal vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def scale(self, scale_factor: float) -> IVector:\n        \"\"\"\n        Scale a vector by a given scale factor.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def shear(self, shear_factor: float, direction: IVector) -> IVector:\n        \"\"\"\n        Shear a vector along a given direction by a shear factor.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def project(self, plane_normal: IVector) -> IVector:\n        \"\"\"\n        Project a vector onto a plane defined by its normal vector.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVector.py",
        "content": "```swarmauri/core/vectors/IVector.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\n\nclass IVector(ABC):\n    \"\"\"\n    Interface for a high-dimensional data vector. This interface defines the\n    basic structure and operations for interacting with vectors in various applications,\n    such as machine learning, information retrieval, and similarity search.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def data(self) -> List[float]:\n        \"\"\"\n        The high-dimensional data that the vector represents. It is typically a list of float values.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/__init__.py",
        "content": "```swarmauri/core/vectors/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVectorProduct.py",
        "content": "```swarmauri/core/vectors/IVectorProduct.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\n\nclass IVectorProduct(ABC):\n    \"\"\"\n    Interface for various vector products including dot product, cross product,\n    and triple products (vector and scalar).\n    \"\"\"\n\n    @abstractmethod\n    def dot_product(self, vector_a: List[float], vector_b: List[float]) -> float:\n        \"\"\"\n        Calculate the dot product of two vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n\n        Returns:\n        - float: The dot product of the two vectors.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def cross_product(self, vector_a: List[float], vector_b: List[float]) -> List[float]:\n        \"\"\"\n        Calculate the cross product of two vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n\n        Returns:\n        - List[float]: The cross product as a new vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def vector_triple_product(self, vector_a: List[float], vector_b: List[float], vector_c: List[float]) -> List[float]:\n        \"\"\"\n        Calculate the vector triple product of three vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n        - vector_c (List[float]): The third vector.\n\n        Returns:\n        - List[float]: The result of the vector triple product as a new vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def scalar_triple_product(self, vector_a: List[float], vector_b: List[float], vector_c: List[float]) -> float:\n        \"\"\"\n        Calculate the scalar triple product of three vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n        - vector_c (List[float]): The third vector.\n\n        Returns:\n        - float: The scalar value result of the scalar triple product.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarm_apis/__init__.py",
        "content": "```swarmauri/core/swarm_apis/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarm_apis/ISwarmAPI.py",
        "content": "```swarmauri/core/swarm_apis/ISwarmAPI.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any\n\nclass ISwarmAPI(ABC):\n    \"\"\"\n    Interface for managing the swarm's API endpoints.\n    \"\"\"\n    \n    @abstractmethod\n    def dispatch_request(self, request_data: Dict[str, Any]) -> Any:\n        \"\"\"\n        Dispatches an incoming user request to one or more suitable agents based on their capabilities.\n\n        Parameters:\n        - request_data (Dict[str, Any]): Data related to the incoming request.\n\n        Returns:\n        - Any: Response from processing the request.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def broadcast_request(self, request_data: Dict[str, Any]) -> Any:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarm_apis/IAgentRegistrationAPI.py",
        "content": "```swarmauri/core/swarm_apis/IAgentRegistrationAPI.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Optional\nfrom swarmauri.core.agents.IAgent import IAgent\n\nclass IAgentRegistrationAPI(ABC):\n    \"\"\"\n    Interface for registering agents with the swarm, designed to support CRUD operations on IAgent instances.\n    \"\"\"\n\n    @abstractmethod\n    def register_agent(self, agent: IAgent) -> bool:\n        \"\"\"\n        Register a new agent with the swarm.\n\n        Parameters:\n            agent (IAgent): An instance of IAgent representing the agent to register.\n\n        Returns:\n            bool: True if the registration succeeded; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_agent(self, agent_id: str, updated_agent: IAgent) -> bool:\n        \"\"\"\n        Update the details of an existing agent. This could include changing the agent's configuration,\n        task assignment, or any other mutable attribute.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent.\n            updated_agent (IAgent): An updated IAgent instance to replace the existing one.\n\n        Returns:\n            bool: True if the update was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_agent(self, agent_id: str) -> bool:\n        \"\"\"\n        Remove an agent from the swarm based on its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent to be removed.\n\n        Returns:\n            bool: True if the removal was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_agent(self, agent_id: str) -> Optional[IAgent]:\n        \"\"\"\n        Retrieve an agent's instance from its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent of interest.\n\n        Returns:\n            Optional[IAgent]: The IAgent instance if found; None otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_agents(self) -> List[IAgent]:\n        \"\"\"\n        List all registered agents.\n\n        Returns:\n            List[IAgent]: A list containing instances of all registered IAgents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/__init__.py",
        "content": "```swarmauri/core/vectorizers/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/IVectorize.py",
        "content": "```swarmauri/core/vectorizers/IVectorize.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union, Any\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass IVectorize(ABC):\n    \"\"\"\n    Interface for converting text to vectors. \n    Implementations of this interface transform input text into numerical \n    vectors that can be used in machine learning models, similarity calculations, \n    and other vector-based operations.\n    \"\"\"\n    @abstractmethod\n    def fit(self, data: Union[str, Any]) -> List[IVector]:\n        pass\n    \n    @abstractmethod\n    def transform(self, data: Union[str, Any]) -> List[IVector]:\n        pass\n\n    @abstractmethod\n    def fit_transform(self, data: Union[str, Any]) -> List[IVector]:\n        pass\n\n    @abstractmethod\n    def infer_vector(self, data: Union[str, Any], *args, **kwargs) -> IVector:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/IFeature.py",
        "content": "```swarmauri/core/vectorizers/IFeature.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass IFeature(ABC):\n\n    @abstractmethod\n    def extract_features(self) -> List[Any]:\n        pass\n    \n\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/ISaveModel.py",
        "content": "```swarmauri/core/vectorizers/ISaveModel.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any\n\nclass ISaveModel(ABC):\n    \"\"\"\n    Interface to abstract the ability to save and load models.\n    \"\"\"\n\n    @abstractmethod\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the model to the specified directory.\n\n        Parameters:\n        - path (str): The directory path where the model will be saved.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_model(self, path: str) -> Any:\n        \"\"\"\n        Loads a model from the specified directory.\n\n        Parameters:\n        - path (str): The directory path from where the model will be loaded.\n\n        Returns:\n        - Returns an instance of the loaded model.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/__init__.py",
        "content": "```swarmauri/core/tracing/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/ITraceContext.py",
        "content": "```swarmauri/core/tracing/ITraceContext.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any\n\nclass ITraceContext(ABC):\n    \"\"\"\n    Interface for a trace context, representing a single trace instance.\n    This context carries the state and metadata of the trace across different system components.\n    \"\"\"\n\n    @abstractmethod\n    def get_trace_id(self) -> str:\n        \"\"\"\n        Retrieves the unique identifier for this trace.\n\n        Returns:\n            str: The unique trace identifier.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_attribute(self, key: str, value: Any):\n        \"\"\"\n        Adds or updates an attribute associated with this trace.\n\n        Args:\n            key (str): The attribute key or name.\n            value (Any): The value of the attribute.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/ITracer.py",
        "content": "```swarmauri/core/tracing/ITracer.py\nfrom swarmauri.core.tracing.ITraceContext import ITraceContext\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Dict, Any\n\n\nclass ITracer(ABC):\n    \"\"\"\n    Interface for implementing distributed tracing across different components of the system.\n    \"\"\"\n\n    @abstractmethod\n    def start_trace(self, name: str, initial_attributes: Optional[Dict[str, Any]] = None) -> ITraceContext:\n        \"\"\"\n        Starts a new trace with a given name and optional initial attributes.\n\n        Args:\n            name (str): Name of the trace, usually represents the operation being traced.\n            initial_attributes (Optional[Dict[str, Any]]): Key-value pairs to be attached to the trace initially.\n\n        Returns:\n            ITraceContext: A context object representing this particular trace instance.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def end_trace(self, trace_context: ITraceContext):\n        \"\"\"\n        Marks the end of a trace, completing its lifecycle and recording its details.\n\n        Args:\n            trace_context (ITraceContext): The trace context to be ended.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def annotate_trace(self, trace_context: ITraceContext, key: str, value: Any):\n        \"\"\"\n        Adds an annotation to an existing trace, enriching it with more detailed information.\n\n        Args:\n            trace_context (ITraceContext): The trace context to annotate.\n            key (str): The key or name of the annotation.\n            value (Any): The value of the annotation.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/IChainTracer.py",
        "content": "```swarmauri/core/tracing/IChainTracer.py\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, List, Tuple, Dict, Any\n\nclass IChainTracer(ABC):\n    \"\"\"\n    Interface for a tracer supporting method chaining through a list of tuples.\n    Each tuple in the list contains: trace context, function, args, and kwargs.\n    \"\"\"\n\n    @abstractmethod\n    def process_chain(self, chain: List[Tuple[Any, Callable[..., Any], List[Any], Dict[str, Any]]]) -> \"IChainTracer\":\n        \"\"\"\n        Processes a sequence of operations defined in a chain.\n\n        Args:\n            chain (List[Tuple[Any, Callable[..., Any], List[Any], Dict[str, Any]]]): A list where each tuple contains:\n                - The trace context or reference required by the function.\n                - The function (method of IChainTracer) to execute.\n                - A list of positional arguments for the function.\n                - A dictionary of keyword arguments for the function.\n\n        Returns:\n            IChainTracer: Returns self to allow further method chaining.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/ICallableChain.py",
        "content": "```swarmauri/core/chains/ICallableChain.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Callable, List, Tuple\n\nCallableDefinition = Tuple[Callable, List[Any], dict]\n\nclass ICallableChain(ABC):\n    @abstractmethod\n    def __call__(self, *initial_args: Any, **initial_kwargs: Any) -> Any:\n        \"\"\"Executes the chain of callables.\"\"\"\n        pass\n\n    @abstractmethod\n    def add_callable(self, func: Callable, args: List[Any] = None, kwargs: dict = None) -> None:\n        \"\"\"Adds a new callable to the chain.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/__init__.py",
        "content": "```swarmauri/core/chains/__init__.py\nfrom swarmauri.core.chains.ICallableChain import ICallableChain\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChain.py",
        "content": "```swarmauri/core/chains/IChain.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any, Dict\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass IChain(ABC):\n    \"\"\"\n    Defines the interface for a Chain within a system, facilitating the organized\n    execution of a sequence of tasks or operations. This interface is at the core of\n    orchestrating operations that require coordination between multiple steps, potentially\n    involving decision-making, branching, and conditional execution based on the outcomes\n    of previous steps or external data.\n\n    A chain can be thought of as a workflow or pipeline, where each step in the chain can\n    perform an operation, transform data, or make decisions that influence the flow of\n    execution.\n\n    Implementors of this interface are responsible for managing the execution order,\n    data flow between steps, and any dynamic adjustments to the execution based on\n    runtime conditions.\n\n    Methods:\n        add_step: Adds a step to the chain.\n        remove_step: Removes a step from the chain.\n        execute: Executes the chain, potentially returning a result.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, steps: List[IChainStep] = None, **configs):\n        pass\n\n    @abstractmethod\n    def add_step(self, step: IChainStep, **kwargs) -> None:\n        \"\"\"\n        Adds a new step to the chain. Steps are executed in the order they are added.\n        Each step is represented by a Callable, which can be a function or method, with\n        optional keyword arguments that specify execution aspects or data needed by the step.\n\n        Parameters:\n            step (IChainStep): The Callable representing the step to add to the chain.\n            **kwargs: Optional keyword arguments that provide additional data or configuration\n                      for the step when it is executed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_step(self, step: IChainStep) -> None:\n        \"\"\"\n        Removes an existing step from the chain. This alters the chain's execution sequence\n        by excluding the specified step from subsequent executions of the chain.\n\n        Parameters:\n            step (IChainStep): The Callable representing the step to remove from the chain.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def execute(self, *args, **kwargs) -> Any:\n        \"\"\"\n        Initiates the execution of the chain. This involves invoking each step in the order\n        they have been added to the chain, passing control from one step to the next, and optionally\n        aggregating or transforming results along the way.\n\n        The execution process can incorporate branching, looping, or conditional logic based on the\n        implementation, allowing for complex workflows to be represented and managed within the chain.\n\n        Parameters:\n            *args: Positional arguments passed to the first step in the chain. These can be data inputs\n                   or other values required for the chain's execution.\n            **kwargs: Keyword arguments that provide additional context, data inputs, or configuration\n                      for the chain's execution. These can be passed to individual steps or influence\n                      the execution flow of the chain.\n\n        Returns:\n            Any: The outcome of executing the chain. This could be a value produced by the final\n                 step, a collection of outputs from multiple steps, or any other result type as\n                 determined by the specific chain implementation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_schema_info(self) -> Dict[str, Any]:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChainFactory.py",
        "content": "```swarmauri/core/chains/IChainFactory.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any, Dict\nfrom swarmauri.core.chains.IChain import IChain\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass IChainFactory(ABC):\n    \"\"\"\n    Interface for creating and managing execution chains within the system.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, **configs):\n        pass\n\n    @abstractmethod\n    def create_chain(self, steps: List[IChainStep] = None) -> IChain:\n        pass\n    \n    @abstractmethod\n    def get_schema_info(self) -> Dict[str, Any]:\n        pass\n    \n    @abstractmethod\n    def get_chain_info(self) -> Dict[str, Any]:\n        pass\n    \n    @abstractmethod\n    def get_chain(self) -> IChain:\n        pass\n    \n    @abstractmethod\n    def set_chain(self, chain: IChain):\n        pass\n    \n    @abstractmethod\n    def reset_chain(self):\n        pass\n    \n    @abstractmethod\n    def get_chain_steps(self) -> List[IChainStep]:\n        pass\n    \n    @abstractmethod\n    def set_chain_steps(self, steps: List[IChainStep]):\n        pass\n    \n    @abstractmethod\n    def add_chain_step(self, step: IChainStep):\n        pass\n    \n    @abstractmethod\n    def remove_chain_step(self, key: str):\n        pass\n    \n    \n    @abstractmethod\n    def get_configs(self) -> Dict[str, Any]:\n        pass\n    \n    @abstractmethod\n    def set_configs(self, **configs):\n        pass\n    \n    @abstractmethod\n    \n    def get_config(self, key: str) -> Any:\n        pass\n    \n    @abstractmethod\n    def set_config(self, key: str, value: Any):\n        pass\n    \n    @abstractmethod\n    def get_schema_info(self) -> Dict[str, Any]:\n        pass\n\n    @abstractmethod\n    def get_chain_info(self) -> Dict[str, Any]:\n        pass    \n    \n\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChainStep.py",
        "content": "```swarmauri/core/chains/IChainStep.py\nfrom typing import List, Dict, Any, Callable\n\nclass IChainStep:\n    \"\"\"\n    Represents a single step within an execution chain.\n    \"\"\"\n    def __init__(self, \n        key: str, \n        method: Callable, \n        args: List[Any] = None, \n        kwargs: Dict[str, Any] = None, \n        ref: str = None):\n        \"\"\"\n        Initialize a chain step.\n\n        Args:\n            key (str): Unique key or identifier for the step.\n            method (Callable): The callable object (function or method) to execute in this step.\n            args (List[Any], optional): Positional arguments for the callable.\n            kwargs (Dict[str, Any], optional): Keyword arguments for the callable.\n            ref (str, optional): Reference to another component or context variable, if applicable.\n        \"\"\"\n        self.key = key\n        self.method = method\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.ref = ref\n```"
    },
    {
        "document_name": "swarmauri/core/distances/__init__.py",
        "content": "```swarmauri/core/distances/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/distances/IDistanceSimilarity.py",
        "content": "```swarmauri/core/distances/IDistanceSimilarity.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom ..vectors.IVector import IVector\n\nclass IDistanceSimilarity(ABC):\n    \"\"\"\n    Interface for computing distances and similarities between high-dimensional data vectors. This interface\n    abstracts the method for calculating the distance and similarity, allowing for the implementation of various \n    distance metrics such as Euclidean, Manhattan, Cosine similarity, etc.\n    \"\"\"\n\n    @abstractmethod\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The computed distance between vector_a and vector_b.\n        \"\"\"\n        pass\n    \n\n    @abstractmethod\n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> float:\n        pass\n\n\n    @abstractmethod\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the similarity between two vectors. The definition of similarity (e.g., cosine similarity)\n        should be implemented in concrete classes.\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector to compare with the first vector.\n\n        Returns:\n            float: A similarity score between vector_a and vector_b.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> float:\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/__init__.py",
        "content": "```swarmauri/core/metrics/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/IMetric.py",
        "content": "```swarmauri/core/metrics/IMetric.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\n\nclass IMetric(ABC):\n    \"\"\"\n    Defines a general interface for metrics within the SwarmaURI system.\n    Metrics can be anything from system performance measurements to\n    machine learning model evaluation metrics.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"\n        The name identifier for the metric.\n\n        Returns:\n            str: The name of the metric.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def value(self) -> Any:\n        \"\"\"\n        Current value of the metric.\n\n        Returns:\n            The metric's value. The type depends on the specific metric implementation.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def unit(self) -> str:\n        \"\"\"\n        The unit of measurement for the metric.\n\n        Returns:\n            str: The unit of measurement (e.g., 'seconds', 'Mbps').\n        \"\"\"\n        pass\n\n    @unit.setter\n    @abstractmethod\n    def unit(self, value: str) -> None:\n        \"\"\"\n        Update the unit of measurement for the metric.\n\n        Args:\n            value (str): The new unit of measurement for the metric.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def __call__(self, **kwargs) -> Any:\n        \"\"\"\n        Retrieves the current value of the metric.\n\n        Returns:\n            The current value of the metric.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/ICalculateMetric.py",
        "content": "```swarmauri/core/metrics/ICalculateMetric.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\n\nclass ICalculateMetric(ABC):\n\n    @abstractmethod\n    def calculate(self, **kwargs) -> Any:\n        \"\"\"\n        Calculate the metric based on the provided data.\n\n        Args:\n            *args: Variable length argument list that the metric calculation might require.\n            **kwargs: Arbitrary keyword arguments that the metric calculation might require.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update(self, value) -> None:\n        \"\"\"\n        Update the metric value based on new information.\n\n        Args:\n            value: The new information used to update the metric. This could be a new\n            measurement or data point that affects the metric's current value.\n\n        Note:\n            This method is intended for internal use and should not be publicly accessible.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/IAggMeasurements.py",
        "content": "```swarmauri/core/metrics/IAggMeasurements.py\nfrom typing import List, Any\nfrom abc import ABC, abstractmethod\n\nclass IAggMeasurements(ABC):\n\n    @abstractmethod\n    def add_measurement(self, measurement: Any) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def measurements(self) -> List[Any]:\n        pass\n\n    @measurements.setter\n    @abstractmethod\n    def measurements(self, value) -> None:\n        pass\n\n    @abstractmethod\n    def reset(self) -> None:\n        \"\"\"\n        Reset or clear the metric's current state, starting fresh as if no data had been processed.\n        This is useful for metrics that might aggregate or average data over time and need to be reset.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/IThreshold.py",
        "content": "```swarmauri/core/metrics/IThreshold.py\nfrom abc import ABC, abstractmethod\n\nclass IThreshold(ABC):\n    @property\n    @abstractmethod\n    def k(self) -> int:\n        pass\n\n    @k.setter\n    @abstractmethod\n    def k(self, value: int) -> None:\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/experiment_stores/__init__.py",
        "content": "```swarmauri/core/experiment_stores/__init__.py\n# core/experiment_stores/IExperimentStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Union\nfrom swarmauri.core.documents.IExperimentDocument import IExperimentDocument\n\nclass IExperimentStore(ABC):\n    \"\"\"\n    Interface for an Experiment Store that manages experimental documents and supports\n    operations related to experimenting, evaluating, testing, and benchmarking.\n    \"\"\"\n    @abstractmethod\n    def add_experiment(self, experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Stores a single experiment in the experiment store.\n\n        Parameters:\n        - experiment (IExperimentDocument): The experimental document to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_experiments(self, experiments: List[IExperimentDocument]) -> None:\n        \"\"\"\n        Stores multiple experiments in the experiment store.\n\n        Parameters:\n        - experiments (List[IExperimentDocument]): The list of experimental documents to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_experiment(self, experiment_id: str) -> Union[IExperimentDocument, None]:\n        \"\"\"\n        Retrieves an experimental document by its ID.\n\n        Parameters:\n        - id (str): The unique identifier of the experiment.\n\n        Returns:\n        - Union[IExperimentDocument, None]: The requested experimental document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_experiments(self) -> List[IExperimentDocument]:\n        \"\"\"\n        Retrieves all experimental documents stored in the experiment store.\n\n        Returns:\n        - List[IExperimentDocument]: A list of all experimental documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_experiment(self, experiment_id: str, updated_experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Updates an experimental document in the experiment store.\n\n        Parameters:\n        - id (str): The unique identifier of the experiment to update.\n        - updated_experiment (IExperimentDocument): The updated experimental document.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_experiment(self, experiment_id: str) -> None:\n        \"\"\"\n        Deletes an experimental document from the experiment store by its ID.\n\n        Parameters:\n        - id (str): The unique identifier of the experimental document to be deleted.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def evaluate_experiments(self, evaluation_criteria: Dict[str, Any]) -> Any:\n        \"\"\"\n        Evaluates the experiments stored in the experiment store based on given criteria and metrics.\n\n        Parameters:\n        - evaluation_criteria (Dict[str, Any]): The criteria and metrics to evaluate the experiments.\n\n        Returns:\n        - Any: The evaluation results, which may vary depending on the evaluation criteria.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def benchmark_experiments(self, benchmarking_data: Dict[str, Any]) -> Any:\n        \"\"\"\n        Benchmarks the experiments against each other or predefined standards.\n\n        Parameters:\n        - benchmarking_data (Dict[str, Any]): Data and parameters for benchmarking the experiments.\n\n        Returns:\n        - Any: The benchmark results, which may vary depending on the benchmarking methodology.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/experiment_stores/IExperimentStore.py",
        "content": "```swarmauri/core/experiment_stores/IExperimentStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Union\nfrom swarmauri.core.documents.IExperimentDocument import IExperimentDocument\n\nclass IExperimentStore(ABC):\n    \"\"\"\n    Interface for an Experiment Store that manages experimental documents and supports\n    operations related to experimenting, evaluating, testing, and benchmarking.\n    \"\"\"\n    @abstractmethod\n    def add_experiment(self, experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Stores a single experiment in the experiment store.\n\n        Parameters:\n        - experiment (IExperimentDocument): The experimental document to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_experiments(self, experiments: List[IExperimentDocument]) -> None:\n        \"\"\"\n        Stores multiple experiments in the experiment store.\n\n        Parameters:\n        - experiments (List[IExperimentDocument]): The list of experimental documents to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_experiment(self, experiment_id: str) -> Union[IExperimentDocument, None]:\n        \"\"\"\n        Retrieves an experimental document by its ID.\n\n        Parameters:\n        - experiment_id (str): The unique identifier of the experiment.\n\n        Returns:\n        - Union[IExperimentDocument, None]: The requested experimental document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_experiments(self) -> List[IExperimentDocument]:\n        \"\"\"\n        Retrieves all experimental documents stored in the experiment store.\n\n        Returns:\n        - List[IExperimentDocument]: A list of all experimental documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_experiment(self, experiment_id: str, updated_experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Updates an experimental document in the experiment store.\n\n        Parameters:\n        - experiment_id (str): The unique identifier of the experiment to update.\n        - updated_experiment (IExperimentDocument): The updated experimental document.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_experiment(self, experiment_id: str) -> None:\n        \"\"\"\n        Deletes an experimental document from the experiment store by its ID.\n\n        Parameters:\n        - experiment_id (str): The unique identifier of the experimental document to be deleted.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agent_factories/IAgentFactory.py",
        "content": "```swarmauri/core/agent_factories/IAgentFactory.py\nfrom abc import ABC, abstractmethod\nfrom typing import Type, Any\nfrom datetime import datetime\n\nclass IAgentFactory(ABC):\n    \"\"\"\n    Interface for Agent Factories, extended to include properties like ID, name, type,\n    creation date, and last modification date.\n    \"\"\"\n\n    @abstractmethod\n    def create_agent(self, agent_type: str, **kwargs) -> Any:\n        pass\n\n    @abstractmethod\n    def register_agent(self, agent_type: str, constructor: Type[Any]) -> None:\n        pass\n\n    # Abstract properties and setters\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"Unique identifier for the factory instance.\"\"\"\n        pass\n\n    @id.setter\n    @abstractmethod\n    def id(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"Name of the factory.\"\"\"\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def type(self) -> str:\n        \"\"\"Type of agents this factory produces.\"\"\"\n        pass\n\n    @type.setter\n    @abstractmethod\n    def type(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def date_created(self) -> datetime:\n        \"\"\"The creation date of the factory instance.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def last_modified(self) -> datetime:\n        \"\"\"Date when the factory was last modified.\"\"\"\n        pass\n\n    @last_modified.setter\n    @abstractmethod\n    def last_modified(self, value: datetime) -> None:\n        pass\n\n    def __hash__(self):\n        \"\"\"\n        The __hash__ method allows objects of this class to be used in sets and as dictionary keys.\n        __hash__ should return an integer and be defined based on immutable properties.\n        This is generally implemented directly in concrete classes rather than in the interface,\n        but it's declared here to indicate that implementing classes must provide it.\n        \"\"\"\n        pass\n\n   \n```"
    },
    {
        "document_name": "swarmauri/core/agent_factories/__init__.py",
        "content": "```swarmauri/core/agent_factories/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/agent_factories/IExportConf.py",
        "content": "```swarmauri/core/agent_factories/IExportConf.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict\n\nclass IExportConf(ABC):\n    \"\"\"\n    Interface for exporting configurations related to agent factories.\n    \n    Implementing classes are expected to provide functionality for representing\n    the factory's configuration as a dictionary, JSON string, or exporting to a file.\n    \"\"\"\n\n    @abstractmethod\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Serializes the agent factory's configuration to a dictionary.\n        \n        Returns:\n            Dict[str, Any]: A dictionary representation of the factory's configuration.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_json(self) -> str:\n        \"\"\"\n        Serializes the agent factory's configuration to a JSON string.\n        \n        Returns:\n            str: A JSON string representation of the factory's configuration.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_file(self, file_path: str) -> None:\n        \"\"\"\n        Exports the agent factory's configuration to a file in a suitable format.\n        \n        Parameters:\n            file_path (str): The path to the file where the configuration should be saved.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/standard/__init__.py",
        "content": "```swarmauri/standard/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/__init__.py",
        "content": "```swarmauri/standard/models/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/base/__init__.py",
        "content": "```swarmauri/standard/models/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/base/ModelBase.py",
        "content": "```swarmauri/standard/models/base/ModelBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any\nfrom ....core.models.IModel import IModel\n\nclass ModelBase(IModel, ABC):\n    \"\"\"\n    Concrete implementation of the IModel abstract base class.\n    This version includes managing the model name through a property and a setter.\n    \"\"\"\n    @abstractmethod\n    def __init__(self, model_name: str):\n        self._model_name = model_name\n    \n    @property\n    def model_name(self):\n        return self._model_name\n    \n    @model_name.setter\n    def model_name(self, value: str) -> None:\n        \"\"\"\n        Property setter that sets the name of the model.\n\n        Parameters:\n        - value (str): The new name of the model.\n        \"\"\"\n        self._model_name = value\n       \n    \n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/__init__.py",
        "content": "```swarmauri/standard/models/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/OpenAIModel.py",
        "content": "```swarmauri/standard/models/concrete/OpenAIModel.py\nimport json\nfrom typing import List\nfrom openai import OpenAI\nfrom swarmauri.core.models.IPredict import IPredict\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\n\n\nclass OpenAIModel(ModelBase, IPredict):\n    def __init__(self, api_key: str, model_name: str):\n        \"\"\"\n        Initialize the OpenAI model with an API key.\n\n        Parameters:\n        - api_key (str): Your OpenAI API key.\n        \"\"\"\n        self.client = OpenAI(api_key=api_key)\n        super().__init__(model_name)\n        \n    \n    def predict(self, messages, temperature=0.7, max_tokens=256, enable_json=False, stop: List[str] = None):\n        \"\"\"\n        Generate predictions using the OpenAI model.\n\n        Parameters:\n        - messages: Input data/messages for the model.\n        - temperature (float): Sampling temperature.\n        - max_tokens (int): Maximum number of tokens to generate.\n        - enable_json (bool): Format response as JSON.\n        \n        Returns:\n        - The generated message content.\n        \"\"\"\n        if self.client is None:\n            raise Exception(\"OpenAI client is not initialized. Call 'load_model' first.\")\n        \n        if enable_json:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                response_format={ \"type\": \"json_object\" },\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=stop\n            )\n        else:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=stop\n            )\n        \n        result = json.loads(response.json())\n        message_content = result['choices'][0]['message']['content']\n        \n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/AzureGPT.py",
        "content": "```swarmauri/standard/models/concrete/AzureGPT.py\nimport json\nfrom openai import AzureOpenAI\nfrom ..base.ModelBase import ModelBase\nfrom ....core.models.IPredict import IPredict\n\nclass AzureGPT(ModelBase, IPredict):\n    def __init__(self, azure_endpoint: str, api_key: str, api_version: str, model_name: str):\n        \"\"\"\n        Initialize the Azure model with an API key.\n\n        Parameters:\n        - api_key (str): Your OpenAI API key.\n        \"\"\"\n        self.azure_endpoint = azure_endpoint\n        self.api_key = api_key\n        self.api_version = api_version\n        self.client = AzureOpenAI(\n                azure_endpoint = azure_endpoint, \n                api_key = api_key,  \n                api_version = api_version\n            )\n        super().__init__(model_name)\n       \n\n    \n    def predict(self, messages, temperature=0.7, max_tokens=256, enable_json=True):\n        \"\"\"\n        Generate predictions using the OpenAI model.\n\n        Parameters:\n        - messages: Input data/messages for the model.\n        - temperature (float): Sampling temperature.\n        - max_tokens (int): Maximum number of tokens to generate.\n        - enable_json (bool): Format response as JSON.\n        \n        Returns:\n        - The generated message content.\n        \"\"\"\n        if self.client is None:\n            raise Exception(\"OpenAI client is not initialized. Call 'load_model' first.\")\n        \n        if enable_json:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                response_format={ \"type\": \"json_object\" },\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=None\n            )\n        else:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=None\n            )\n        \n        result = response.json()\n        message_content = json.loads(result['choices'][0]['message']['content'])\n        \n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/OpenAIImageGenerator.py",
        "content": "```swarmauri/standard/models/concrete/OpenAIImageGenerator.py\nimport json\nfrom openai import OpenAI\nfrom ..base.ModelBase import ModelBase\nfrom ....core.models.IPredict import IPredict\n\nclass OpenAIImageGenerator(ModelBase, IPredict):\n    def __init__(self, api_key: str, model_name: str = \"dall-e\"):\n        \"\"\"\n        Initializes the OpenAI image generator model.\n\n        Parameters:\n        - api_key (str): The API key provided by OpenAI for access to their services.\n        - model_name (str): Name of the image generation model provided by OpenAI.\n                            Defaults to \"dall-e\" for DALL\u00c2\u00b7E, their image generation model.\n        \"\"\"\n        self.client = OpenAI(api_key=api_key)\n        super().__init__(model_name)\n\n    def predict(self, prompt: str, size: str = \"1024x1024\", \n                quality: str = \"standard\", n: int = 1) -> str:\n        \"\"\"\n        Generates an image based on the given prompt and other parameters.\n\n        Parameters:\n        - prompt (str): A description of the image you want to generate.\n        - **kwargs: Additional parameters that the image generation endpoint might use.\n\n        Returns:\n        - str: A URL or identifier for the generated image.\n        \"\"\"\n        try:\n            response = self.client.images.generate(\n                model=self.model_name,\n                prompt=prompt,\n                size=size,\n                quality=quality,\n                n=n\n            )\n            result = response.json()\n            return result\n        \n        except Exception as e:\n            return str(e)\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/OpenAIToolModel.py",
        "content": "```swarmauri/standard/models/concrete/OpenAIToolModel.py\nfrom openai import OpenAI\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\nfrom swarmauri.core.models.IPredict import IPredict\n\nclass OpenAIToolModel(ModelBase, IPredict):\n    def __init__(self, api_key: str, model_name: str = \"gpt-3.5-turbo-0125\"):\n        self.client = OpenAI(api_key=api_key)\n        super().__init__(model_name)\n\n    def predict(self, messages, tools=None, tool_choice=None, temperature=0.7, max_tokens=1024):\n        if tools and not tool_choice:\n            tool_choice = \"auto\"\n        response = self.client.chat.completions.create(\n            model=self.model_name,\n            messages=messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            tools=tools,\n            tool_choice=tool_choice,\n        )\n        return response\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/__init__.py",
        "content": "```swarmauri/standard/agents/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/__init__.py",
        "content": "```swarmauri/standard/agents/base/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/NamedAgentBase.py",
        "content": "```swarmauri/standard/agents/base/NamedAgentBase.py\nfrom typing import Any, Optional\nfrom abc import ABC\nfrom swarmauri.core.agents.IAgentName import IAgentName\n\n\nclass NamedAgentBase(IAgentName,ABC):\n    \n    def __init__(self, name: str):\n        self._name = name\n\n    def exec(self, input_str: Optional[Any]) -> Any:\n        raise NotImplementedError('The `exec` function has not been implemeneted on this class.')\n    \n    @property\n    def name(self) -> str:\n        return self._name\n    \n    @name.setter\n    def name(self, value) -> None:\n        self._name = value     \n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/ConversationAgentBase.py",
        "content": "```swarmauri/standard/agents/base/ConversationAgentBase.py\nfrom typing import Any, Optional\nfrom abc import ABC\n\nfrom swarmauri.core.agents.IAgentConversation import IAgentConversation\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\n\nclass ConversationAgentBase(AgentBase, IAgentConversation, ABC):\n    def __init__(self, model: IModel, conversation: IConversation):\n        AgentBase.__init__(self, model)\n        self._conversation = conversation\n\n    \n    def exec(self, input_str: Optional[Any]) -> Any:\n        raise NotImplementedError('The `exec` function has not been implemeneted on this class.')\n      \n\n    @property\n    def conversation(self) -> IConversation:\n        return self._conversation\n\n    @conversation.setter\n    def conversation(self, value) -> None:\n        self._conversation = value\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/ToolAgentBase.py",
        "content": "```swarmauri/standard/agents/base/ToolAgentBase.py\nfrom abc import ABC\nfrom typing import Any, Optional\nfrom swarmauri.core.agents.IAgentConversation import IAgentConversation\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.conversations.IConversation import IConversation\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\n\n\nclass ToolAgentBase(ConversationAgentBase, IAgentConversation, ABC):\n    \n    def __init__(self, \n                 model: IModel, \n                 conversation: IConversation,\n                 toolkit: IToolkit):\n        ConversationAgentBase.__init__(self, model, conversation)\n        self._toolkit = toolkit\n\n    def exec(self, input_str: Optional[Any]) -> Any:\n        raise NotImplementedError('The `exec` function has not been implemeneted on this class.')\n    \n    @property\n    def toolkit(self) -> IToolkit:\n        return self._toolkit\n    \n    @toolkit.setter\n    def toolkit(self, value) -> None:\n        self._toolkit = value        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/AgentBase.py",
        "content": "```swarmauri/standard/agents/base/AgentBase.py\nfrom typing import Any, Optional\nfrom abc import ABC\nfrom swarmauri.core.agents.IAgent import IAgent\nfrom swarmauri.core.models.IModel import IModel\n\n\n\nclass AgentBase(IAgent, ABC):\n    def __init__(self, model: IModel):\n        self._model = model\n\n    def exec(self, input_str: Optional[Any]) -> Any:\n        raise NotImplementedError('The `exec` function has not been implemeneted on this class.')\n    \n    @property\n    def model(self) -> IModel:\n        return self._model\n    \n    @model.setter\n    def model(self, value) -> None:\n        self._model = value        \n\n    \n    def __getattr__(self, name):\n        # Example of transforming attribute name from simplified to internal naming convention\n        internal_name = f\"_{name}\"\n        if internal_name in self.__dict__:\n            return self.__dict__[internal_name]\n        raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n    \n    def __setattr__(self, name, value):\n        # Direct assignment to the __dict__ to bypass any potential infinite recursion\n        # from setting attributes that do not explicitly exist.\n        object.__setattr__(self, name, value) \n        \n        \n    def __str__(self):\n        class_name = self.__class__.__name__\n        variables_str = \", \".join(f\"{k}={v}\" for k, v in self.__dict__.items())\n        return f\"<{class_name} {variables_str}>\"\n        \n    def __repr__(self):\n        class_name = self.__class__.__name__\n        variables_str = \", \".join(f\"{k}={v}\" for k, v in self.__dict__.items())\n        return f\"{class_name} ({variables_str})\"\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/VectorStoreAgentBase.py",
        "content": "```swarmauri/standard/agents/base/VectorStoreAgentBase.py\nfrom typing import Any, Optional\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.conversations.IConversation import IConversation\nfrom swarmauri.core.agents.IAgentVectorStore import IAgentVectorStore\nfrom swarmauri.core.vector_stores.IVectorStore import IVectorStore\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\n\n\nclass VectorStoreAgentBase(ConversationAgentBase, NamedAgentBase, IAgentVectorStore):\n    \"\"\"\n    Base class for agents that handle and store documents within their processing scope.\n    Extends ConversationAgentBase and NamedAgentBase to utilize conversational context,\n    naming capabilities, and implements IAgentDocumentStore for document storage.\n    \"\"\"\n\n    def __init__(self, name: str, model: IModel, conversation: IConversation, vector_store: IVectorStore):\n        NamedAgentBase.__init__(self, name=name)  # Initialize name through NamedAgentBase\n        ConversationAgentBase.__init__(self, model, conversation)  # Initialize conversation and model\n        self._vector_store = vector_store  # Document store initialization\n\n    @property\n    def vector_store(self) -> Optional[IDocument]:\n        \"\"\"\n        Gets the document store associated with this agent.\n        \n        Returns:\n            Optional[IDocument]: The document store of the agent, if any.\n        \"\"\"\n        return self._vector_store\n\n    @vector_store.setter\n    def vector_store(self, value: IDocument) -> None:\n        \"\"\"\n        Sets the document store for this agent.\n\n        Args:\n            value (IDocument): The new document store to be associated with the agent.\n        \"\"\"\n        self._vector_store = value\n    \n    def exec(self, input_data: Optional[Any]) -> Any:\n        \"\"\"\n        Placeholder method to demonstrate expected behavior of derived classes.\n        Subclasses should implement their specific logic for processing input data and optionally interacting with the document store.\n\n        Args:\n            input_data (Optional[Any]): Input data to process, can be of any format that the agent is designed to handle.\n\n        Returns:\n            Any: The result of processing the input data.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement the exec method.\")\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/__init__.py",
        "content": "```swarmauri/standard/agents/concrete/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/ToolAgent.py",
        "content": "```swarmauri/standard/agents/concrete/ToolAgent.py\nfrom typing import Any, Optional, Union, Dict\nimport json\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\nfrom swarmauri.core.conversations.IConversation import IConversation\nfrom swarmauri.core.messages import IMessage\n\nfrom swarmauri.standard.agents.base.ToolAgentBase import ToolAgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage, FunctionMessage\n\n\nclass ToolAgent(ToolAgentBase):\n    def __init__(self, \n                 model: IModel, \n                 conversation: IConversation, \n                 toolkit: IToolkit):\n        super().__init__(model, conversation, toolkit)\n\n    def exec(self, input_data: Union[str, IMessage],  model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n        toolkit = self.toolkit\n        \n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        # Add the human message to the conversation\n        conversation.add_message(human_message)\n\n            \n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_dict()\n        \n        prediction = model.predict(messages=messages, \n                                   tools=toolkit.tools, \n                                   tool_choice=\"auto\", \n                                   **model_kwargs)\n        \n        prediction_message = prediction.choices[0].message\n        \n        agent_response = prediction_message.content\n        \n        agent_message = AgentMessage(content=prediction_message.content, \n                                     tool_calls=prediction_message.tool_calls)\n        conversation.add_message(agent_message)\n        \n        tool_calls = prediction.choices[0].message.tool_calls\n        if tool_calls:\n        \n            for tool_call in tool_calls:\n                func_name = tool_call.function.name\n                \n                func_call = toolkit.get_tool_by_name(func_name)\n                func_args = json.loads(tool_call.function.arguments)\n                func_result = func_call(**func_args)\n                \n                func_message = FunctionMessage(func_result, \n                                               name=func_name, \n                                               tool_call_id=tool_call.id)\n                conversation.add_message(func_message)\n            \n            \n            messages = conversation.as_dict()\n            rag_prediction = model.predict(messages=messages, \n                                           tools=toolkit.tools, \n                                           tool_choice=\"none\",\n                                           **model_kwargs)\n            \n            prediction_message = rag_prediction.choices[0].message\n            \n            agent_response = prediction_message.content\n            agent_message = AgentMessage(agent_response)\n            conversation.add_message(agent_message)\n            prediction = rag_prediction\n            \n        return agent_response \n    \n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/ChatSwarmAgent.py",
        "content": "```swarmauri/standard/agents/concrete/ChatSwarmAgent.py\nfrom typing import Any, Optional, Union, Dict\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.messages import IMessage\nfrom swarmauri.core.conversations import IConversation\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage\n\nclass ChatSwarmAgent(ConversationAgentBase):\n    def __init__(self, model: IModel, conversation: IConversation):\n        super().__init__(model, conversation)\n\n    def exec(self, input_data: Union[str, IMessage], model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        # Add the human message to the conversation\n        conversation.add_message(human_message)\n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_dict()\n        if model_kwargs:\n            prediction = model.predict(messages=messages, **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n        # Create an AgentMessage instance with the model's response and update the conversation\n        agent_message = AgentMessage(prediction)\n        conversation.add_message(agent_message)\n        \n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/SingleCommandAgent.py",
        "content": "```swarmauri/standard/agents/concrete/SingleCommandAgent.py\nfrom typing import Any, Optional\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\n\nclass SingleCommandAgent(AgentBase):\n    def __init__(self, model: IModel, \n                 conversation: IConversation):\n        super().__init__(model, conversation)\n\n    def exec(self, input_str: Optional[str] = None) -> Any:\n        model = self.model\n        prediction = model.predict(input_str)\n        \n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/SimpleSwarmAgent.py",
        "content": "```swarmauri/standard/agents/concrete/SimpleSwarmAgent.py\nfrom typing import Any, Optional\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.conversations.IConversation import IConversation\n\n\nfrom swarmauri.standard.agents.base.SwarmAgentBase import AgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage\n\nclass SimpleSwarmAgent(AgentBase):\n    def __init__(self, model: IModel, \n                 conversation: IConversation):\n        super().__init__(model, conversation)\n\n    def exec(self, input_str: Optional[str] = None) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Construct a new human message (for example purposes)\n        if input_str:\n            human_message = HumanMessage(input_str)\n            conversation.add_message(human_message)\n        \n        messages = conversation.as_dict()\n        prediction = model.predict(messages=messages)\n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/MultiPartyChatSwarmAgent.py",
        "content": "```swarmauri/standard/agents/concrete/MultiPartyChatSwarmAgent.py\nfrom typing import Any, Optional, Union, Dict\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.messages import IMessage\n\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\nfrom swarmauri.standard.conversations.concrete.SharedConversation import SharedConversation\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage\n\nclass MultiPartyChatSwarmAgent(ConversationAgentBase, NamedAgentBase):\n    def __init__(self, \n                 model: IModel, \n                 conversation: SharedConversation,\n                 name: str):\n        ConversationAgentBase.__init__(self, model, conversation)\n        NamedAgentBase.__init__(self, name)\n\n    def exec(self, input_data: Union[str, IMessage] = \"\", model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        if input_data != \"\":\n            # Add the human message to the conversation\n            conversation.add_message(human_message, sender_id=self.name)\n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_dict()\n\n        \n        if model_kwargs:\n            prediction = model.predict(messages=messages, **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n        # Create an AgentMessage instance with the model's response and update the conversation\n        if prediction != '':\n            agent_message = AgentMessage(prediction)\n            conversation.add_message(agent_message, sender_id=self.name)\n        \n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/MultiPartyToolAgent.py",
        "content": "```swarmauri/standard/agents/concrete/MultiPartyToolAgent.py\nfrom typing import Any, Optional, Union, Dict\nimport json\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\nfrom swarmauri.core.conversations.IConversation import IConversation\nfrom swarmauri.core.messages import IMessage\n\nfrom swarmauri.standard.agents.base.ToolAgentBase import ToolAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage, FunctionMessage\n\n\nclass MultiPartyToolAgent(ToolAgentBase, NamedAgentBase):\n    def __init__(self, \n                 model: IModel, \n                 conversation: IConversation, \n                 toolkit: IToolkit,\n                 name: str):\n        ToolAgentBase.__init__(self, model, conversation, toolkit)\n        NamedAgentBase.__init__(self, name)\n\n    def exec(self, input_data: Union[str, IMessage], model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n        toolkit = self.toolkit\n        \n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        if input_data != \"\":\n            # Add the human message to the conversation\n            conversation.add_message(human_message, sender_id=self.name)\n            \n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_dict()\n        \n\n        if model_kwargs:\n            prediction = model.predict(messages=messages, \n                                   tools=toolkit.tools, \n                                   tool_choice=\"auto\",\n                                   **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n        \n        \n        prediction_message = prediction.choices[0].message\n        agent_response = prediction_message.content\n        \n        agent_message = AgentMessage(content=prediction_message.content, \n                                     tool_calls=prediction_message.tool_calls)\n        conversation.add_message(agent_message, sender_id=self.name)\n        \n        tool_calls = prediction.choices[0].message.tool_calls\n        if tool_calls:\n        \n            for tool_call in tool_calls:\n                func_name = tool_call.function.name\n                \n                func_call = toolkit.get_tool_by_name(func_name)\n                func_args = json.loads(tool_call.function.arguments)\n                func_result = func_call(**func_args)\n                \n                func_message = FunctionMessage(func_result, \n                                               name=func_name, \n                                               tool_call_id=tool_call.id)\n                conversation.add_message(func_message, sender_id=self.name)\n            \n            \n            messages = conversation.as_dict()\n            rag_prediction = model.predict(messages=messages, \n                                           tools=toolkit.tools, \n                                           tool_choice=\"none\")\n            \n            prediction_message = rag_prediction.choices[0].message\n            \n            agent_response = prediction_message.content\n            if agent_response != \"\":\n                agent_message = AgentMessage(agent_response)\n                conversation.add_message(agent_message, sender_id=self.name)\n            prediction = rag_prediction\n            \n        return agent_response \n    \n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/RagAgent.py",
        "content": "```swarmauri/standard/agents/concrete/RagAgent.py\nfrom typing import Any, Optional, Union, Dict\nfrom swarmauri.core.messages import IMessage\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\nfrom swarmauri.standard.agents.base.VectorStoreAgentBase import VectorStoreAgentBase\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\n\nfrom swarmauri.standard.messages.concrete import (HumanMessage, \n                                                  SystemMessage,\n                                                  AgentMessage)\n\nclass RagAgent(VectorStoreAgentBase):\n    \"\"\"\n    RagAgent (Retriever-And-Generator Agent) extends DocumentAgentBase,\n    specialized in retrieving documents based on input queries and generating responses.\n    \"\"\"\n\n    def __init__(self, name: str, model: IModel, conversation: SystemContextBase, vector_store: VectorDocumentStoreRetrieveBase):\n        super().__init__(name=name, model=model, conversation=conversation, vector_store=vector_store)\n\n    def exec(self, \n             input_data: Union[str, IMessage], \n             top_k: int = 5, \n             model_kwargs: Optional[Dict] = {}\n             ) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n        \n        # Add the human message to the conversation\n        conversation.add_message(human_message)\n        \n        \n        \n        similar_documents = self.vector_store.retrieve(query=input_data, top_k=top_k)\n        substr = '\\n'.join([doc.content for doc in similar_documents])\n        \n        # Use substr to set system context\n        system_context = SystemMessage(substr)\n        conversation.system_context = system_context\n        \n\n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_dict()\n        if model_kwargs:\n            prediction = model.predict(messages=messages, **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n            \n        # Create an AgentMessage instance with the model's response and update the conversation\n        agent_message = AgentMessage(prediction)\n        conversation.add_message(agent_message)\n        \n        return prediction\n    \n    \n    \n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/GenerativeRagAgent.py",
        "content": "```swarmauri/standard/agents/concrete/GenerativeRagAgent.py\nfrom typing import Any, Optional, Union, Dict\nfrom swarmauri.core.messages import IMessage\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\nfrom swarmauri.standard.agents.base.DocumentAgentBase import DocumentAgentBase\nfrom swarmauri.standard.document_stores.base.DocumentStoreRetrieveBase import DocumentStoreRetrieveBase\nfrom swarmauri.standard.documents.concrete.Document import Document\nfrom swarmauri.standard.chunkers.concrete.MdSnippetChunker import MdSnippetChunker\nfrom swarmauri.standard.messages.concrete import (HumanMessage, \n                                                  SystemMessage,\n                                                  AgentMessage)\n\nclass GenerativeRagAgent(DocumentAgentBase):\n    \"\"\"\n    RagAgent (Retriever-And-Generator Agent) extends DocumentAgentBase,\n    specialized in retrieving documents based on input queries and generating responses.\n    \"\"\"\n\n    def __init__(self, name: str, model: IModel, conversation: SystemContextBase, document_store: DocumentStoreRetrieveBase):\n        super().__init__(name=name, model=model, conversation=conversation, document_store=document_store)\n\n    def exec(self, \n             input_data: Union[str, IMessage], \n             top_k: int = 5, \n             model_kwargs: Optional[Dict] = {}\n             ) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n        \n        # Add the human message to the conversation\n        conversation.add_message(human_message)\n        \n        \n        \n        similar_documents = self.document_store.retrieve(query=input_data, top_k=top_k)\n        substr = '\\n'.join([doc.content for doc in similar_documents])\n        \n        # Use substr to set system context\n        system_context = SystemMessage(substr)\n        conversation.system_context = system_context\n        \n\n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_dict()\n        if model_kwargs:\n            prediction = model.predict(messages=messages, **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n            \n        # Create an AgentMessage instance with the model's response and update the conversation\n        agent_message = AgentMessage(prediction)\n        conversation.add_message(agent_message)\n        \n        chunker = MdSnippetChunker()\n        \n        new_documents = [Document(doc_id=self.document_store.document_count()+1,\n                                     content=each[2], \n                                     metadata={\"source\": \"RagSaverAgent\", \n                                               \"language\": each[1],\n                                               \"comments\": each[0]})\n                     for each in chunker.chunk_text(prediction)]\n\n        self.document_store.add_documents(new_documents)\n        \n        return prediction\n    \n    \n    \n\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/__init__.py",
        "content": "```swarmauri/standard/utils/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/load_documents_from_json.py",
        "content": "```swarmauri/standard/utils/load_documents_from_json.py\nimport json\nfrom typing import List\nfrom swarmauri.standard.documents.concrete.Document import Document\n\ndef load_documents_from_json(json_file_path):\n    documents = []\n    with open(json_file_path, 'r') as f:\n        data = json.load(f)\n    documents = [Document(id=str(_), content=doc['content'], metadata={\"document_name\": doc['document_name']}) for _, doc in enumerate(data) if doc['content']]\n    return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/__init__.py",
        "content": "```swarmauri/standard/conversations/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/base/__init__.py",
        "content": "```swarmauri/standard/conversations/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/base/ConversationBase.py",
        "content": "```swarmauri/standard/conversations/base/ConversationBase.py\nfrom abc import ABC\nfrom typing import List, Union\nfrom ....core.messages.IMessage import IMessage\nfrom ....core.conversations.IConversation import IConversation\n\nclass ConversationBase(IConversation, ABC):\n    \"\"\"\n    Concrete implementation of IConversation, managing conversation history and operations.\n    \"\"\"\n    \n    def __init__(self):\n        self._history: List[IMessage] = []\n\n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        return self._history\n    \n    def add_message(self, message: IMessage):\n        self._history.append(message)\n\n    def get_last(self) -> Union[IMessage, None]:\n        if self._history:\n            return self._history[-1]\n        return None\n\n    def clear_history(self):\n        self._history.clear()\n\n    def as_dict(self) -> List[dict]:\n        return [message.as_dict() for message in self.history] # This must utilize the public self.history\n    \n    \n    # def __repr__(self):\n        # return repr([message.as_dict() for message in self._history])\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/base/SystemContextBase.py",
        "content": "```swarmauri/standard/conversations/base/SystemContextBase.py\nfrom abc import ABC\nfrom typing import Optional, Union\nfrom swarmauri.core.conversations.ISystemContext import ISystemContext\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\nfrom swarmauri.standard.conversations.base.ConversationBase import ConversationBase\n\nclass SystemContextBase(ConversationBase, ISystemContext, ABC):\n    def __init__(self, *args, system_message_content: Optional[SystemMessage] = None):\n        ConversationBase.__init__(self)\n        # Automatically handle both string and SystemMessage types for initializing system context\n        self._system_context = None  # Initialize with None\n        if system_message_content:\n            self.system_context = system_message_content\n    \n    @property\n    def system_context(self) -> Union[SystemMessage, None]:\n        \"\"\"Get the system context message. Raises an error if it's not set.\"\"\"\n        if self._system_context is None:\n            raise ValueError(\"System context has not been set.\")\n        return self._system_context\n    \n    @system_context.setter\n    def system_context(self, new_system_message: Union[SystemMessage, str]) -> None:\n        \"\"\"\n        Set a new system context message. The new system message can be a string or \n        an instance of SystemMessage. If it's a string, it converts it to a SystemMessage.\n        \"\"\"\n        if isinstance(new_system_message, SystemMessage):\n            self._system_context = new_system_message\n        elif isinstance(new_system_message, str):\n            self._system_context = SystemMessage(new_system_message)\n        else:\n            raise ValueError(\"System context must be a string or a SystemMessage instance.\")\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/__init__.py",
        "content": "```swarmauri/standard/conversations/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/LimitedSizeConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/LimitedSizeConversation.py\nfrom ..base.ConversationBase import ConversationBase\nfrom ....core.messages.IMessage import IMessage\nfrom ....core.conversations.IMaxSize import IMaxSize\n\nclass LimitedSizeConversation(ConversationBase, IMaxSize):\n    def __init__(self, max_size: int):\n        super().__init__()\n        self._max_size = max_size\n        \n    @property\n    def max_size(self) -> int:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        return self._max_size\n    \n    @max_size.setter\n    def max_size(self, new_max_size: int) -> int:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        if new_max_size > 0:\n            self._max_size = int\n        else:\n            raise ValueError('Cannot set conversation size to 0.')\n\n\n    def add_message(self, message: IMessage):\n        \"\"\"Adds a message and ensures the conversation does not exceed the max size.\"\"\"\n        super().add_message(message)\n        self._enforce_max_size_limit()\n\n    def _enforce_max_size_limit(self):\n        \"\"\"\n        Enforces the maximum size limit of the conversation history.\n        If the current history size exceeds the maximum size, the oldest messages are removed.\n        \"\"\"\n        while len(self._history) > self.max_size:\n            self._history.pop(0)\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/SimpleConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/SimpleConversation.py\nfrom typing import List, Union\nfrom ....core.messages.IMessage import IMessage\nfrom ..base.ConversationBase import ConversationBase\n\nclass SimpleConversation(ConversationBase):\n    \"\"\"\n    Concrete implementation of IConversation, managing conversation history and operations.\n    \"\"\"\n    \n    def __init__(self):\n       super().__init__()\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/LimitedSystemContextConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/LimitedSystemContextConversation.py\nfrom typing import Optional, Union, List\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.core.conversations.IMaxSize import IMaxSize\nfrom swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\n\nclass LimitedSystemContextConversation(SystemContextBase, IMaxSize):\n    def __init__(self, max_size: int, system_message_content: Optional[SystemMessage] = None):\n        \"\"\"\n        Initializes the conversation with a system context message and a maximum history size.\n        \n        Parameters:\n            max_size (int): The maximum number of messages allowed in the conversation history.\n            system_message_content (Optional[str], optional): The initial system message content. Can be a string.\n        \"\"\"\n        SystemContextBase.__init__(self, system_message_content=system_message_content if system_message_content else \"\")  # Initialize SystemContext with a SystemMessage\n        self._max_size = max_size  # Set the maximum size\n    \n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        \n        \n        res = [] \n        res.append(self.system_context)\n        res.extend(self._history)\n        return res\n        \n        \n    @property\n    def max_size(self) -> int:\n        \"\"\"\n        Provides access to the max_size property.\n        \"\"\"\n        return self._max_size\n    \n    @max_size.setter\n    def max_size(self, new_max_size: int) -> None:\n        \"\"\"\n        Sets a new maximum size for the conversation history.\n        \"\"\"\n        if new_max_size <= 0:\n            raise ValueError(\"max_size must be greater than 0.\")\n        self._max_size = new_max_size\n\n    def add_message(self, message: IMessage):\n        \"\"\"\n        Adds a message to the conversation history and ensures history does not exceed the max size.\n        \"\"\"\n        if isinstance(message, SystemMessage):\n            raise ValueError(f\"System context cannot be set through this method on {self.__class_name__}.\")\n        else:\n            super().add_message(message)\n        self._enforce_max_size_limit()\n        \n    def _enforce_max_size_limit(self):\n        \"\"\"\n        Remove messages from the beginning of the conversation history if the limit is exceeded.\n        \"\"\"\n        while len(self._history) + 1 > self._max_size:\n            self._history.pop(0)\n\n    @property\n    def system_context(self) -> Union[SystemMessage, None]:\n        \"\"\"Get the system context message. Raises an error if it's not set.\"\"\"\n        if self._system_context is None:\n            raise ValueError(\"System context has not been set.\")\n        return self._system_context\n\n\n    @system_context.setter\n    def system_context(self, new_system_message: Union[SystemMessage, str]) -> None:\n        \"\"\"\n        Set a new system context message. The new system message can be a string or \n        an instance of SystemMessage. If it's a string, it converts it to a SystemMessage.\n        \"\"\"\n        if isinstance(new_system_message, SystemMessage):\n            self._system_context = new_system_message\n        elif isinstance(new_system_message, str):\n            self._system_context = SystemMessage(new_system_message)\n        else:\n            raise ValueError(\"System context must be a string or a SystemMessage instance.\")\n            \n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/SharedConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/SharedConversation.py\nimport inspect\nfrom threading import Lock\nfrom typing import Optional, Dict, List, Tuple\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.standard.conversations.base.ConversationBase import ConversationBase\nfrom swarmauri.standard.messages.concrete.HumanMessage import HumanMessage\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\n\nclass SharedConversation(ConversationBase):\n    \"\"\"\n    A thread-safe conversation class that supports individual system contexts for each SwarmAgent.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self._lock = Lock()  # A lock to ensure thread safety\n        self._agent_system_contexts: Dict[str, SystemMessage] = {}  # Store system contexts for each agent\n        self._history: List[Tuple[str, IMessage]] = []  # Stores tuples of (sender_id, IMessage)\n\n\n    @property\n    def history(self):\n        history = []\n        for each in self._history:\n            history.append((each[0], each[1]))\n        return history\n\n    def add_message(self, message: IMessage, sender_id: str):\n        with self._lock:\n            self._history.append((sender_id, message))\n\n    def reset_messages(self) -> None:\n        self._history = []\n        \n\n    def _get_caller_name(self) -> Optional[str]:\n        for frame_info in inspect.stack():\n            # Check each frame for an instance with a 'name' attribute in its local variables\n            local_variables = frame_info.frame.f_locals\n            for var_name, var_value in local_variables.items():\n                if hasattr(var_value, 'name'):\n                    # Found an instance with a 'name' attribute. Return its value.\n                    return getattr(var_value, 'name')\n        # No suitable caller found\n        return None\n\n    def as_dict(self) -> List[Dict]:\n        caller_name = self._get_caller_name()\n        history = []\n\n        with self._lock:\n            # If Caller is not one of the agents, then give history\n            if caller_name not in self._agent_system_contexts.keys():\n                for sender_id, message in self._history:\n                    history.append((sender_id, message.as_dict()))\n                \n                \n            else:\n                system_context = self.get_system_context(caller_name)\n                #print(caller_name, system_context, type(system_context))\n                if type(system_context) == str:\n                    history.append(SystemMessage(system_context).as_dict())\n                else:\n                    history.append(system_context.as_dict())\n                    \n                for sender_id, message in self._history:\n                    #print(caller_name, sender_id, message, type(message))\n                    if sender_id == caller_name:\n                        if message.__class__.__name__ == 'AgentMessage' or 'FunctionMessage':\n                            # The caller is the sender; treat as AgentMessage\n                            history.append(message.as_dict())\n                            \n                            # Print to see content that is empty.\n                            #if not message.content:\n                                #print('\\n\\t\\t\\t=>', message, message.content)\n                    else:\n                        if message.content:\n                            # The caller is not the sender; treat as HumanMessage\n                            history.append(HumanMessage(message.content).as_dict())\n        return history\n    \n    def get_last(self) -> IMessage:\n        with self._lock:\n            return super().get_last()\n\n\n    def clear_history(self):\n        with self._lock:\n            super().clear_history()\n\n\n        \n\n    def set_system_context(self, agent_id: str, context: SystemMessage):\n        \"\"\"\n        Sets the system context for a specific agent.\n\n        Args:\n            agent_id (str): Unique identifier for the agent.\n            context (SystemMessage): The context message to be set for the agent.\n        \"\"\"\n        with self._lock:\n            self._agent_system_contexts[agent_id] = context\n\n    def get_system_context(self, agent_id: str) -> Optional[SystemMessage]:\n        \"\"\"\n        Retrieves the system context for a specific agent.\n\n        Args:\n            agent_id (str): Unique identifier for the agent.\n\n        Returns:\n            Optional[SystemMessage]: The context message of the agent, or None if not found.\n        \"\"\"\n        return self._agent_system_contexts.get(agent_id, None)\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/__init__.py",
        "content": "```swarmauri/standard/documents/__init__.py\nfrom .concrete import *\nfrom .base import *\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/base/__init__.py",
        "content": "```swarmauri/standard/documents/base/__init__.py\nfrom .DocumentBase import DocumentBase\nfrom .EmbeddedBase import EmbeddedBase\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/base/EmbeddedBase.py",
        "content": "```swarmauri/standard/documents/base/EmbeddedBase.py\nfrom abc import ABC\nfrom typing import List, Any, Optional\nimport importlib\nfrom swarmauri.core.documents.IEmbed import IEmbed\nfrom swarmauri.standard.vectors.base.VectorBase import VectorBase\nfrom swarmauri.standard.documents.base.DocumentBase import DocumentBase\n\nclass EmbeddedBase(DocumentBase, IEmbed, ABC):\n    def __init__(self, id: str = \"\", content: str = \"\", metadata: dict = {}, embedding: VectorBase = None):\n        DocumentBase.__init__(self, id, content, metadata)\n        self._embedding = embedding\n        \n    @property\n    def embedding(self) -> VectorBase:\n        return self._embedding\n\n    @embedding.setter\n    def embedding(self, value: VectorBase) -> None:\n        self._embedding = value\n\n    def __str__(self):\n        return f\"EmbeddedDocument ID: {self.id}, Content: {self.content}, Metadata: {self.metadata}, embedding={self.embedding}\"\n\n    def __repr__(self):\n        return f\"EmbeddedDocument(id={self.id}, content={self.content}, metadata={self.metadata}, embedding={self.embedding})\"\n\n    def to_dict(self):\n        document_dict = super().to_dict()\n        document_dict.update({\n            \"type\": self.__class__.__name__,\n            \"embedding\": self.embedding.to_dict() if hasattr(self.embedding, 'to_dict') else self.embedding\n            })\n\n        return document_dict\n\n    @classmethod\n    def from_dict(cls, data):\n        vector_data = data.pop(\"embedding\")\n        if vector_data:\n            vector_type = vector_data.pop('type')\n            if vector_type:\n                module = importlib.import_module(f\"swarmauri.standard.vectors.concrete.{vector_type}\")\n                vector_class = getattr(module, vector_type)\n                vector = vector_class.from_dict(vector_data)\n            else:\n                vector = None\n        else:\n            vector = None \n        return cls(**data, embedding=vector)\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/base/DocumentBase.py",
        "content": "```swarmauri/standard/documents/base/DocumentBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass DocumentBase(IDocument, ABC):\n    \n    def __init__(self, id: str = \"\", content: str = \"\", metadata: dict = {}):\n        self._id = id\n        self._content = content\n        self._metadata = metadata\n\n    @property\n    def id(self) -> str:\n        \"\"\"\n        Get the document's ID.\n        \"\"\"\n        return self._id\n\n    @id.setter\n    def id(self, value: str) -> None:\n        \"\"\"\n        Set the document's ID.\n        \"\"\"\n        self._id = value\n\n    @property\n    def content(self) -> str:\n        \"\"\"\n        Get the document's content.\n        \"\"\"\n        return self._content\n\n    @content.setter\n    def content(self, value: str) -> None:\n        \"\"\"\n        Set the document's content.\n        \"\"\"\n        if value:\n            self._content = value\n        else:\n            raise ValueError('Cannot create a document with no content.')\n\n    @property\n    def metadata(self) -> Dict:\n        \"\"\"\n        Get the document's metadata.\n        \"\"\"\n        return self._metadata\n\n    @metadata.setter\n    def metadata(self, value: Dict) -> None:\n        \"\"\"\n        Set the document's metadata.\n        \"\"\"\n        self._metadata = value\n\n    def __str__(self):\n        return f\"Document ID: {self.id}, Content: {self.content}, Metadata: {self.metadata}\"\n\n    def __repr__(self):\n        return f\"Document(id={self.id}, content={self.content}, metadata={self.metadata})\"\n\n    def to_dict(self):\n        return {'type': self.__class__.__name__,\n                'id': self.id, \n                'content': self.content, \n                'metadata': self.metadata}\n      \n    @classmethod\n    def from_dict(cls, data):\n        data.pop(\"type\", None)\n        return cls(**data)\n\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/concrete/__init__.py",
        "content": "```swarmauri/standard/documents/concrete/__init__.py\nfrom .Document import Document\nfrom .EmbeddedDocument import EmbeddedDocument\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/concrete/EmbeddedDocument.py",
        "content": "```swarmauri/standard/documents/concrete/EmbeddedDocument.py\nfrom typing import Optional, Any\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.documents.base.EmbeddedBase import EmbeddedBase\n\nclass EmbeddedDocument(EmbeddedBase):\n    def __init__(self, id,  content, metadata, embedding: Optional[IVector] = None):\n        EmbeddedBase.__init__(self, id=id, content=content, metadata=metadata, embedding=embedding)\n\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/concrete/Document.py",
        "content": "```swarmauri/standard/documents/concrete/Document.py\nfrom swarmauri.standard.documents.base.DocumentBase import DocumentBase\n\nclass Document(DocumentBase):\n    pass\n    \n        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/__init__.py",
        "content": "```swarmauri/standard/messages/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/base/__init__.py",
        "content": "```swarmauri/standard/messages/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/base/MessageBase.py",
        "content": "```swarmauri/standard/messages/base/MessageBase.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.messages.IMessage import IMessage\n\nclass MessageBase(IMessage, ABC):\n    \n    @abstractmethod\n    def __init__(self, role: str, content: str):\n        self._role = role\n        self._content = content\n    \n    @property\n    def role(self) -> str:\n        return self._role\n    \n    @property\n    def content(self) -> str:\n        return self._content\n\n    \n    def as_dict(self) -> dict:\n        \"\"\"\n        Dynamically return a dictionary representation of the object,\n        including all properties.\n        \"\"\"\n        result_dict = {}\n        # Iterate over all attributes\n        for attr in dir(self):\n            # Skip private attributes and anything not considered a property\n            if attr.startswith(\"_\") or callable(getattr(self, attr)):\n                continue\n            result_dict[attr] = getattr(self, attr)\n            \n        return result_dict\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Return the string representation of the ConcreteMessage.\n        \"\"\"\n        return f\"{self.__class__.__name__}(role='{self.role}')\"\n    \n    def __getattr__(self, name):\n        \"\"\"\n        Return the value of the named attribute of the instance.\n        \"\"\"\n        try:\n            return self.__dict__[name]\n        except KeyError:\n            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n\n    \n    def __setattr__(self, name, value):\n        \"\"\"\n        Set the value of the named attribute of the instance.\n        \"\"\"\n        self.__dict__[name] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/__init__.py",
        "content": "```swarmauri/standard/messages/concrete/__init__.py\nfrom .HumanMessage import HumanMessage\nfrom .AgentMessage import AgentMessage\nfrom .FunctionMessage import FunctionMessage\nfrom .SystemMessage import SystemMessage\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/AgentMessage.py",
        "content": "```swarmauri/standard/messages/concrete/AgentMessage.py\nfrom typing import Optional, Any\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\n\nclass AgentMessage(MessageBase):\n    def __init__(self, content, tool_calls: Optional[Any] = None):\n        super().__init__(role='assistant', content=content)\n        if tool_calls:\n            self.tool_calls = tool_calls\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/HumanMessage.py",
        "content": "```swarmauri/standard/messages/concrete/HumanMessage.py\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\nclass HumanMessage(MessageBase):\n    \"\"\"\n    Represents a message created by a human user.\n\n    Extends the `Message` class to specifically represent messages input by human users in a conversational\n    interface. It contains the message content and assigns the type \"HumanMessage\" to distinguish it from\n    other types of messages.\n    \"\"\"\n\n    def __init__(self, content, name=None):\n        \"\"\"\n        Initializes a new instance of HumanMessage with specified content.\n\n        Args:\n            content (str): The text content of the human-created message.\n            name (str, optional): The name of the human sender.\n        \"\"\"\n        super().__init__(role='user', content=content)\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/FunctionMessage.py",
        "content": "```swarmauri/standard/messages/concrete/FunctionMessage.py\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\n\nclass FunctionMessage(MessageBase):\n    \"\"\"\n    Represents a message created by a human user.\n\n    This class extends the `Message` class to specifically represent messages that\n    are input by human users in a conversational interface. It contains the message\n    content and assigns the type \"HumanMessage\" to distinguish it from other types\n    of messages.\n\n    Attributes:\n        content (str): The text content of the message.\n\n    Methods:\n        display: Returns a dictionary representation of the message for display,\n                 tagging it with the role \"user\".\n    \"\"\"\n\n    def __init__(self, content, name, tool_call_id):\n        super().__init__(role='tool', content=content)\n        self.name = name\n        self.tool_call_id = tool_call_id\n    \n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/SystemMessage.py",
        "content": "```swarmauri/standard/messages/concrete/SystemMessage.py\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\nclass SystemMessage(MessageBase):\n    \"\"\"\n    SystemMessage class represents a message generated by the system. \n    \n    This type of message is used to communicate system-level information such as \n    errors, notifications, or updates to the user. Inherits from the Message base class.\n    \n    Attributes:\n        content (str): The content of the system message.\n    \"\"\"\n    \n    def __init__(self, content):\n        super().__init__(role='system', content=content)\n    \n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/__init__.py",
        "content": "```swarmauri/standard/parsers/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/base/__init__.py",
        "content": "```swarmauri/standard/parsers/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/__init__.py",
        "content": "```swarmauri/standard/parsers/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/CSVParser.py",
        "content": "```swarmauri/standard/parsers/concrete/CSVParser.py\nimport csv\nfrom io import StringIO\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass CSVParser(IParser):\n    \"\"\"\n    Concrete implementation of IParser for parsing CSV formatted text into Document instances.\n\n    The parser can handle input as a CSV formatted string or from a file, with each row\n    represented as a separate Document. Assumes the first row is the header which will\n    be used as keys for document metadata.\n    \"\"\"\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the given CSV data into a list of Document instances.\n\n        Parameters:\n        - data (Union[str, Any]): The input data to parse, either as a CSV string or file path.\n\n        Returns:\n        - List[IDocument]: A list of documents parsed from the CSV data.\n        \"\"\"\n        # Prepare an in-memory string buffer if the data is provided as a string\n        if isinstance(data, str):\n            data_stream = StringIO(data)\n        else:\n            raise ValueError(\"Data provided is not a valid CSV string\")\n\n        # Create a list to hold the parsed documents\n        documents: List[IDocument] = []\n\n        # Read CSV content row by row\n        reader = csv.DictReader(data_stream)\n        for row in reader:\n            # Each row represents a document, where the column headers are metadata fields\n            document = Document(doc_id=row.get('id', None), \n                                        content=row.get('content', ''), \n                                        metadata=row)\n            documents.append(document)\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/EntityRecognitionParser.py",
        "content": "```swarmauri/standard/parsers/concrete/EntityRecognitionParser.py\nimport spacy\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass EntityRecognitionParser(IParser):\n    \"\"\"\n    EntityRecognitionParser leverages NER capabilities to parse text and \n    extract entities with their respective tags such as PERSON, LOCATION, ORGANIZATION, etc.\n    \"\"\"\n\n    def __init__(self):\n        # Load a SpaCy model. The small model is used for demonstration; larger models provide improved accuracy.\n        self.nlp = spacy.load(\"en_core_web_sm\")\n    \n    def parse(self, text: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input text, identifies entities, and returns a list of documents with entities tagged.\n\n        Parameters:\n        - text (Union[str, Any]): The input text to be parsed and analyzed for entities.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances representing the identified entities in the text.\n        \"\"\"\n        # Ensure the input is a string type before processing\n        if not isinstance(text, str):\n            text = str(text)\n        \n        # Apply the NER model\n        doc = self.nlp(text)\n\n        # Compile identified entities into documents\n        entities_docs = []\n        for ent in doc.ents:\n            # Create a document for each entity with metadata carrying entity type\n            entity_doc = Document(doc_id=ent.text, content=ent.text, metadata={\"entity_type\": ent.label_})\n            entities_docs.append(entity_doc)\n        \n        return entities_docs\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/HtmlTagStripParser.py",
        "content": "```swarmauri/standard/parsers/concrete/HtmlTagStripParser.py\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\nimport html\nimport re\n\nclass HTMLTagStripParser(IParser):\n    \"\"\"\n    A concrete parser that removes HTML tags and unescapes HTML content,\n    leaving plain text.\n    \"\"\"\n\n    def parse(self, data):\n        \"\"\"\n        Strips HTML tags from input data and unescapes HTML content.\n        \n        Args:\n            data (str): The HTML content to be parsed.\n        \n        Returns:\n            List[IDocument]: A list containing a single IDocument instance of the stripped text.\n        \"\"\"\n\n        # Ensure that input is a string\n        if not isinstance(data, str):\n            raise ValueError(\"HTMLTagStripParser expects input data to be of type str.\")\n        \n        # Remove HTML tags\n        text = re.sub('<[^<]+?>', '', data)  # Matches anything in < > and replaces it with empty string\n        \n        # Unescape HTML entities\n        text = html.unescape(text)\n\n        # Wrap the cleaned text into a Document and return it in a list\n        document = Document(doc_id=\"1\", content=text, metadata={\"original_length\": len(data)})\n        \n        return [document]\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/KeywordExtractorParser.py",
        "content": "```swarmauri/standard/parsers/concrete/KeywordExtractorParser.py\nimport yake\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass KeywordExtractorParser(IParser):\n    \"\"\"\n    Extracts keywords from text using the YAKE keyword extraction library.\n    \"\"\"\n\n    def __init__(self, lang: str = 'en', num_keywords: int = 10):\n        \"\"\"\n        Initialize the keyword extractor with specified language and number of keywords.\n\n        Parameters:\n        - lang (str): The language of the text for keyword extraction. Default is 'en' for English.\n        - num_keywords (int): The number of top keywords to extract. Default is 10.\n        \"\"\"\n        self.lang = lang\n        self.num_keywords = num_keywords\n        # Initialize YAKE extractor with specified parameters\n        self.kw_extractor = yake.KeywordExtractor(lan=lang, n=3, dedupLim=0.9, dedupFunc='seqm', windowsSize=1, top=num_keywords, features=None)\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Extract keywords from input text and return as list of IDocument instances containing keyword information.\n\n        Parameters:\n        - data (Union[str, Any]): The input text from which to extract keywords.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances, each containing information about an extracted keyword.\n        \"\"\"\n        # Ensure data is in string format for analysis\n        text = str(data) if not isinstance(data, str) else data\n\n        # Extract keywords using YAKE\n        keywords = self.kw_extractor.extract_keywords(text)\n\n        # Create Document instances for each keyword\n        documents = [Document(doc_id=str(index), content=keyword, metadata={\"score\": score}) for index, (keyword, score) in enumerate(keywords)]\n        \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/MarkdownParser.py",
        "content": "```swarmauri/standard/parsers/concrete/MarkdownParser.py\nimport re\nfrom markdown import markdown\nfrom bs4 import BeautifulSoup\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass MarkdownParser(IParser):\n    \"\"\"\n    A concrete implementation of the IParser interface that parses Markdown text.\n    \n    This parser takes Markdown formatted text, converts it to HTML using Python's\n    markdown library, and then uses BeautifulSoup to extract plain text content. The\n    resulting plain text is then wrapped into IDocument instances.\n    \"\"\"\n    \n    def parse(self, data: str) -> list[IDocument]:\n        \"\"\"\n        Parses the input Markdown data into a list of IDocument instances.\n        \n        Parameters:\n        - data (str): The input Markdown formatted text to be parsed.\n        \n        Returns:\n        - list[IDocument]: A list containing a single IDocument instance with the parsed text content.\n        \"\"\"\n        # Convert Markdown to HTML\n        html_content = markdown(data)\n        \n        # Use BeautifulSoup to extract text content from HTML\n        soup = BeautifulSoup(html_content, features=\"html.parser\")\n        plain_text = soup.get_text(separator=\" \", strip=True)\n        \n        # Generate a document ID\n        doc_id = \"1\"  # For this implementation, a simple fixed ID is used. \n                      # A more complex system might generate unique IDs for each piece of text.\n\n        # Create and return a list containing the single extracted plain text document\n        document = Document(doc_id=doc_id, content=plain_text, metadata={\"source_format\": \"markdown\"})\n        return [document]\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/OpenAPISpecParser.py",
        "content": "```swarmauri/standard/parsers/concrete/OpenAPISpecParser.py\nfrom typing import List, Union, Any\nimport yaml\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass OpenAPISpecParser(IParser):\n    \"\"\"\n    A parser that processes OpenAPI Specification files (YAML or JSON format)\n    and extracts information into structured Document instances. \n    This is useful for building documentation, APIs inventory, or analyzing the API specification.\n    \"\"\"\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses an OpenAPI Specification from a YAML or JSON string into a list of Document instances.\n\n        Parameters:\n        - data (Union[str, Any]): The OpenAPI specification in YAML or JSON format as a string.\n\n        Returns:\n        - List[IDocument]: A list of Document instances representing the parsed information.\n        \"\"\"\n        try:\n            # Load the OpenAPI spec into a Python dictionary\n            spec_dict = yaml.safe_load(data)\n        except yaml.YAMLError as e:\n            raise ValueError(f\"Failed to parse the OpenAPI specification: {e}\")\n        \n        documents = []\n        # Iterate over paths in the OpenAPI spec to extract endpoint information\n        for path, path_item in spec_dict.get(\"paths\", {}).items():\n            for method, operation in path_item.items():\n                # Create a Document instance for each operation\n                doc_id = f\"{path}_{method}\"\n                content = yaml.dump(operation)\n                metadata = {\n                    \"path\": path,\n                    \"method\": method.upper(),\n                    \"operationId\": operation.get(\"operationId\", \"\")\n                }\n                document = Document(doc_id=doc_id, content=content, metadata=metadata)\n                documents.append(document)\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/PhoneNumberExtractorParser.py",
        "content": "```swarmauri/standard/parsers/concrete/PhoneNumberExtractorParser.py\nimport re\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass PhoneNumberExtractorParser(IParser):\n    \"\"\"\n    A parser that extracts phone numbers from the input text.\n    Utilizes regular expressions to identify phone numbers in various formats.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the PhoneNumberExtractorParser.\n        \"\"\"\n        super().__init__()\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input data, looking for phone numbers employing a regular expression.\n        Each phone number found is contained in a separate IDocument instance.\n\n        Parameters:\n        - data (Union[str, Any]): The input text to be parsed for phone numbers.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances, each containing a phone number.\n        \"\"\"\n        # Define a regular expression for phone numbers.\n        # This is a simple example and might not capture all phone number formats accurately.\n        phone_regex = r'\\+?\\d[\\d -]{8,}\\d'\n\n        # Find all occurrences of phone numbers in the text\n        phone_numbers = re.findall(phone_regex, str(data))\n\n        # Create a new IDocument for each phone number found\n        documents = [Document(doc_id=str(index), content=phone_number, metadata={}) for index, phone_number in enumerate(phone_numbers)]\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/PythonParser.py",
        "content": "```swarmauri/standard/parsers/concrete/PythonParser.py\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\nimport ast\nimport uuid\n\nclass PythonParser(IParser):\n    \"\"\"\n    A parser that processes Python source code to extract structural elements\n    such as functions, classes, and their docstrings.\n    \n    This parser utilizes the `ast` module to parse the Python code into an abstract syntax tree (AST)\n    and then walks the tree to extract relevant information.\n    \"\"\"\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the given Python source code to extract structural elements.\n\n        Args:\n            data (Union[str, Any]): The input Python source code as a string.\n\n        Returns:\n            List[IDocument]: A list of IDocument objects, each representing a structural element \n                             extracted from the code along with its metadata.\n        \"\"\"\n        if not isinstance(data, str):\n            raise ValueError(\"PythonParser expects a string input.\")\n        \n        documents = []\n        tree = ast.parse(data)\n        \n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef) or isinstance(node, ast.ClassDef):\n                element_name = node.name\n                docstring = ast.get_docstring(node)\n                \n                # Generate a unique ID for each element\n                doc_id = str(uuid.uuid4())\n                \n                # Create a metadata dictionary\n                metadata = {\n                    \"type\": \"function\" if isinstance(node, ast.FunctionDef) else \"class\",\n                    \"name\": element_name,\n                    \"docstring\": docstring\n                }\n                \n                # Create a Document for each structural element\n                document = Document(doc_id=doc_id, content=docstring, metadata=metadata)\n                documents.append(document)\n                \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/RegExParser.py",
        "content": "```swarmauri/standard/parsers/concrete/RegExParser.py\nimport re\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass RegExParser(IParser):\n    \"\"\"\n    A parser that uses a regular expression to extract information from text.\n    \"\"\"\n\n    def __init__(self, pattern: str):\n        \"\"\"\n        Initializes the RegExParser with a specific regular expression pattern.\n\n        Parameters:\n        - pattern (str): The regular expression pattern used for parsing the text.\n        \"\"\"\n        self.pattern = pattern\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input data using the specified regular expression pattern and\n        returns a list of IDocument instances containing the extracted information.\n\n        Parameters:\n        - data (Union[str, Any]): The input data to be parsed. It can be a string or any format \n                                   that the concrete implementation can handle.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances containing the parsed information.\n        \"\"\"\n        # Ensure data is a string\n        if not isinstance(data, str):\n            data = str(data)\n\n        # Use the regular expression pattern to find all matches in the text\n        matches = re.findall(self.pattern, data)\n\n        # Create a Document for each match and collect them into a list\n        documents = [Document(doc_id=str(i+1), content=match, metadata={}) for i, match in enumerate(matches)]\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/TextBlobNounParser.py",
        "content": "```swarmauri/standard/parsers/concrete/TextBlobNounParser.py\nfrom typing import List, Union, Any\nfrom textblob import TextBlob\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass TextBlobNounParser(IParser):\n    \"\"\"\n    A concrete implementation of IParser using TextBlob for Natural Language Processing tasks.\n    \n    This parser leverages TextBlob's functionalities such as noun phrase extraction, \n    sentiment analysis, classification, language translation, and more for parsing texts.\n    \"\"\"\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input data using TextBlob to perform basic NLP tasks \n        and returns a list of documents with the parsed information.\n        \n        Parameters:\n        - data (Union[str, Any]): The input data to parse, expected to be text data for this parser.\n        \n        Returns:\n        - List[IDocument]: A list of documents with metadata generated from the parsing process.\n        \"\"\"\n        # Ensure the data is a string\n        if not isinstance(data, str):\n            raise ValueError(\"TextBlobParser expects a string as input data.\")\n        \n        # Use TextBlob for NLP tasks\n        blob = TextBlob(data)\n        \n        # Extracts noun phrases to demonstrate one of TextBlob's capabilities. \n        # In practice, this parser could be expanded to include more sophisticated processing.\n        noun_phrases = list(blob.noun_phrases)\n        \n        # Example: Wrap the extracted noun phrases into an IDocument instance\n        # In real scenarios, you might want to include more details, like sentiment, POS tags, etc.\n        document = Document(doc_id=\"0\", content=data, metadata={\"noun_phrases\": noun_phrases})\n        \n        return [document]\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/TextBlobSentenceParser.py",
        "content": "```swarmauri/standard/parsers/concrete/TextBlobSentenceParser.py\nfrom textblob import TextBlob\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\nfrom typing import List, Union, Any\n\nclass TextBlobParser(IParser):\n    \"\"\"\n    A parser that leverages TextBlob to break text into sentences.\n\n    This parser uses the natural language processing capabilities of TextBlob\n    to accurately identify sentence boundaries within large blocks of text.\n    \"\"\"\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input text into sentence-based document chunks using TextBlob.\n\n        Args:\n            data (Union[str, Any]): The input text to be parsed.\n\n        Returns:\n            List[IDocument]: A list of IDocument instances, each representing a sentence.\n        \"\"\"\n        # Ensure the input is a string\n        if not isinstance(data, str):\n            data = str(data)\n\n        # Utilize TextBlob for sentence tokenization\n        blob = TextBlob(data)\n        sentences = blob.sentences\n\n        # Create a document instance for each sentence\n        documents = [\n            Document(doc_id=str(index), content=str(sentence), metadata={'parser': 'TextBlobParser'})\n            for index, sentence in enumerate(sentences)\n        ]\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/TFIDFParser.py",
        "content": "```swarmauri/standard/parsers/concrete/TFIDFParser.py\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom swarmauri.core.parsers.IParser import IParser\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.Document import Document\n\nclass TFIDFParser(IParser):\n    def __init__(self):\n        self.vectorizer = TfidfVectorizer()\n        super().__init__()\n\n    def parse(self, data):\n        # Assuming `data` is a list of strings (documents)\n        tfidf_matrix = self.vectorizer.fit_transform(data)\n        # Depending on how you want to use the output, you could return Document objects\n        # For demonstration, let's return a list of IDocument with vectorized content\n        documents = [Document(doc_id=str(i), content=vector, metadata={}) for i, vector in enumerate(tfidf_matrix.toarray())]\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/URLExtractorParser.py",
        "content": "```swarmauri/standard/parsers/concrete/URLExtractorParser.py\nfrom typing import List, Union, Any\nfrom urllib.parse import urlparse\nimport re\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass URLExtractorParser(IParser):\n    \"\"\"\n    A concrete implementation of IParser that extracts URLs from text.\n    \n    This parser scans the input text for any URLs and creates separate\n    documents for each extracted URL. It utilizes regular expressions\n    to identify URLs within the given text.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the URLExtractorParser.\n        \"\"\"\n        super().__init__()\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parse input data (string) and extract URLs, each URL is then represented as a document.\n        \n        Parameters:\n        - data (Union[str, Any]): The input data to be parsed for URLs.\n        \n        Returns:\n        - List[IDocument]: A list of documents, each representing an extracted URL.\n        \"\"\"\n        if not isinstance(data, str):\n            raise ValueError(\"URLExtractorParser expects input data to be of type str.\")\n\n        # Regular expression for finding URLs\n        url_regex = r\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\"\n        \n        # Find all matches in the text\n        urls = re.findall(url_regex, data)\n        \n        # Create a document for each extracted URL\n        documents = [Document(doc_id=str(i), content=url, metadata={\"source\": \"URLExtractor\"}) for i, url in enumerate(urls)]\n        \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/XMLParser.py",
        "content": "```swarmauri/standard/parsers/concrete/XMLParser.py\nimport xml.etree.ElementTree as ET\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass XMLParser(IParser):\n    \"\"\"\n    A parser that extracts information from XML data and converts it into IDocument objects.\n    This parser assumes a simple use-case where each targeted XML element represents a separate document.\n    \"\"\"\n\n    def __init__(self, element_tag: str):\n        \"\"\"\n        Initialize the XMLParser with the tag name of the XML elements to be extracted as documents.\n\n        Parameters:\n        - element_tag (str): The tag name of XML elements to parse into documents.\n        \"\"\"\n        self.element_tag = element_tag\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses XML data and converts elements with the specified tag into IDocument instances.\n\n        Parameters:\n        - data (Union[str, Any]): The XML data as a string to be parsed.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances created from the XML elements.\n        \"\"\"\n        if isinstance(data, str):\n            root = ET.fromstring(data)  # Parse the XML string into an ElementTree element\n        else:\n            raise TypeError(\"Data for XMLParser must be a string containing valid XML.\")\n\n        documents = []\n        for element in root.findall(self.element_tag):\n            # Extracting content and metadata from each element\n            content = \"\".join(element.itertext())  # Get text content\n            metadata = {child.tag: child.text for child in element}  # Extract child elements as metadata\n\n            # Create a Document instance for each element\n            doc = Document(doc_id=None, content=content, metadata=metadata)\n            documents.append(doc)\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/BERTEmbeddingParser.py",
        "content": "```swarmauri/standard/parsers/concrete/BERTEmbeddingParser.py\nfrom typing import List, Union, Any\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom swarmauri.core.parsers.IParser import IParser\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.Document import Document\n\nclass BERTEmbeddingParser(IParser):\n    \"\"\"\n    A parser that transforms input text into document embeddings using BERT.\n    \n    This parser tokenizes the input text, passes it through a pre-trained BERT model,\n    and uses the resulting embeddings as the document content.\n    \"\"\"\n\n    def __init__(self, model_name: str = 'bert-base-uncased'):\n        \"\"\"\n        Initializes the BERTEmbeddingParser with a specific BERT model.\n        \n        Parameters:\n        - model_name (str): The name of the pre-trained BERT model to use.\n        \"\"\"\n        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n        self.model = BertModel.from_pretrained(model_name)\n        self.model.eval()  # Set model to evaluation mode\n\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Tokenizes input data and generates embeddings using a BERT model.\n\n        Parameters:\n        - data (Union[str, Any]): Input data, expected to be a single string or batch of strings.\n\n        Returns:\n        - List[IDocument]: A list containing a single IDocument instance with BERT embeddings as content.\n        \"\"\"\n        \n        # Tokenization\n        inputs = self.tokenizer(data, return_tensors='pt', padding=True, truncation=True, max_length=512)\n\n        # Generate embeddings\n        with torch.no_grad():\n            outputs = self.model(**inputs)\n\n        # Use the last hidden state as document embeddings (batch_size, sequence_length, hidden_size)\n        embeddings = outputs.last_hidden_state\n        \n        # Convert to list of numpy arrays\n        embeddings = embeddings.detach().cpu().numpy()\n        \n        # For simplicity, let's consider the mean of embeddings across tokens to represent the document\n        doc_embeddings = embeddings.mean(axis=1)\n        \n        # Creating document object(s)\n        documents = [Document(doc_id=str(i), content=emb, metadata={\"source\": \"BERTEmbeddingParser\"}) for i, emb in enumerate(doc_embeddings)]\n        \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/__init__.py",
        "content": "```swarmauri/standard/prompts/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/base/__init__.py",
        "content": "```swarmauri/standard/prompts/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/__init__.py",
        "content": "```swarmauri/standard/prompts/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/Prompt.py",
        "content": "```swarmauri/standard/prompts/concrete/Prompt.py\nfrom swarmauri.core.prompts.IPrompt import IPrompt\n\nclass Prompt(IPrompt):\n    \"\"\"\n    The ChatPrompt class represents a simple, chat-like prompt system where a \n    message can be set and retrieved as needed. It's particularly useful in \n    applications involving conversational agents, chatbots, or any system that \n    requires dynamic text-based interactions.\n    \"\"\"\n\n    def __init__(self, prompt: str = \"\"):\n        \"\"\"\n        Initializes an instance of ChatPrompt with an optional initial message.\n        \n        Parameters:\n        - message (str, optional): The initial message for the prompt. Defaults to an empty string.\n        \"\"\"\n        self.prompt = prompt\n\n    def __call__(self, prompt):\n        \"\"\"\n        Enables the instance to be callable, allowing direct retrieval of the message. \n        This method facilitates intuitive access to the prompt's message, mimicking callable \n        behavior seen in functional programming paradigms.\n        \n        Returns:\n        - str: The current message stored in the prompt.\n        \"\"\"\n        return self.prompt\n\n    def set_prompt(self, prompt: str):\n        \"\"\"\n        Updates the internal message of the chat prompt. This method provides a way to change \n        the content of the prompt dynamically, reflecting changes in the conversational context \n        or user inputs.\n        \n        Parameters:\n        - message (str): The new message to set for the prompt.\n        \"\"\"\n        self.prompt = prompt\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/PromptTemplate.py",
        "content": "```swarmauri/standard/prompts/concrete/PromptTemplate.py\nfrom typing import Dict, List\nfrom swarmauri.core.prompts.IPrompt import IPrompt\nfrom swarmauri.core.prompts.ITemplate import ITemplate\n\nclass PromptTemplate(IPrompt, ITemplate):\n    \"\"\"\n    A class for generating prompts based on a template and variables.\n    Implements the IPrompt for generating prompts and ITemplate for template manipulation.\n    \"\"\"\n\n    def __init__(self, template: str = \"\", variables: List[Dict[str, str]] = []):\n        self._template = template\n        self._variables_list = variables\n\n    @property\n    def template(self) -> str:\n        \"\"\"\n        Get the current prompt template.\n        \"\"\"\n        return self._template\n\n    @template.setter\n    def template(self, value: str) -> None:\n        \"\"\"\n        Set a new template string for the prompt.\n        \"\"\"\n        self._template = value\n\n    @property\n    def variables(self) -> List[Dict[str, str]]:\n        \"\"\"\n        Get the current set of variables for the template.\n        \"\"\"\n        return self._variables_list \n\n    @variables.setter\n    def variables(self, value: List[Dict[str, str]]) -> None:\n        if not isinstance(value, list):\n            raise ValueError(\"Variables must be a list of dictionaries.\")\n        self._variables_list = value\n\n    def set_template(self, template: str) -> None:\n        \"\"\"\n        Sets or updates the current template string.\n        \"\"\"\n        self._template = template\n\n    def set_variables(self, variables: Dict[str, str]) -> None:\n        \"\"\"\n        Sets or updates the variables to be substituted into the template.\n        \"\"\"\n        self._variables_list = variables\n\n    def generate_prompt(self, variables: List[Dict[str, str]] = None) -> str:\n        variables = variables.pop(0) or (self._variables_list.pop(0) if self._variables_list else {})\n        return self._template.format(**variables)\n\n    def __call__(self, variables: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Generates a prompt using the current template and provided keyword arguments for substitution.\n        \"\"\"\n        return self.generate_prompt(variables)\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/PromptGenerator.py",
        "content": "```swarmauri/standard/prompts/concrete/PromptGenerator.py\nfrom typing import Dict, List, Generator\nfrom swarmauri.core.prompts.IPrompt import IPrompt\nfrom swarmauri.core.prompts.ITemplate import ITemplate\n\n\nclass PromptGenerator(IPrompt, ITemplate):\n    \"\"\"\n    A class that generates prompts based on a template and a list of variable sets.\n    It implements the IPrompt and ITemplate interfaces.\n    \"\"\"\n\n    def __init__(self, template: str = \"\", variables: List[Dict[str, str]] = []):\n        self._template = template\n        self._variables_list = variables\n\n    @property\n    def template(self) -> str:\n        return self._template\n\n    @template.setter\n    def template(self, value: str) -> None:\n        self._template = value\n\n    @property\n    def variables(self) -> List[Dict[str, str]]:\n        return self._variables_list\n\n    @variables.setter\n    def variables(self, value: List[Dict[str, str]]) -> None:\n        if not isinstance(value, list):\n            raise ValueError(\"Expected a list of dictionaries for variables.\")\n        self._variables_list = value\n\n    def set_template(self, template: str) -> None:\n        self._template = template\n\n    def set_variables(self, variables: List[Dict[str, str]]) -> None:\n        self.variables = variables\n\n    def generate_prompt(self, **kwargs) -> str:\n        \"\"\"\n        Generates a prompt using the provided variables if any, \n        else uses the next variables set in the list.\n        \"\"\"\n        variables = kwargs if kwargs else self.variables.pop(0) if self.variables else {}\n        return self._template.format(**variables)\n\n    def __call__(self) -> Generator[str, None, None]:\n        \"\"\"\n        Returns a generator that yields prompts constructed from the template and \n        each set of variables in the variables list.\n        \"\"\"\n        for variables_set in self._variables_list:\n            yield self.generate_prompt(**variables_set)\n        self._variables_list = []  # Reset the list after all prompts have been generated.\n```"
    },
    {
        "document_name": "swarmauri/standard/states/__init__.py",
        "content": "```swarmauri/standard/states/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/states/base/__init__.py",
        "content": "```swarmauri/standard/states/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/states/concrete/__init__.py",
        "content": "```swarmauri/standard/states/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/__init__.py",
        "content": "```swarmauri/standard/swarms/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/base/__init__.py",
        "content": "```swarmauri/standard/swarms/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/base/SwarmComponentBase.py",
        "content": "```swarmauri/standard/swarms/base/SwarmComponentBase.py\nfrom swarmauri.core.swarms.ISwarmComponent import ISwarmComponent\n\nclass SwarmComponentBase(ISwarmComponent):\n    \"\"\"\n    Interface for defining basics of any component within the swarm system.\n    \"\"\"\n    def __init__(self, key: str, name: str, superclass: str, module: str, class_name: str, args=None, kwargs=None):\n        self.key = key\n        self.name = name\n        self.superclass = superclass\n        self.module = module\n        self.class_name = class_name\n        self.args = args or []\n        self.kwargs = kwargs or {}\n    \n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/concrete/__init__.py",
        "content": "```swarmauri/standard/swarms/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/concrete/SimpleSwarmFactory.py",
        "content": "```swarmauri/standard/swarms/concrete/SimpleSwarmFactory.py\nimport json\nimport pickle\nfrom typing import List\nfrom swarmauri.core.chains.ISwarmFactory import (\n    ISwarmFactory , \n    CallableChainItem, \n    AgentDefinition, \n    FunctionDefinition\n)\nclass SimpleSwarmFactory(ISwarmFactory):\n    def __init__(self):\n        self.swarms = []\n        self.callable_chains = []\n\n    def create_swarm(self, agents=[]):\n        swarm = {\"agents\": agents}\n        self.swarms.append(swarm)\n        return swarm\n\n    def create_agent(self, agent_definition: AgentDefinition):\n        # For simplicity, agents are stored in a list\n        # Real-world usage might involve more sophisticated management and instantiation based on type and configuration\n        agent = {\"definition\": agent_definition._asdict()}\n        self.agents.append(agent)\n        return agent\n\n    def create_callable_chain(self, chain_definition: List[CallableChainItem]):\n        chain = {\"definition\": [item._asdict() for item in chain_definition]}\n        self.callable_chains.append(chain)\n        return chain\n\n    def register_function(self, function_definition: FunctionDefinition):\n        if function_definition.identifier in self.functions:\n            raise ValueError(f\"Function {function_definition.identifier} is already registered.\")\n        \n        self.functions[function_definition.identifier] = function_definition\n    \n    def export_configuration(self, format_type: str = 'json'):\n        # Now exporting both swarms and callable chains\n        config = {\"swarms\": self.swarms, \"callable_chains\": self.callable_chains}\n        if format_type == \"json\":\n            return json.dumps(config)\n        elif format_type == \"pickle\":\n            return pickle.dumps(config)\n\n    def load_configuration(self, config_data, format_type: str = 'json'):\n        # Loading both swarms and callable chains\n        config = json.loads(config_data) if format_type == \"json\" else pickle.loads(config_data)\n        self.swarms = config.get(\"swarms\", [])\n        self.callable_chains = config.get(\"callable_chains\", [])\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/__init__.py",
        "content": "```swarmauri/standard/toolkits/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/base/__init__.py",
        "content": "```swarmauri/standard/toolkits/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/base/ToolkitBase.py",
        "content": "```swarmauri/standard/toolkits/base/ToolkitBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nfrom ....core.toolkits.IToolkit import IToolkit\nfrom ....core.tools.ITool import ITool  \n\nclass ToolkitBase(IToolkit, ABC):\n    \"\"\"\n    A class representing a toolkit used by Swarm Agents.\n    Tools are maintained in a dictionary keyed by the tool's name.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, initial_tools: Dict[str, ITool] = None):\n        \"\"\"\n        Initialize the Toolkit with an optional dictionary of initial tools.\n        \"\"\"\n        # If initial_tools is provided, use it; otherwise, use an empty dictionary\n        self._tools = initial_tools if initial_tools is not None else {}\n\n    @property\n    def tools(self) -> Dict[str, ITool]:\n        return [self._tools[tool].as_dict() for tool in self._tools]\n\n    def add_tools(self, tools: Dict[str, ITool]):\n        \"\"\"\n        Add multiple tools to the toolkit.\n\n        Parameters:\n            tools (Dict[str, Tool]): A dictionary of tool objects keyed by their names.\n        \"\"\"\n        self._tools.update(tools)\n\n    def add_tool(self, tool: ITool):\n        \"\"\"\n        Add a single tool to the toolkit.\n\n        Parameters:\n            tool (Tool): The tool instance to be added to the toolkit.\n        \"\"\"\n        self._tools[tool.function['name']] = tool\n\n    def remove_tool(self, tool_name: str):\n        \"\"\"\n        Remove a tool from the toolkit by name.\n\n        Parameters:\n            tool_name (str): The name of the tool to be removed from the toolkit.\n        \"\"\"\n        if tool_name in self._tools:\n            del self._tools[tool_name]\n        else:\n            raise ValueError(f\"Tool '{tool_name}' not found in the toolkit.\")\n\n    def get_tool_by_name(self, tool_name: str) -> ITool:\n        \"\"\"\n        Get a tool from the toolkit by name.\n\n        Parameters:\n            tool_name (str): The name of the tool to retrieve.\n\n        Returns:\n            Tool: The tool instance with the specified name.\n        \"\"\"\n        if tool_name in self._tools:\n            return self._tools[tool_name]\n        else:\n            raise ValueError(f\"Tool '{tool_name}' not found in the toolkit.\")\n\n    def __len__(self) -> int:\n        \"\"\"\n        Returns the number of tools in the toolkit.\n\n        Returns:\n            int: The number of tools in the toolkit.\n        \"\"\"\n        return len(self._tools)\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/concrete/__init__.py",
        "content": "```swarmauri/standard/toolkits/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/concrete/Toolkit.py",
        "content": "```swarmauri/standard/toolkits/concrete/Toolkit.py\nfrom typing import Dict\nfrom ..base.ToolkitBase import ToolkitBase\nfrom ....core.tools.ITool import ITool\n\nclass Toolkit(ToolkitBase):\n    \"\"\"\n    A class representing a toolkit used by Swarm Agents.\n    Tools are maintained in a dictionary keyed by the tool's name.\n    \"\"\"\n\n    def __init__(self, initial_tools: Dict[str, ITool] = None):\n        \"\"\"\n        Initialize the Toolkit with an optional dictionary of initial tools.\n        \"\"\"\n        \n        super().__init__(initial_tools)\n    \n```"
    },
    {
        "document_name": "swarmauri/standard/tools/__init__.py",
        "content": "```swarmauri/standard/tools/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/base/__init__.py",
        "content": "```swarmauri/standard/tools/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/base/ToolBase.py",
        "content": "```swarmauri/standard/tools/base/ToolBase.py\nfrom typing import Optional, List, Any\nfrom abc import ABC, abstractmethod\nimport json\nfrom swarmauri.core.tools.ITool import ITool\n        \nclass ToolBase(ITool, ABC):\n    \n    @abstractmethod\n    def __init__(self, name, description, parameters=[]):\n        self._name = name\n        self._description = description\n        self._parameters = parameters\n        self.type = \"function\"\n        self.function = {\n            \"name\": name,\n            \"description\": description,\n        }\n        \n        # Dynamically constructing the parameters schema\n        properties = {}\n        required = []\n        \n        for param in parameters:\n            properties[param.name] = {\n                \"type\": param.type,\n                \"description\": param.description,\n            }\n            if param.enum:\n                properties[param.name]['enum'] = param.enum\n\n            if param.required:\n                required.append(param.name)\n        \n        self.function['parameters'] = {\n            \"type\": \"object\",\n            \"properties\": properties,\n        }\n        \n        if required:  # Only include 'required' if there are any required parameters\n            self.function['parameters']['required'] = required\n\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def description(self):\n        return self._description\n\n    @property\n    def parameters(self):\n        return self._parameters\n\n    def __iter__(self):\n        yield ('type', self.type)\n        yield ('function', self.function)\n        \n\n    def as_dict(self):\n        return {'type': self.type, 'function': self.function}\n        # return self.__dict__\n\n    def to_json(obj):\n        return json.dumps(obj, default=lambda obj: obj.__dict__)\n\n    def __getstate__(self):\n        return {'type': self.type, 'function': self.function}\n\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"\n        Placeholder method for executing the functionality of the tool.\n        Subclasses should override this method to define specific tool behaviors.\n\n        Parameters:\n        - *args: Variable length argument list.\n        - **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement the call_function method.\")\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/__init__.py",
        "content": "```swarmauri/standard/tools/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/TestTool.py",
        "content": "```swarmauri/standard/tools/concrete/TestTool.py\nimport json\nimport subprocess as sp\nfrom ..base.ToolBase import ToolBase\nfrom .Parameter import Parameter\n\nclass TestTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"program\",\n                type=\"string\",\n                description=\"The program that the user wants to open ('notepad' or 'calc' or 'mspaint')\",\n                required=True,\n                enum=[\"notepad\", \"calc\", \"mspaint\"]\n            )\n        ]\n        \n        super().__init__(name=\"TestTool\", \n                         description=\"This opens a program based on the user's request.\", \n                         parameters=parameters)\n\n    def __call__(self, program) -> str:\n        # sp.check_output(program)\n        # Here you would implement the actual logic for fetching the weather information.\n        # For demonstration, let's just return the parameters as a string.\n        return f\"Program Opened: {program}\\n\"\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/WeatherTool.py",
        "content": "```swarmauri/standard/tools/concrete/WeatherTool.py\nimport json\nfrom ..base.ToolBase import ToolBase\nfrom .Parameter import Parameter\n\nclass WeatherTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"location\",\n                type=\"string\",\n                description=\"The location for which to fetch weather information\",\n                required=True\n            ),\n            Parameter(\n                name=\"unit\",\n                type=\"string\",\n                description=\"The unit for temperature ('fahrenheit' or 'celsius')\",\n                required=True,\n                enum=[\"fahrenheit\", \"celsius\"]\n            )\n        ]\n        \n        super().__init__(name=\"WeatherTool\", description=\"Fetch current weather info for a location\", parameters=parameters)\n\n    def __call__(self, location, unit=\"fahrenheit\") -> str:\n        weather_info = (location, unit)\n        # Here you would implement the actual logic for fetching the weather information.\n        # For demonstration, let's just return the parameters as a string.\n        return f\"Weather Info: {weather_info}\\n\"\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/Parameter.py",
        "content": "```swarmauri/standard/tools/concrete/Parameter.py\nfrom typing import Optional, List, Any\nimport json\nfrom ....core.tools.IParameter import IParameter\n\nclass Parameter(IParameter):\n    \"\"\"\n    A class to represent a parameter for a tool.\n\n    Attributes:\n        name (str): Name of the parameter.\n        type (str): Data type of the parameter (e.g., 'int', 'str', 'float').\n        description (str): A brief description of the parameter.\n        required (bool): Whether the parameter is required or optional.\n        enum (Optional[List[any]]): A list of acceptable values for the parameter, if any.\n    \"\"\"\n\n    def __init__(self, name: str, type: str, description: str, required: bool = True, enum: Optional[List[Any]] = None):\n        \"\"\"\n        Initializes a new instance of the Parameter class.\n\n        Args:\n            name (str): The name of the parameter.\n            type (str): The type of the parameter.\n            description (str): A brief description of what the parameter is used for.\n            required (bool, optional): Specifies if the parameter is required. Defaults to True.\n            enum (Optional[List[Any]], optional): A list of acceptable values for the parameter. Defaults to None.\n        \"\"\"\n        self._name = name\n        self._type = type\n        self._description = description\n        self._required = required\n        self._enum = enum\n        \n    @property\n    def name(self) -> str:\n        \"\"\"\n        Abstract property for getting the name of the parameter.\n        \"\"\"\n        return self._name\n\n    @name.setter\n    def name(self, value: str):\n        \"\"\"\n        Abstract setter for setting the name of the parameter.\n        \"\"\"\n        self._name = value\n\n    @property\n    def type(self) -> str:\n        \"\"\"\n        Abstract property for getting the type of the parameter.\n        \"\"\"\n        return self._type\n\n    @type.setter\n    def type(self, value: str):\n        \"\"\"\n        Abstract setter for setting the type of the parameter.\n        \"\"\"\n        self._type = value\n\n    @property\n    def description(self) -> str:\n        \"\"\"\n        Abstract property for getting the description of the parameter.\n        \"\"\"\n        return self._description\n\n    @description.setter\n    def description(self, value: str):\n        \"\"\"\n        Abstract setter for setting the description of the parameter.\n        \"\"\"\n        self._description = value\n\n    @property\n    def required(self) -> bool:\n        \"\"\"\n        Abstract property for getting the required status of the parameter.\n        \"\"\"\n        return self._required\n\n    @required.setter\n    def required(self, value: bool):\n        \"\"\"\n        Abstract setter for setting the required status of the parameter.\n        \"\"\"\n        self._required = value\n\n    @property\n    def enum(self) -> Optional[List[Any]]:\n        \"\"\"\n        Abstract property for getting the enum list of the parameter.\n        \"\"\"\n        return self._enum\n\n    @enum.setter\n    def enum(self, value: Optional[List[Any]]):\n        \"\"\"\n        Abstract setter for setting the enum list of the parameter.\n        \"\"\"\n        self._enum = value\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/AdditionTool.py",
        "content": "```swarmauri/standard/tools/concrete/AdditionTool.py\nfrom ..base.ToolBase import ToolBase\nfrom .Parameter import Parameter\n\nclass AdditionTool(ToolBase):\n    \n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"x\",\n                type=\"integer\",\n                description=\"The left operand\",\n                required=True\n            ),\n            Parameter(\n                name=\"y\",\n                type=\"integer\",\n                description=\"The right operand\",\n                required=True\n            )\n        ]\n        super().__init__(name=\"TestTool\", \n                         description=\"This opens a program based on the user's request.\", \n                         parameters=parameters)\n\n    def __call__(self, x: int, y: int) -> int:\n        \"\"\"\n        Add two numbers x and y and return the sum.\n\n        Parameters:\n        - x (int): The first number.\n        - y (int): The second number.\n\n        Returns:\n        - int: The sum of x and y.\n        \"\"\"\n        return x + y\n```"
    },
    {
        "document_name": "swarmauri/standard/apis/__init__.py",
        "content": "```swarmauri/standard/apis/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/apis/base/__init__.py",
        "content": "```swarmauri/standard/apis/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/apis/concrete/__init__.py",
        "content": "```swarmauri/standard/apis/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/__init__.py",
        "content": "```swarmauri/standard/vector_stores/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/__init__.py",
        "content": "```swarmauri/standard/vector_stores/base/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/VectorDocumentStoreBase.py",
        "content": "```swarmauri/standard/vector_stores/base/VectorDocumentStoreBase.py\nimport json\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.vector_stores.IVectorStore import IVectorStore\n\nclass VectorDocumentStoreBase(IVectorStore, ABC):\n    \"\"\"\n    Abstract base class for document stores, implementing the IVectorStore interface.\n\n    This class provides a standard API for adding, updating, getting, and deleting documents in a vector store.\n    The specifics of storing (e.g., in a database, in-memory, or file system) are to be implemented by concrete subclasses.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Add a single document to the document store.\n\n        Parameters:\n        - document (IDocument): The document to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Add multiple documents to the document store in a batch operation.\n\n        Parameters:\n        - documents (List[IDocument]): A list of documents to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Optional[IDocument]:\n        \"\"\"\n        Retrieve a single document by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to retrieve.\n\n        Returns:\n        - Optional[IDocument]: The requested document if found; otherwise, None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieve all documents stored in the document store.\n\n        Returns:\n        - List[IDocument]: A list of all documents in the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Update a document in the document store.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to update.\n        - updated_document (IDocument): The updated document instance.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Delete a document from the document store by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n    \n    def document_count(self):\n        return len(self.documents)\n    \n    def document_dumps(self) -> str:\n        return json.dumps([each.to_dict() for each in self.documents])\n\n    def document_dump(self, file_path: str) -> None:\n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump([each.to_dict() for each in self.documents], \n                f,\n                ensure_ascii=False, \n                indent=4)  \n\n    def document_loads(self, json_data: str) -> None:\n        self.documents = [globals()[each['type']].from_dict(each) for each in json.loads(json_data)]\n\n    def document_load(self, file_path: str) -> None:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            self.documents = [globals()[each['type']].from_dict(each) for each in json.load(file_path)]\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/VectorDocumentStoreRetrieveBase.py",
        "content": "```swarmauri/standard/vector_stores/base/VectorDocumentStoreRetrieveBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.vector_stores.IVectorRetrieve import IVectorRetrieve\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreBase import VectorDocumentStoreBase\n\nclass VectorDocumentStoreRetrieveBase(VectorDocumentStoreBase, IVectorRetrieve, ABC):\n        \n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the top_k most relevant documents based on the given query.\n        \n        Args:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n        \n        Returns:\n            List[IDocument]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/SaveLoadStoreBase.py",
        "content": "```swarmauri/standard/vector_stores/base/SaveLoadStoreBase.py\nfrom typing import List\nimport os\nimport json\nimport glob\nimport importlib \nfrom swarmauri.core.vector_stores.ISaveLoadStore import ISaveLoadStore\nfrom swarmauri.standard.documents import DocumentBase\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\n\nclass SaveLoadStoreBase(ISaveLoadStore):\n    \"\"\"\n    Base class for vector stores with built-in support for saving and loading\n    the vectorizer's model and the documents.\n    \"\"\"\n    \n    def __init__(self, vectorizer: IVectorize, documents: List[DocumentBase]):\n        self.vectorizer = vectorizer\n        self.documents = documents\n    \n    def save_store(self, directory_path: str) -> None:\n        \"\"\"\n        Saves both the vectorizer's model and the documents.\n        \"\"\"\n        # Ensure the directory exists\n        if not os.path.exists(directory_path):\n            os.makedirs(directory_path)\n            \n        # Save the vectorizer model\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        self.vectorizer.save_model(model_path)\n        \n        # Save documents\n        documents_path = os.path.join(directory_path, \"documents.json\")\n        with open(documents_path, 'w', encoding='utf-8') as f:\n            json.dump([each.to_dict() for each in self.documents], \n                f,\n                ensure_ascii=False, \n                indent=4)\n\n    \n    def load_store(self, directory_path: str) -> None:\n        \"\"\"\n        Loads both the vectorizer's model and the documents.\n        \"\"\"\n        # Load the vectorizer model\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        self.vectorizer.load_model(model_path)\n        \n        # Load documents\n        documents_path = os.path.join(directory_path, \"documents.json\")\n        with open(documents_path, 'r', encoding='utf-8') as f:\n            self.documents = [self._load_document(each) for each in json.load(f)]\n\n    def _load_document(self, data):\n        document_type = data.pop(\"type\") \n        if document_type:\n            module = importlib.import_module(f\"swarmauri.standard.documents.concrete.{document_type}\")\n            document_class = getattr(module, document_type)\n            document = document_class.from_dict(data)\n            return document\n        else:\n            raise ValueError(\"Unknown document type\")\n\n    def save_parts(self, directory_path: str, chunk_size: int = 10485760) -> None:\n        \"\"\"\n        Splits the file into parts if it's too large and saves those parts individually.\n        \"\"\"\n        file_number = 1\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        parts_directory = os.path.join(directory_path, \"parts\")\n        \n        if not os.path.exists(parts_directory):\n            os.makedirs(parts_directory)\n\n\n\n        with open(f\"{model_path}/model.safetensors\", 'rb') as f:\n            chunk = f.read(chunk_size)\n            while chunk:\n                with open(f\"{parts_directory}/model.safetensors.part{file_number}\", 'wb') as chunk_file:\n                    chunk_file.write(chunk)\n                file_number += 1\n                chunk = f.read(chunk_size)\n\n        # Split the documents into parts and save them\n        documents_dir = os.path.join(directory_path, \"documents\")\n\n        self._split_json_file(directory_path, chunk_size=chunk_size)\n\n\n    def _split_json_file(self, directory_path: str, max_records=100, chunk_size: int = 10485760):    \n        # Read the input JSON file\n        combined_documents_file_path = os.path.join(directory_path, \"documents.json\")\n\n        # load the master JSON file\n        with open(combined_documents_file_path , 'r') as file:\n            data = json.load(file)\n\n        # Set and Create documents parts folder if it does not exist\n        documents_dir = os.path.join(directory_path, \"documents\")\n        if not os.path.exists(documents_dir):\n            os.makedirs(documents_dir)\n        current_batch = []\n        file_index = 1\n        current_size = 0\n        \n        for record in data:\n            current_batch.append(record)\n            current_size = len(json.dumps(current_batch).encode('utf-8'))\n            \n            # Check if current batch meets the splitting criteria\n            if len(current_batch) >= max_records or current_size >= chunk_size:\n                # Write current batch to a new file\n                output_file = f'document_part_{file_index}.json'\n                output_file = os.path.join(documents_dir, output_file)\n                with open(output_file, 'w') as outfile:\n                    json.dump(current_batch, outfile)\n                \n                # Prepare for the next batch\n                current_batch = []\n                current_size = 0\n                file_index += 1\n\n        # Check if there's any remaining data to be written\n        if current_batch:\n            output_file = f'document_part_{file_index}.json'\n            output_file = os.path.join(documents_dir, output_file)\n            with open(output_file, 'w') as outfile:\n                json.dump(current_batch, outfile)\n\n    def load_parts(self, directory_path: str, file_pattern: str = '*.part*') -> None:\n        \"\"\"\n        Combines file parts from a directory back into a single file and loads it.\n        \"\"\"\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        parts_directory = os.path.join(directory_path, \"parts\")\n        output_file_path = os.path.join(model_path, \"model.safetensors\")\n\n        parts = sorted(glob.glob(os.path.join(parts_directory, file_pattern)))\n        with open(output_file_path, 'wb') as output_file:\n            for part in parts:\n                with open(part, 'rb') as file_part:\n                    output_file.write(file_part.read())\n\n        # Load the combined_model now        \n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        self.vectorizer.load_model(model_path)\n\n        # Load document files\n        self._load_documents(directory_path)\n        \n\n    def _load_documents(self, directory_path: str) -> None:\n        \"\"\"\n        Loads the documents from parts stored in the given directory.\n        \"\"\"\n        part_paths = glob.glob(os.path.join(directory_path, \"documents/*.json\"))\n        for part_path in part_paths:\n            with open(part_path, \"r\") as f:\n                part_documents = json.load(f)\n                for document_data in part_documents:\n                    document_type = document_data.pop(\"type\")\n                    document_module = importlib.import_module(f\"swarmauri.standard.documents.concrete.{document_type}\")\n                    document_class = getattr(document_module, document_type)\n                    document = document_class.from_dict(document_data)\n                    self.documents.append(document)\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/__init__.py",
        "content": "```swarmauri/standard/vector_stores/concrete/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/TFIDFVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/TFIDFVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.vectorizers.concrete.TFIDFVectorizer import TFIDFVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase\n\nclass TFIDFVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = TFIDFVectorizer()\n        self.metric = CosineDistance()\n        self.documents = []\n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)\n      \n\n    def add_document(self, document: IDocument) -> None:\n        self.documents.append(document)\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        self.documents.extend(documents)\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def get_document(self, doc_id: str) -> Union[IDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n\n    def get_all_documents(self) -> List[IDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [doc for doc in self.documents if doc.id != doc_id]\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        for i, document in enumerate(self.documents):\n            if document.id == doc_id:\n                self.documents[i] = updated_document\n                break\n\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        transform_matrix = self.vectorizer.fit_transform(query, self.documents)\n\n        # The inferred vector is the last vector in the transformed_matrix\n        # The rest of the matrix is what we are comparing\n        distances = self.metric.distances(transform_matrix[-1], transform_matrix[:-1])  \n\n        # Get the indices of the top_k most similar (least distant) documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        return [self.documents[i] for i in top_k_indices]\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/Doc2VecVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/Doc2VecVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vectorizers.concrete.Doc2VecVectorizer import Doc2VecVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase    \n\n\nclass Doc2VecVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = Doc2VecVectorizer()\n        self.metric = CosineDistance()\n        self.documents = []      \n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)\n\n    def add_document(self, document: IDocument) -> None:\n        self.documents.append(document)\n        self._recalculate_embeddings()\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        self.documents.extend(documents)\n        self._recalculate_embeddings()\n\n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n\n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [doc for doc in self.documents if doc.id != doc_id]\n        self._recalculate_embeddings()\n\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        for i, document in enumerate(self.documents):\n            if document.id == doc_id:\n                self.documents[i] = updated_document\n                break\n        self._recalculate_embeddings()\n\n    def _recalculate_embeddings(self):\n        # Recalculate document embeddings for the current set of documents\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count]) for _count, _d in enumerate(self.documents)\n            if _d.content]\n\n        self.documents = embedded_documents\n\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        query_vector = self.vectorizer.infer_vector(query)\n        document_vectors = [_d.embedding for _d in self.documents if _d.content]\n\n        distances = self.metric.distances(query_vector, document_vectors)\n\n        # Get the indices of the top_k least distant (most similar) documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        \n        return [self.documents[i] for i in top_k_indices]\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/MLMVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/MLMVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vectorizers.concrete.MLMVectorizer import MLMVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase    \n\nclass MLMVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = MLMVectorizer()  # Assuming this is already implemented\n        self.metric = CosineDistance()\n        self.documents: List[EmbeddedDocument] = []\n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)      \n\n    def add_document(self, document: IDocument) -> None:\n        self.documents.append(document)\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count])\n\n        for _count, _d in enumerate(self.documents) if _d.content]\n\n        self.documents = embedded_documents\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        self.documents.extend(documents)\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count]) for _count, _d in enumerate(self.documents) \n            if _d.content]\n\n        self.documents = embedded_documents\n\n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n        \n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [_d for _d in self.documents if _d.id != doc_id]\n\n    def update_document(self, doc_id: str) -> None:\n        raise NotImplementedError('Update_document not implemented on BERTDocumentStore class.')\n        \n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        query_vector = self.vectorizer.infer_vector(query)\n        document_vectors = [_d.embedding for _d in self.documents if _d.content]\n        distances = self.metric.distances(query_vector, document_vectors)\n        \n        # Get the indices of the top_k most similar documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        \n        return [self.documents[i] for i in top_k_indices]\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/SpatialDocVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/SpatialDocVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vectorizers.concrete.SpatialDocVectorizer import SpatialDocVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase    \n\nclass MLMVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = SpatialDocVectorizer()  # Assuming this is already implemented\n        self.metric = CosineDistance()\n        self.documents: List[EmbeddedDocument] = []\n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)      \n\n    def add_document(self, document: IDocument) -> None:\n        self.documents.append(document)\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count])\n\n        for _count, _d in enumerate(self.documents) if _d.content]\n\n        self.documents = embedded_documents\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        self.documents.extend(documents)\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count]) for _count, _d in enumerate(self.documents) \n            if _d.content]\n\n        self.documents = embedded_documents\n\n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n        \n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [_d for _d in self.documents if _d.id != doc_id]\n\n    def update_document(self, doc_id: str) -> None:\n        raise NotImplementedError('Update_document not implemented on BERTDocumentStore class.')\n        \n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        query_vector = self.vectorizer.infer_vector(query)\n        document_vectors = [_d.embedding for _d in self.documents if _d.content]\n        distances = self.metric.distances(query_vector, document_vectors)\n        \n        # Get the indices of the top_k most similar documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        \n        return [self.documents[i] for i in top_k_indices]\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/__init__.py",
        "content": "```swarmauri/standard/document_stores/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/base/__init__.py",
        "content": "```swarmauri/standard/document_stores/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/base/DocumentStoreBase.py",
        "content": "```swarmauri/standard/document_stores/base/DocumentStoreBase.py\nimport json\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.document_stores.IDocumentStore import IDocumentStore\n\nclass DocumentStoreBase(IDocumentStore, ABC):\n    \"\"\"\n    Abstract base class for document stores, implementing the IDocumentStore interface.\n\n    This class provides a standard API for adding, updating, getting, and deleting documents in a store.\n    The specifics of storing (e.g., in a database, in-memory, or file system) are to be implemented by concrete subclasses.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Add a single document to the document store.\n\n        Parameters:\n        - document (IDocument): The document to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Add multiple documents to the document store in a batch operation.\n\n        Parameters:\n        - documents (List[IDocument]): A list of documents to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Optional[IDocument]:\n        \"\"\"\n        Retrieve a single document by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to retrieve.\n\n        Returns:\n        - Optional[IDocument]: The requested document if found; otherwise, None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieve all documents stored in the document store.\n\n        Returns:\n        - List[IDocument]: A list of all documents in the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Update a document in the document store.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to update.\n        - updated_document (IDocument): The updated document instance.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Delete a document from the document store by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n    \n    def document_count(self):\n        return len(self.documents)\n    \n    def dump(self, file_path):\n        with open(file_path, 'w') as f:\n            json.dumps([each.__dict__ for each in self.documents], f, indent=4)\n            \n    def load(self, file_path):\n        with open(file_path, 'r') as f:\n            self.documents = json.loads(f)\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/base/DocumentStoreRetrieveBase.py",
        "content": "```swarmauri/standard/document_stores/base/DocumentStoreRetrieveBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.document_stores.IDocumentRetrieve import IDocumentRetrieve\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.document_stores.base.DocumentStoreBase import DocumentStoreBase\n\nclass DocumentStoreRetrieveBase(DocumentStoreBase, IDocumentRetrieve, ABC):\n\n        \n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the top_k most relevant documents based on the given query.\n        \n        Args:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n        \n        Returns:\n            List[IDocument]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/concrete/__init__.py",
        "content": "```swarmauri/standard/document_stores/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/__init__.py",
        "content": "```swarmauri/standard/chunkers/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/base/__init__.py",
        "content": "```swarmauri/standard/chunkers/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/__init__.py",
        "content": "```swarmauri/standard/chunkers/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/SlidingWindowChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/SlidingWindowChunker.py\nfrom typing import List\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass SlidingWindowChunker(IChunker):\n    \"\"\"\n    A concrete implementation of IChunker that uses sliding window technique\n    to break the text into chunks.\n    \"\"\"\n    \n    def __init__(self, window_size: int, step_size: int, overlap: bool = True):\n        \"\"\"\n        Initialize the SlidingWindowChunker with specific window and step sizes.\n        \n        Parameters:\n        - window_size (int): The size of the window for each chunk (in terms of number of words).\n        - step_size (int): The step size for the sliding window (in terms of number of words).\n        - overlap (bool, optional): Whether the windows should overlap. Default is True.\n        \"\"\"\n        self.window_size = window_size\n        self.step_size = step_size if overlap else window_size  # Non-overlapping if window size equals step size.\n           \n    def chunk_text(self, text: str, *args, **kwargs) -> List[str]:\n        \"\"\"\n        Splits the input text into chunks based on the sliding window technique.\n        \n        Parameters:\n        - text (str): The input text to be chunked.\n        \n        Returns:\n        - List[str]: A list of text chunks.\n        \"\"\"\n        words = text.split()  # Tokenization by whitespaces. More sophisticated tokenization might be necessary.\n        chunks = []\n        \n        for i in range(0, len(words) - self.window_size + 1, self.step_size):\n            chunk = ' '.join(words[i:i+self.window_size])\n            chunks.append(chunk)\n        \n        return chunks\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/DelimiterBasedChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/DelimiterBasedChunker.py\nfrom typing import List, Union, Any\nimport re\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass DelimiterBasedChunker(IChunker):\n    \"\"\"\n    A concrete implementation of IChunker that splits text into chunks based on specified delimiters.\n    \"\"\"\n\n    def __init__(self, delimiters: List[str] = None):\n        \"\"\"\n        Initializes the chunker with a list of delimiters.\n\n        Parameters:\n        - delimiters (List[str], optional): A list of strings that will be used as delimiters for splitting the text.\n                                            If not specified, a default list of sentence-ending punctuation is used.\n        \"\"\"\n        if delimiters is None:\n            delimiters = ['.', '!', '?']  # Default delimiters\n        # Create a regex pattern that matches any of the specified delimiters.\n        # The pattern uses re.escape on each delimiter to ensure special regex characters are treated literally.\n        self.delimiter_pattern = f\"({'|'.join(map(re.escape, delimiters))})\"\n    \n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[str]:\n        \"\"\"\n        Chunks the given text based on the delimiters specified during initialization.\n\n        Parameters:\n        - text (Union[str, Any]): The input text to be chunked.\n\n        Returns:\n        - List[str]: A list of text chunks split based on the specified delimiters.\n        \"\"\"\n        # Split the text based on the delimiter pattern, including the delimiters in the result\n        chunks = re.split(self.delimiter_pattern, text)\n        # Combine delimiters with the preceding text chunk since re.split() separates them\n        combined_chunks = []\n        for i in range(0, len(chunks) - 1, 2):  # Step by 2 to process text chunk with its following delimiter\n            combined_chunks.append(chunks[i] + (chunks[i + 1] if i + 1 < len(chunks) else ''))\n        return combined_chunks\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/FixedLengthChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/FixedLengthChunker.py\nfrom typing import List, Union, Any\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass FixedLengthChunker(IChunker):\n    \"\"\"\n    Concrete implementation of IChunker that divides text into fixed-length chunks.\n    \n    This chunker breaks the input text into chunks of a specified size, making sure \n    that each chunk has exactly the number of characters specified by the chunk size, \n    except for possibly the last chunk.\n    \"\"\"\n\n    def __init__(self, chunk_size: int):\n        \"\"\"\n        Initializes a new instance of the FixedLengthChunker class with a specific chunk size.\n\n        Parameters:\n        - chunk_size (int): The fixed size (number of characters) for each chunk.\n        \"\"\"\n        self.chunk_size = chunk_size\n\n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[str]:\n        \"\"\"\n        Splits the input text into fixed-length chunks.\n\n        Parameters:\n        - text (Union[str, Any]): The input text to be chunked.\n        \n        Returns:\n        - List[str]: A list of text chunks, each of a specified fixed length.\n        \"\"\"\n        # Check if the input is a string, if not, attempt to convert to a string.\n        if not isinstance(text, str):\n            text = str(text)\n        \n        # Using list comprehension to split text into chunks of fixed size\n        chunks = [text[i:i+self.chunk_size] for i in range(0, len(text), self.chunk_size)]\n        \n        return chunks\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/SimpleSentenceChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/SimpleSentenceChunker.py\nimport re\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass SimpleSentenceChunker(IChunker):\n    \"\"\"\n    A simple implementation of the IChunker interface to chunk text into sentences.\n    \n    This class uses basic punctuation marks (., !, and ?) as indicators for sentence boundaries.\n    \"\"\"\n    \n    def chunk_text(self, text, *args, **kwargs):\n        \"\"\"\n        Chunks the given text into sentences using basic punctuation.\n\n        Args:\n            text (str): The input text to be chunked into sentences.\n        \n        Returns:\n            List[str]: A list of sentence chunks.\n        \"\"\"\n        # Split text using a simple regex pattern that looks for periods, exclamation marks, or question marks.\n        # Note: This is a very simple approach and might not work well with abbreviations or other edge cases.\n        sentence_pattern = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s'\n        sentences = re.split(sentence_pattern, text)\n        \n        # Filter out any empty strings that may have resulted from the split operation\n        sentences = [sentence.strip() for sentence in sentences if sentence]\n        \n        return sentences\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/MdSnippetChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/MdSnippetChunker.py\nfrom typing import List, Union, Any, Optional\nimport re\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass MdSnippetChunker(IChunker):\n    def __init__(self, language: Optional[str] = None):\n        \"\"\"\n        Initializes the MdSnippetChunker with a specific programming language\n        to look for within Markdown fenced code blocks.\n        \"\"\"\n        self.language = language\n    \n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[tuple]:\n        \"\"\"\n        Extracts paired comments and code blocks from Markdown content based on the \n        specified programming language.\n        \"\"\"\n        if self.language:\n            # If language is specified, directly extract the corresponding blocks\n            pattern = fr'```{self.language}\\s*(.*?)```'\n            scripts = re.findall(pattern, text, re.DOTALL)\n            comments_temp = re.split(pattern, text, flags=re.DOTALL)\n        else:\n            # Extract blocks and languages dynamically if no specific language is provided\n            scripts = []\n            languages = []\n            for match in re.finditer(r'```(\\w+)?\\s*(.*?)```', text, re.DOTALL):\n                if match.group(1) is not None:  # Checks if a language identifier is present\n                    languages.append(match.group(1))\n                    scripts.append(match.group(2))\n                else:\n                    languages.append('')  # Default to an empty string if no language is found\n                    scripts.append(match.group(2))\n            comments_temp = re.split(r'```.*?```', text, flags=re.DOTALL)\n\n        comments = [comment.strip() for comment in comments_temp]\n\n        if text.strip().startswith('```'):\n            comments = [''] + comments\n        if text.strip().endswith('```'):\n            comments.append('')\n\n        if self.language:\n            structured_output = [(comments[i], self.language, scripts[i].strip()) for i in range(len(scripts))]\n        else:\n            structured_output = [(comments[i], languages[i], scripts[i].strip()) for i in range(len(scripts))]\n\n        return structured_output\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/__init__.py",
        "content": "```swarmauri/standard/vectors/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/base/__init__.py",
        "content": "```swarmauri/standard/vectors/base/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/base/VectorBase.py",
        "content": "```swarmauri/standard/vectors/base/VectorBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nimport json\nimport numpy as np\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass VectorBase(IVector, ABC):\n    def __init__(self, data: List[float]):\n        self._data = data\n\n    @property\n    def data(self) -> List[float]:\n        \"\"\"\n        Returns the vector's data.\n        \"\"\"\n        return self._data\n\n    def to_numpy(self) -> np.ndarray:\n        \"\"\"\n        Converts the vector into a numpy array.\n\n        Returns:\n            np.ndarray: The numpy array representation of the vector.\n        \"\"\"\n        return np.array(self._data)\n    \n    def __repr__(self):\n        return str(self.data)\n    \n    def __len__(self):\n        return len(self.data)\n\n    def to_dict(self) -> dict:\n        \"\"\"\n        Converts the vector into a dictionary suitable for JSON serialization.\n        This method needs to be called explicitly for conversion.\n        \"\"\"\n        return {'type': self.__class__.__name__,'data': self.data}\n\n    @classmethod\n    def from_dict(cls, data):\n        return cls(**data)\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/concrete/SimpleVector.py",
        "content": "```swarmauri/standard/vectors/concrete/SimpleVector.py\nfrom typing import List\nfrom swarmauri.standard.vectors.base.VectorBase import VectorBase\n\nclass SimpleVector(VectorBase):\n    def __init__(self, data: List[float]):\n        super().__init__(data)\n        \n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/concrete/__init__.py",
        "content": "```swarmauri/standard/vectors/concrete/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/concrete/VectorProduct.py",
        "content": "```swarmauri/standard/vectors/concrete/VectorProduct.py\nimport numpy as np\nfrom typing import List\n\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.core.vectors.IVectorProduct import IVectorProduct\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\n\nclass VectorProduct(IVectorProduct):\n    def dot_product(self, vector_a: IVector, vector_b: IVector) -> float:\n        a = np.array(vector_a.data).flatten()\n        b = np.array(vector_b.data).flatten()\n        return np.dot(a, b)\n    \n    def cross_product(self, vector_a: IVector, vector_b: IVector) -> IVector:\n        if len(vector_a.data) != 3 or len(vector_b.data) != 3:\n            raise ValueError(\"Cross product is only defined for 3-dimensional vectors\")\n        a = np.array(vector_a.data)\n        b = np.array(vector_b.data)\n        cross = np.cross(a, b)\n        return SimpleVector(cross.tolist())\n    \n    def vector_triple_product(self, vector_a: IVector, vector_b: IVector, vector_c: IVector) -> IVector:\n        a = np.array(vector_a.data)\n        b = np.array(vector_b.data)\n        c = np.array(vector_c.data)\n        result = np.cross(a, np.cross(b, c))\n        return SimpleVector(result.tolist())\n    \n    def scalar_triple_product(self, vector_a: IVector, vector_b: IVector, vector_c: IVector) -> float:\n        a = np.array(vector_a.data)\n        b = np.array(vector_b.data)\n        c = np.array(vector_c.data)\n        return np.dot(a, np.cross(b, c))\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/__init__.py",
        "content": "```swarmauri/standard/vectorizers/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/base/__init__.py",
        "content": "```swarmauri/standard/vectorizers/base/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/__init__.py",
        "content": "```swarmauri/standard/vectorizers/concrete/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/Doc2VecVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/Doc2VecVectorizer.py\nfrom typing import List, Union, Any\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\nclass Doc2VecVectorizer(IVectorize, IFeature, ISaveModel):\n    def __init__(self):\n        self.model = Doc2Vec(vector_size=2000, window=10, min_count=1, workers=5)\n\n    def extract_features(self):\n        return list(self.model.wv.key_to_index.keys())\n\n    def fit(self, documents: List[str], labels=None) -> None:\n        tagged_data = [TaggedDocument(words=_d.split(), \n            tags=[str(i)]) for i, _d in enumerate(documents)]\n\n        self.model.build_vocab(tagged_data)\n        self.model.train(tagged_data, total_examples=self.model.corpus_count, epochs=self.model.epochs)\n\n    def transform(self, documents: List[str]) -> List[IVector]:\n        vectors = [self.model.infer_vector(doc.split()) for doc in documents]\n        return [SimpleVector(vector) for vector in vectors]\n\n    def fit_transform(self, documents: List[Union[str, Any]], **kwargs) -> List[IVector]:\n        \"\"\"\n        Fine-tunes the MLM and generates embeddings for the provided documents.\n        \"\"\"\n        self.fit(documents, **kwargs)\n        return self.transform(documents)\n\n    def infer_vector(self, data: str) -> IVector:\n        vector = self.model.infer_vector(data.split())\n        return SimpleVector(vector.squeeze().tolist())\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the Doc2Vec model to the specified path.\n        \"\"\"\n        self.model.save(path)\n    \n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads a Doc2Vec model from the specified path.\n        \"\"\"\n        self.model = Doc2Vec.load(path)\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/MLMVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/MLMVectorizer.py\nfrom typing import List, Union, Any\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset\n\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\nclass MLMVectorizer(IVectorize, IFeature, ISaveModel):\n    \"\"\"\n    IVectorize implementation that fine-tunes a Masked Language Model (MLM).\n    \"\"\"\n\n    def __init__(self, model_name='bert-base-uncased', \n        batch_size = 32, \n        learning_rate = 5e-5, \n        masking_ratio: float = 0.15, \n        randomness_ratio: float = 0.10,\n        add_new_tokens: bool = False):\n        \"\"\"\n        Initializes the vectorizer with a pre-trained MLM model and tokenizer for fine-tuning.\n        \n        Parameters:\n        - model_name (str): Identifier for the pre-trained model and tokenizer.\n        \"\"\"\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForMaskedLM.from_pretrained(model_name)\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(self.device)\n        self.epochs = 0\n        self.batch_size = batch_size\n        self.learning_rate = learning_rate\n        self.masking_ratio = masking_ratio\n        self.randomness_ratio = randomness_ratio\n        self.add_new_tokens = add_new_tokens\n        self.mask_token_id = self.tokenizer.convert_tokens_to_ids([self.tokenizer.mask_token])[0]\n\n    def extract_features(self):\n        raise NotImplementedError('Extract_features not implemented on MLMVectorizer.')\n\n    def _mask_tokens(self, encodings):\n        input_ids = encodings.input_ids.to(self.device)\n        attention_mask = encodings.attention_mask.to(self.device)\n\n        labels = input_ids.detach().clone()\n\n        probability_matrix = torch.full(labels.shape, self.masking_ratio, device=self.device)\n        special_tokens_mask = [\n            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n        ]\n        probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool, device=self.device), value=0.0)\n        masked_indices = torch.bernoulli(probability_matrix).bool()\n\n        labels[~masked_indices] = -100\n        \n        indices_replaced = torch.bernoulli(torch.full(labels.shape, self.masking_ratio, device=self.device)).bool() & masked_indices\n        input_ids[indices_replaced] = self.mask_token_id\n\n        indices_random = torch.bernoulli(torch.full(labels.shape, self.randomness_ratio, device=self.device)).bool() & masked_indices & ~indices_replaced\n        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long, device=self.device)\n        input_ids[indices_random] = random_words[indices_random]\n\n        return input_ids, attention_mask, labels\n\n    def fit(self, documents: List[Union[str, Any]]):\n        # Check if we need to add new tokens\n        if self.add_new_tokens:\n            new_tokens = self.find_new_tokens(documents)\n            if new_tokens:\n                num_added_toks = self.tokenizer.add_tokens(new_tokens)\n                if num_added_toks > 0:\n                    print(f\"Added {num_added_toks} new tokens.\")\n                    self.model.resize_token_embeddings(len(self.tokenizer))\n\n        encodings = self.tokenizer(documents, return_tensors='pt', padding=True, truncation=True, max_length=512)\n        input_ids, attention_mask, labels = self._mask_tokens(encodings)\n        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n        dataset = TensorDataset(input_ids, attention_mask, labels)\n        data_loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n\n        self.model.train()\n        for batch in data_loader:\n            batch = {k: v.to(self.device) for k, v in zip(['input_ids', 'attention_mask', 'labels'], batch)}\n            outputs = self.model(**batch)\n            loss = outputs.loss\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        self.epochs += 1\n        print(f\"Epoch {self.epochs} complete. Loss {loss.item()}\")\n\n    def find_new_tokens(self, documents):\n        # Identify unique words in documents that are not in the tokenizer's vocabulary\n        unique_words = set()\n        for doc in documents:\n            tokens = set(doc.split())  # Simple whitespace tokenization\n            unique_words.update(tokens)\n        existing_vocab = set(self.tokenizer.get_vocab().keys())\n        new_tokens = list(unique_words - existing_vocab)\n        return new_tokens if new_tokens else None\n\n    def transform(self, documents: List[Union[str, Any]]) -> List[IVector]:\n        \"\"\"\n        Generates embeddings for a list of documents using the fine-tuned MLM.\n        \"\"\"\n        self.model.eval()\n        embedding_list = []\n        \n        for document in documents:\n            inputs = self.tokenizer(document, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n            with torch.no_grad():\n                outputs = self.model(**inputs)\n            # Extract embedding (for simplicity, averaging the last hidden states)\n            if hasattr(outputs, 'last_hidden_state'):\n                embedding = outputs.last_hidden_state.mean(1)\n            else:\n                # Fallback or corrected attribute access\n                embedding = outputs['logits'].mean(1)\n            embedding = embedding.cpu().numpy()\n            embedding_list.append(SimpleVector(embedding.squeeze().tolist()))\n\n        return embedding_list\n\n    def fit_transform(self, documents: List[Union[str, Any]], **kwargs) -> List[IVector]:\n        \"\"\"\n        Fine-tunes the MLM and generates embeddings for the provided documents.\n        \"\"\"\n        self.fit(documents, **kwargs)\n        return self.transform(documents)\n\n    def infer_vector(self, data: Union[str, Any], *args, **kwargs) -> IVector:\n        \"\"\"\n        Generates an embedding for the input data.\n\n        Parameters:\n        - data (Union[str, Any]): The input data, expected to be a textual representation.\n                                  Could be a single string or a batch of strings.\n        \"\"\"\n        # Tokenize the input data and ensure the tensors are on the correct device.\n        self.model.eval()\n        inputs = self.tokenizer(data, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n\n        # Generate embeddings using the model\n        with torch.no_grad():\n            outputs = self.model(**inputs)\n\n        if hasattr(outputs, 'last_hidden_state'):\n            # Access the last layer and calculate the mean across all tokens (simple pooling)\n            embedding = outputs.last_hidden_state.mean(dim=1)\n        else:\n            embedding = outputs['logits'].mean(1)\n        # Move the embeddings back to CPU for compatibility with downstream tasks if necessary\n        embedding = embedding.cpu().numpy()\n\n        return SimpleVector(embedding.squeeze().tolist())\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the model and tokenizer to the specified directory.\n        \"\"\"\n        self.model.save_pretrained(path)\n        self.tokenizer.save_pretrained(path)\n\n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads the model and tokenizer from the specified directory.\n        \"\"\"\n        self.model = AutoModelForMaskedLM.from_pretrained(path)\n        self.tokenizer = AutoTokenizer.from_pretrained(path)\n        self.model.to(self.device)  # Ensure the model is loaded to the correct device\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/TFIDFVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/TFIDFVectorizer.py\nfrom typing import List, Union, Any\nimport joblib\nfrom sklearn.feature_extraction.text import TfidfVectorizer as SklearnTfidfVectorizer\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\n\nclass TFIDFVectorizer(IVectorize, IFeature, ISaveModel):\n    def __init__(self):\n        # Using scikit-learn's TfidfVectorizer as the underlying mechanism\n        self.model = SklearnTfidfVectorizer()\n        super().__init__()\n        \n    def extract_features(self):\n        return self.model.get_feature_names_out()\n\n    def fit(self, data: Union[str, Any]) -> List[IVector]:\n        \"\"\"\n        Vectorizes the input data using the TF-IDF scheme.\n\n        Parameters:\n        - data (Union[str, Any]): The input data to be vectorized. Expected to be a single string (document)\n                                  or a list of strings (corpus).\n\n        Returns:\n        - List[IVector]: A list containing IVector instances, each representing a document's TF-IDF vector.\n        \"\"\"\n        if isinstance(data, str):\n            data = [data]  # Convert a single string into a list for the vectorizer\n        \n        self.fit_matrix = self.model.fit_transform(data)\n\n        # Convert the sparse matrix rows into SimpleVector instances\n        vectors = [SimpleVector(vector.toarray().flatten()) for vector in self.fit_matrix]\n\n        return vectors\n\n    def fit_transform(self, data: Union[str, Any], documents) -> List[IVector]:\n        documents = [doc.content for doc in documents]\n        if isinstance(data, str):\n            data = [data]  # Convert a single string into a list for the vectorizer\n        documents.extend(data)\n\n        transform_matrix = self.model.fit_transform(documents)\n\n        # Convert the sparse matrix rows into SimpleVector instances\n        vectors = [SimpleVector(vector.toarray().flatten()) for vector in transform_matrix]\n        return vectors\n    \n    def transform(self, data: Union[str, Any], documents) -> List[IVector]:\n        raise NotImplementedError('Transform not implemented on TFIDFVectorizer.')\n\n    def infer_vector(self, data: str, documents) -> IVector:\n        documents = [doc.content for doc in documents]\n        documents.append(data)\n        tmp_tfidf_matrix = self.transform(documents)\n        query_vector = tmp_tfidf_matrix[-1]\n        return query_vector\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the TF-IDF model to the specified path using joblib.\n        \"\"\"\n        joblib.dump(self.model, path)\n    \n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads a TF-IDF model from the specified path using joblib.\n        \"\"\"\n        self.model = joblib.load(path)\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/NMFVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/NMFVectorizer.py\nimport joblib\n\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\nclass NMFVectorizer(IVectorize, IFeature, ISaveModel):\n    def __init__(self, n_components=10):\n        # Initialize TF-IDF Vectorizer\n        self.tfidf_vectorizer = TfidfVectorizer()\n        # Initialize NMF with the desired number of components\n        self.model = NMF(n_components=n_components)\n        self.feature_names = []\n\n    def fit(self, data):\n        \"\"\"\n        Fit the NMF model to data.\n\n        Args:\n            data (Union[str, Any]): The text data to fit.\n        \"\"\"\n        # Transform data into TF-IDF matrix\n        tfidf_matrix = self.tfidf_vectorizer.fit_transform(data)\n        # Fit the NMF model\n        self.model.fit(tfidf_matrix)\n        # Store feature names\n        self.feature_names = self.tfidf_vectorizer.get_feature_names_out()\n\n    def transform(self, data):\n        \"\"\"\n        Transform new data into NMF feature space.\n\n        Args:\n            data (Union[str, Any]): Text data to transform.\n\n        Returns:\n            List[IVector]: A list of vectors representing the transformed data.\n        \"\"\"\n        # Transform data into TF-IDF matrix\n        tfidf_matrix = self.tfidf_vectorizer.transform(data)\n        # Transform TF-IDF matrix into NMF space\n        nmf_features = self.model.transform(tfidf_matrix)\n\n        # Wrap NMF features in SimpleVector instances and return\n        return [SimpleVector(features.tolist()) for features in nmf_features]\n\n    def fit_transform(self, data):\n        \"\"\"\n        Fit the model to data and then transform it.\n        \n        Args:\n            data (Union[str, Any]): The text data to fit and transform.\n\n        Returns:\n            List[IVector]: A list of vectors representing the fitted and transformed data.\n        \"\"\"\n        self.fit(data)\n        return self.transform(data)\n\n    def infer_vector(self, data):\n        \"\"\"\n        Convenience method for transforming a single data point.\n        \n        Args:\n            data (Union[str, Any]): Single text data to transform.\n\n        Returns:\n            IVector: A vector representing the transformed single data point.\n        \"\"\"\n        return self.transform([data])[0]\n    \n    def extract_features(self):\n        \"\"\"\n        Extract the feature names from the TF-IDF vectorizer.\n        \n        Returns:\n            The feature names.\n        \"\"\"\n        return self.feature_names\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the NMF model and TF-IDF vectorizer using joblib.\n        \"\"\"\n        # It might be necessary to save both tfidf_vectorizer and model\n        # Consider using a directory for 'path' or appended identifiers for each model file\n        joblib.dump(self.tfidf_vectorizer, f\"{path}_tfidf.joblib\")\n        joblib.dump(self.model, f\"{path}_nmf.joblib\")\n\n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads the NMF model and TF-IDF vectorizer from paths using joblib.\n        \"\"\"\n        self.tfidf_vectorizer = joblib.load(f\"{path}_tfidf.joblib\")\n        self.model = joblib.load(f\"{path}_nmf.joblib\")\n        # Dependending on your implementation, you might need to refresh the feature_names\n        self.feature_names = self.tfidf_vectorizer.get_feature_names_out()\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/SpatialDocVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/SpatialDocVectorizer.py\nimport numpy as np\n\nimport torch\nfrom torch import nn\nfrom transformers import BertTokenizer, BertModel\n\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\n\nclass SpatialDocVectorizer(nn.Module, IVectorize, ISaveModel, IFeature):\n    def __init__(self, special_tokens_dict=None):\n        self.special_tokens_dict = special_tokens_dict or {\n            'additional_special_tokens': ['[DIR]', '[TYPE]', '[SECTION]', '[PATH]']\n        }\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        self.tokenizer.add_special_tokens(self.special_tokens_dict)\n        self.model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n        self.model.resize_token_embeddings(len(self.tokenizer))\n\n    def add_metadata(self, text, section_header, file_path, doc_type):\n        dir_token = f\"[DIR={file_path.split('/')[-2]}]\"\n        doc_type_token = f\"[TYPE={doc_type}]\"\n        metadata_str = f\"{dir_token} {doc_type_token} [SECTION={section_header}] [PATH={file_path}] \"\n        return metadata_str + text\n\n    def tokenize_and_encode(self, text):\n        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        outputs = self.model(**inputs)\n        return outputs.pooler_output\n\n    def enhance_embedding_with_positional_info(self, embeddings, doc_position, total_docs):\n        position_effect = torch.sin(torch.tensor(doc_position / total_docs, dtype=torch.float))\n        enhanced_embeddings = embeddings + position_effect\n        return enhanced_embeddings\n\n    def vectorize_document(self, chunks, section_headers, file_paths, doc_types):\n        all_embeddings = []\n        total_chunks = len(chunks)\n        for i, (chunk, header, path, doc_type) in enumerate(zip(chunks, section_headers, file_paths, doc_types)):\n            embedded_text = self.add_metadata(chunk, header, path, doc_type)\n            embeddings = self.tokenize_and_encode(embedded_text)\n            enhanced_embeddings = self.enhance_embedding_with_positional_info(embeddings, i, total_chunks)\n            all_embeddings.append(enhanced_embeddings)\n        document_embedding = torch.mean(torch.stack(all_embeddings), dim=0)\n        return SimpleVector(data=document_embedding.detach().numpy().tolist())\n\n    def vectorize(self, text):\n        inputs = self.tokenize_and_encode(text)\n        return SimpleVector(data=inputs.cpu().detach().numpy().tolist())\n\n    def fit(self, data):\n        # Although this vectorizer might not need to be fitted in the traditional sense,\n        # this method placeholder allows integration into pipelines that expect a fit method.\n        return self\n\n    def transform(self, data):\n        if isinstance(data, list):\n            return [self.vectorize(text).data for text in data]\n        else:\n            return self.vectorize(data).data\n\n    def fit_transform(self, data):\n        self.fit(data)\n        return self.transform(data)\n\n    def infer_vector(self, data, *args, **kwargs):\n        return self.vectorize(data)\n\n    def save_model(self, path):\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'tokenizer': self.tokenizer\n        }, path)\n    \n    def load_model(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.tokenizer = checkpoint['tokenizer']\n\n    def extract_feature(self, text):\n        inputs = self.tokenize_and_encode(text)\n        return SimpleVector(data=inputs.cpu().detach().numpy().tolist())\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/__init__.py",
        "content": "```swarmauri/standard/tracing/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/base/__init__.py",
        "content": "```swarmauri/standard/tracing/base/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/SimpleTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/SimpleTracer.py\nfrom datetime import datetime\nimport uuid\nfrom typing import Dict, Any, Optional\n\nfrom swarmauri.core.tracing.ITracer import ITracer\nfrom swarmauri.standard.tracing.concrete.SimpleTraceContext import SimpleTraceContext\n\nclass SimpleTracer(ITracer):\n    _instance = None  # Singleton instance placeholder\n\n    @classmethod\n    def instance(cls):\n        if cls._instance is None:\n            cls._instance = cls()\n        return cls._instance\n\n    def __init__(self):\n        if SimpleTracer._instance is not None:\n            raise RuntimeError(\"SimpleTracer is a singleton. Use SimpleTracer.instance().\")\n        self.trace_stack = []\n\n    def start_trace(self, name: str, initial_attributes: Optional[Dict[str, Any]] = None) -> SimpleTraceContext:\n        trace_id = str(uuid.uuid4())\n        trace_context = SimpleTraceContext(trace_id, name, initial_attributes)\n        self.trace_stack.append(trace_context)\n        return trace_context\n\n    def end_trace(self):\n        if self.trace_stack:\n            completed_trace = self.trace_stack.pop()\n            completed_trace.close()\n            # Example of simply printing the completed trace; in practice, you might log it or store it elsewhere\n            print(f\"Trace Completed: {completed_trace.name}, Duration: {completed_trace.start_time} to {completed_trace.end_time}, Attributes: {completed_trace.attributes}\")\n\n    def annotate_trace(self, key: str, value: Any):\n        if not self.trace_stack:\n            print(\"No active trace to annotate.\")\n            return\n        current_trace = self.trace_stack[-1]\n        current_trace.add_attribute(key, value)\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/TracedVariable.py",
        "content": "```swarmauri/standard/tracing/concrete/TracedVariable.py\nfrom typing import Any\nfrom swarmauri.standard.tracing.concrete.SimpleTracer import SimpleTracer  # Assuming this is the path to the tracer\n\nclass TracedVariable:\n    \"\"\"\n    Wrapper class to trace multiple changes to a variable within the context manager.\n    \"\"\"\n    def __init__(self, name: str, value: Any, tracer: SimpleTracer):\n        self.name = name\n        self._value = value\n        self._tracer = tracer\n        self._changes = []  # Initialize an empty list to track changes\n\n    @property\n    def value(self) -> Any:\n        return self._value\n\n    @value.setter\n    def value(self, new_value: Any):\n        # Record the change before updating the variable's value\n        change_annotation = {\"from\": self._value, \"to\": new_value}\n        self._changes.append(change_annotation)\n        \n        # Update the trace by appending the latest change to the list under a single key\n        # Note that the key is now constant and does not change with each update\n        self._tracer.annotate_trace(key=f\"{self.name}_changes\", value=self._changes)\n        \n        self._value = new_value\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/ChainTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/ChainTracer.py\nfrom swarmauri.core.tracing.IChainTracer import IChainTracer\nfrom typing import Callable, List, Tuple, Dict, Any   \n        \nclass ChainTracer(IChainTracer):\n    def __init__(self):\n        self.traces = []\n\n    def process_chain(self, chain: List[Tuple[Callable[..., Any], List[Any], Dict[str, Any]]]) -> \"ChainTracer\":\n        \"\"\"\n        Processes each item in the operation chain by executing the specified external function\n        with its args and kwargs. Logs starting, annotating, and ending the trace based on tuple position.\n\n        Args:\n            chain (List[Tuple[Callable[..., Any], List[Any], Dict[str, Any]]]): A list where each tuple contains:\n                - An external function to execute.\n                - A list of positional arguments for the function.\n                - A dictionary of keyword arguments for the function.\n        \"\"\"\n        for i, (func, args, kwargs) in enumerate(chain):\n            # Infer operation type and log\n            \n            if i == 0:\n                operation = \"Start\"\n                self.start_trace(*args, **kwargs)\n            elif i == len(chain) - 1:\n                operation = \"End\"\n                self.end_trace(*args, **kwargs)\n            else:\n                operation = \"Annotate\"\n                self.annotate_trace(*args, **kwargs)\n                \n            # For the actual external function call\n            result = func(*args, **kwargs)\n            print(f\"Function '{func.__name__}' executed with result: {result}\")\n\n            self.traces.append((operation, func, args, kwargs, result))\n\n        return self\n\n    def start_trace(self, *args, **kwargs) -> None:\n        print(f\"Starting trace with args: {args}, kwargs: {kwargs}\")\n        \n    def annotate_trace(self, *args, **kwargs) -> None:\n        print(f\"Annotating trace with args: {args}, kwargs: {kwargs}\")\n\n    def end_trace(self, *args, **kwargs) -> None:\n        print(f\"Ending trace with args: {args}, kwargs: {kwargs}\")\n\n    def show(self) -> None:\n        for entry in self.traces:\n            print(entry)\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/SimpleTraceContext.py",
        "content": "```swarmauri/standard/tracing/concrete/SimpleTraceContext.py\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\n\nfrom swarmauri.core.tracing.ITraceContext import ITraceContext\n\nclass SimpleTraceContext(ITraceContext):\n    def __init__(self, trace_id: str, name: str, initial_attributes: Optional[Dict[str, Any]] = None):\n        self.trace_id = trace_id\n        self.name = name\n        self.attributes = initial_attributes if initial_attributes else {}\n        self.start_time = datetime.now()\n        self.end_time = None\n\n    def get_trace_id(self) -> str:\n        return self.trace_id\n\n    def add_attribute(self, key: str, value: Any):\n        self.attributes[key] = value\n\n    def close(self):\n        self.end_time = datetime.now()\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/VariableTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/VariableTracer.py\nfrom contextlib import contextmanager\n\nfrom swarmauri.standard.tracing.concrete.TracedVariable import TracedVariable\nfrom swarmauri.standard.tracing.concrete.SimpleTracer import SimpleTracer\n\n# Initialize a global instance of SimpleTracer for use across the application\nglobal_tracer = SimpleTracer()\n\n@contextmanager\ndef VariableTracer(name: str, initial_value=None):\n    \"\"\"\n    Context manager for tracing the declaration, modification, and usage of a variable.\n    \"\"\"\n    trace_context = global_tracer.start_trace(name=f\"Variable: {name}\", initial_attributes={\"initial_value\": initial_value})\n    traced_variable = TracedVariable(name, initial_value, global_tracer)\n    \n    try:\n        yield traced_variable\n    finally:\n        # Optionally record any final value or state of the variable before it goes out of scope\n        global_tracer.annotate_trace(key=f\"{name}_final\", value={\"final_value\": traced_variable.value})\n        # End the trace, marking the variable's lifecycle\n        global_tracer.end_trace()\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/CallableTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/CallableTracer.py\nimport functools\nfrom swarmauri.standard.tracing.concrete.SimpleTracer import SimpleTracer  # Import SimpleTracer from the previously defined path\n\n# Initialize the global tracer object\ntracer = SimpleTracer()\n\ndef CallableTracer(func):\n    \"\"\"\n    A decorator to trace function or method calls, capturing inputs, outputs, and the caller.\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Trying to automatically identify the caller details; practical implementations \n        # might need to adjust based on specific requirements or environment.\n        caller_info = f\"{func.__module__}.{func.__name__}\"\n        \n        # Start a new trace context for this callable\n        trace_context = tracer.start_trace(name=caller_info, initial_attributes={'args': args, 'kwargs': kwargs})\n        \n        try:\n            # Call the actual function/method\n            result = func(*args, **kwargs)\n            tracer.annotate_trace(key=\"result\", value=result)\n            return result\n        except Exception as e:\n            # Optionally annotate the trace with the exception details\n            tracer.annotate_trace(key=\"exception\", value=str(e))\n            raise  # Re-raise the exception to not interfere with the program's flow\n        finally:\n            # End the trace after the function call is complete\n            tracer.end_trace()\n    return wrapper\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/__init__.py",
        "content": "```swarmauri/standard/tracing/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/__init__.py",
        "content": "```swarmauri/standard/chains/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/__init__.py",
        "content": "```swarmauri/standard/chains/base/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/ChainBase.py",
        "content": "```swarmauri/standard/chains/base/ChainBase.py\nfrom typing import List, Dict, Any\nfrom swarmauri.core.chains.IChain import IChain\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass ChainBase(IChain):\n    \"\"\"\n    A base implementation of the IChain interface.\n    \"\"\"\n\n    def __init__(self, \n                 steps: List[IChainStep] = None,\n                 **configs):\n        self.steps = steps if steps is not None else []\n        self.configs = configs\n\n    def add_step(self, step: IChainStep) -> None:\n        self.steps.append(step)\n\n    def remove_step(self, step: IChainStep) -> None:\n        \"\"\"\n        Removes an existing step from the chain. This alters the chain's execution sequence\n        by excluding the specified step from subsequent executions of the chain.\n\n        Parameters:\n            step (IChainStep): The Callable representing the step to remove from the chain.\n        \"\"\"\n\n        raise NotImplementedError('this is not yet implemented')\n\n    def execute(self, *args, **kwargs) -> Any:\n        raise NotImplementedError('this is not yet implemented')\n\n    def get_schema_info(self) -> Dict[str, Any]:\n        # Return a serialized version of the Chain instance's configuration\n        return {\n            \"steps\": [str(step) for step in self.steps],\n            \"configs\": self.configs\n        }\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/ChainStepBase.py",
        "content": "```swarmauri/standard/chains/base/ChainStepBase.py\nfrom typing import Any, Callable, List, Dict\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass ChainStepBase(IChainStep):\n    \"\"\"\n    Represents a single step within an execution chain.\n    \"\"\"\n    \n    def __init__(self, \n        key: str, \n        method: Callable, \n        args: List[Any] = None, \n        kwargs: Dict[str, Any] = None, \n        ref: str = None):\n        \"\"\"\n        Initialize a chain step.\n\n        Args:\n            key (str): Unique key or identifier for the step.\n            method (Callable): The callable object (function or method) to execute in this step.\n            args (List[Any], optional): Positional arguments for the callable.\n            kwargs (Dict[str, Any], optional): Keyword arguments for the callable.\n            ref (str, optional): Reference to another component or context variable, if applicable.\n        \"\"\"\n        self.key = key\n        self.method = method\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.ref = ref\n        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/__init__.py",
        "content": "```swarmauri/standard/chains/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/CallableChain.py",
        "content": "```swarmauri/standard/chains/concrete/CallableChain.py\nfrom typing import Any, Callable, List, Dict, Optional\nfrom swarmauri.core.chains.ICallableChain import ICallableChain, CallableDefinition\n\n\nclass CallableChain(ICallableChain):\n    def __init__(self, callables: Optional[List[CallableDefinition]] = None):\n        \n        self.callables = callables if callables is not None else []\n\n    def __call__(self, *initial_args, **initial_kwargs):\n        result = None\n        for func, args, kwargs in self.callables:\n            if result is not None:\n                # If there was a previous result, use it as the first argument for the next function\n                args = [result] + list(args)\n            result = func(*args, **kwargs)\n        return result\n    \n    def add_callable(self, func: Callable[[Any], Any], args: List[Any] = None, kwargs: Dict[str, Any] = None) -> None:\n        # Add a new callable to the chain\n        self.callables.append((func, args or [], kwargs or {}))\n    \n    def __or__(self, other: \"CallableChain\") -> \"CallableChain\":\n        if not isinstance(other, CallableChain):\n            raise TypeError(\"Operand must be an instance of CallableChain\")\n        \n        new_chain = CallableChain(self.callables + other.callables)\n        return new_chain\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/StateChain.py",
        "content": "```swarmauri/standard/chains/concrete/StateChain.py\nfrom typing import Any, Dict, List, Callable\nfrom swarmauri.standard.chains.base.ChainStepBase import ChainStepBase\nfrom swarmauri.core.chains.IChain import IChain\n\nclass StateChain(IChain):\n    \"\"\"\n    Enhanced to support ChainSteps with return parameters, storing return values as instance state variables.\n    Implements the IChain interface including get_schema_info and remove_step methods.\n    \"\"\"\n    def __init__(self):\n        self._steps: List[ChainStepBase] = []\n        self._context: Dict[str, Any] = {}\n    \n    def add_step(self, key: str, method: Callable[..., Any], *args, ref: str = None, **kwargs):\n        # Directly store args, kwargs, and optionally a return_key without resolving them\n        step = ChainStepBase(key, method, args=args, kwargs=kwargs, ref=ref)  # Note the use of 'ref' as 'return_key'\n        self._steps.append(step)\n    \n    def remove_step(self, step: ChainStepBase) -> None:\n        self._steps = [s for s in self._steps if s.key != step.key]\n    \n    def execute(self, *args, **kwargs) -> Any:\n        # Execute the chain and manage result storage based on return_key\n        for step in self._steps:\n            resolved_args = [self._resolve_placeholders(arg) for arg in step.args]\n            resolved_kwargs = {k: self._resolve_placeholders(v) for k, v in step.kwargs.items() if k != 'ref'}\n            result = step.method(*resolved_args, **resolved_kwargs)\n            if step.ref:  # step.ref is used here as the return_key analogy\n                print('step.ref', step.ref)\n                resolved_ref = self._resolve_ref(step.ref)\n                print(resolved_ref)\n                self._context[resolved_ref] = result\n        return self._context  # or any specific result you intend to return\n    \n    def _resolve_ref(self, value: Any) -> Any:\n        if isinstance(value, str) and value.startswith('${') and value.endswith('}'):\n            placeholder = value[2:-1]\n            return placeholder\n        return value\n    \n    def _resolve_placeholders(self, value: Any) -> Any:\n        if isinstance(value, str) and value.startswith('${') and value.endswith('}'):\n            placeholder = value[2:-1]\n            return self._context.get(placeholder)\n        return value\n\n    def set_context(self, **kwargs):\n        self._context.update(kwargs)\n    \n    def get_schema_info(self) -> Dict[str, Any]:\n        # Implementing required method from IChain; \n        # Adapt the return structure to your needs\n        return {\n            \"steps\": [step.key for step in self._steps],\n            \"context_keys\": list(self._context.keys())\n        }\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/ChainStep.py",
        "content": "```swarmauri/standard/chains/concrete/ChainStep.py\nfrom typing import Any, Callable, List, Dict\nfrom swarmauri.core.chains.IChainStep import IChainStep\nfrom swarmauri.standard.chains.base.ChainStepBase import ChainStepBase\n\nclass ChainStep(ChainStepBase):\n    \"\"\"\n    Represents a single step within an execution chain.\n    \"\"\"\n    \n    def __init__(self, \n        key: str, \n        method: Callable, \n        args: List[Any] = None, \n        kwargs: Dict[str, Any] = None, \n        ref: str = None):\n        \"\"\"\n        Initialize a chain step.\n\n        Args:\n            key (str): Unique key or identifier for the step.\n            method (Callable): The callable object (function or method) to execute in this step.\n            args (List[Any], optional): Positional arguments for the callable.\n            kwargs (Dict[str, Any], optional): Keyword arguments for the callable.\n            ref (str, optional): Reference to another component or context variable, if applicable.\n        \"\"\"\n        self.key = key\n        self.method = method\n        self.args = args \n        self.kwargs = kwargs\n        self.ref = ref\n        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/__init__.py",
        "content": "```swarmauri/standard/distances/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/base/__init__.py",
        "content": "```swarmauri/standard/distances/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/ChiSquaredDistance.py",
        "content": "```swarmauri/standard/distances/concrete/ChiSquaredDistance.py\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass ChiSquaredDistance(IDistanceSimilarity):\n    \"\"\"\n    Implementation of the IDistanceSimilarity interface using Chi-squared distance metric.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Chi-squared distance between two vectors.\n        \"\"\"\n        if len(vector_a.data) != len(vector_b.data):\n            raise ValueError(\"Vectors must have the same dimensionality.\")\n\n        chi_squared_distance = 0\n        for a, b in zip(vector_a.data, vector_b.data):\n            if (a + b) != 0:\n                chi_squared_distance += (a - b) ** 2 / (a + b)\n\n        return 0.5 * chi_squared_distance\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the similarity between two vectors based on the Chi-squared distance.\n        \"\"\"\n        return 1 / (1 + self.distance(vector_a, vector_b))\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/CosineDistance.py",
        "content": "```swarmauri/standard/distances/concrete/CosineDistance.py\nfrom numpy.linalg import norm\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.VectorProduct import VectorProduct\n\nclass CosineDistance(IDistanceSimilarity, VectorProduct):\n    \"\"\"\n    Implements cosine distance calculation as an IDistanceSimiliarity interface.\n    Cosine distance measures the cosine of the angle between two non-zero vectors\n    of an inner product space, capturing the orientation rather than the magnitude \n    of these vectors.\n    \"\"\"\n       \n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\" \n        Computes the cosine distance between two vectors: 1 - cosine similarity.\n    \n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n    \n        Returns:\n            float: The computed cosine distance between vector_a and vector_b.\n                   It ranges from 0 (completely similar) to 2 (completely dissimilar).\n        \"\"\"\n        norm_a = norm(vector_a.data)\n        norm_b = norm(vector_b.data)\n    \n        # Check if either of the vector norms is close to zero\n        if norm_a < 1e-10 or norm_b < 1e-10:\n            return 1.0  # Return maximum distance for cosine which varies between -1 to 1, so 1 indicates complete dissimilarity\n    \n        # Compute the cosine similarity between the vectors\n        cos_sim = self.dot_product(vector_a, vector_b) / (norm_a * norm_b)\n    \n        # Covert cosine similarity to cosine distance\n        cos_distance = 1 - cos_sim\n    \n        return cos_distance\n    \n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the cosine similarity between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The cosine similarity between vector_a and vector_b.\n        \"\"\"\n        return 1 - self.distance(vector_a, vector_b)\n\n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/EuclideanDistance.py",
        "content": "```swarmauri/standard/distances/concrete/EuclideanDistance.py\nfrom math import sqrt\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\n\nclass EuclideanDistance(IDistanceSimilarity):\n    \"\"\"\n    Class to compute the Euclidean distance between two vectors.\n    Implements the IDistanceSimiliarity interface.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Euclidean distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The computed Euclidean distance between vector_a and vector_b.\n        \"\"\"\n        if len(vector_a.data) != len(vector_b.data):\n            raise ValueError(\"Vectors do not have the same dimensionality.\")\n        \n        distance = sqrt(sum((a - b) ** 2 for a, b in zip(vector_a.data, vector_b.data)))\n        return distance\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the similarity score as the inverse of the Euclidean distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The similarity score between vector_a and vector_b.\n        \"\"\"\n        distance = self.distance(vector_a, vector_b)\n        return 1 / (1 + distance)\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/JaccardIndexDistance.py",
        "content": "```swarmauri/standard/distances/concrete/JaccardIndexDistance.py\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass JaccardIndexDistance(IDistanceSimilarity):\n    \"\"\"\n    A class implementing Jaccard Index as a similarity and distance metric between two vectors.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Jaccard distance between two vectors.\n\n        The Jaccard distance, which is 1 minus the Jaccard similarity,\n        measures dissimilarity between sample sets. It's defined as\n        1 - (the intersection of the sets divided by the union of the sets).\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector.\n\n        Returns:\n            float: The Jaccard distance between vector_a and vector_b.\n        \"\"\"\n        set_a = set(vector_a.data)\n        set_b = set(vector_b.data)\n\n        # Calculate the intersection and union of the two sets.\n        intersection = len(set_a.intersection(set_b))\n        union = len(set_a.union(set_b))\n\n        # In the special case where the union is zero, return 1.0 which implies complete dissimilarity.\n        if union == 0:\n            return 1.0\n\n        # Compute Jaccard similarity and then return the distance as 1 - similarity.\n        jaccard_similarity = intersection / union\n        return 1 - jaccard_similarity\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Jaccard similarity between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector.\n\n        Returns:\n            float: Jaccard similarity score between vector_a and vector_b.\n        \"\"\"\n        set_a = set(vector_a.data)\n        set_b = set(vector_b.data)\n\n        # Calculate the intersection and union of the two sets.\n        intersection = len(set_a.intersection(set_b))\n        union = len(set_a.union(set_b))\n\n        # In case the union is zero, which means both vectors have no elements, return 1.0 implying identical sets.\n        if union == 0:\n            return 1.0\n\n        # Compute and return Jaccard similarity.\n        return intersection / union\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/LevenshteinDistance.py",
        "content": "```swarmauri/standard/distances/concrete/LevenshteinDistance.py\nfrom typing import List\nimport numpy as np\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass LevenshteinDistance(IDistanceSimilarity):\n    \"\"\"\n    Implements the IDistance interface to calculate the Levenshtein distance between two vectors.\n    The Levenshtein distance between two strings is given by the minimum number of operations needed to transform\n    one string into the other, where an operation is an insertion, deletion, or substitution of a single character.\n    \"\"\"\n    \n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the Levenshtein distance between two vectors.\n\n        Note: Since Levenshtein distance is typically calculated between strings,\n        it is assumed that the vectors represent strings where each element of the\n        vector corresponds to the ASCII value of a character in the string.\n\n        Args:\n            vector_a (List[float]): The first vector in the comparison.\n            vector_b (List[float]): The second vector in the comparison.\n\n        Returns:\n           float: The computed Levenshtein distance between vector_a and vector_b.\n        \"\"\"\n        string_a = ''.join([chr(int(round(value))) for value in vector_a.data])\n        string_b = ''.join([chr(int(round(value))) for value in vector_b.data])\n        \n        return self.levenshtein(string_a, string_b)\n    \n    def levenshtein(self, seq1: str, seq2: str) -> float:\n        \"\"\"\n        Calculate the Levenshtein distance between two strings.\n        \n        Args:\n            seq1 (str): The first string.\n            seq2 (str): The second string.\n        \n        Returns:\n            float: The Levenshtein distance between seq1 and seq2.\n        \"\"\"\n        size_x = len(seq1) + 1\n        size_y = len(seq2) + 1\n        matrix = np.zeros((size_x, size_y))\n        \n        for x in range(size_x):\n            matrix[x, 0] = x\n        for y in range(size_y):\n            matrix[0, y] = y\n\n        for x in range(1, size_x):\n            for y in range(1, size_y):\n                if seq1[x-1] == seq2[y-1]:\n                    matrix[x, y] = min(matrix[x-1, y] + 1, matrix[x-1, y-1], matrix[x, y-1] + 1)\n                else:\n                    matrix[x, y] = min(matrix[x-1, y] + 1, matrix[x-1, y-1] + 1, matrix[x, y-1] + 1)\n        \n        return matrix[size_x - 1, size_y - 1]\n    \n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        string_a = ''.join([chr(int(round(value))) for value in vector_a.data])\n        string_b = ''.join([chr(int(round(value))) for value in vector_b.data])\n        return 1 - self.levenshtein(string_a, string_b) / max(len(vector_a), len(vector_b))\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/__init__.py",
        "content": "```swarmauri/standard/distances/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/__init__.py",
        "content": "```swarmauri/standard/metrics/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/__init__.py",
        "content": "```swarmauri/standard/metrics/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/MetricBase.py",
        "content": "```swarmauri/standard/metrics/base/MetricBase.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.metrics.IMetric import IMetric\n\nclass MetricBase(IMetric, ABC):\n    \"\"\"\n    A base implementation of the IMetric interface that provides the foundation\n    for specific metric implementations.\n    \"\"\"\n\n    def __init__(self, name: str, unit: str):\n        \"\"\"\n        Initializes the metric with a name and unit of measurement.\n\n        Args:\n            name (str): The name of the metric.\n            unit (str): The unit of measurement for the metric (e.g., 'seconds', 'accuracy').\n        \"\"\"\n        self._name = name\n        self._unit = unit\n        self._value = None  # Initialize with None, or a default value as appropriate\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        The metric's name identifier.\n        \"\"\"\n        return self._name\n\n    @property\n    def value(self) -> Any:\n        \"\"\"\n        The current value of the metric.\n        \"\"\"\n        return self._value\n\n    @property\n    def unit(self) -> str:\n        \"\"\"\n        The unit of measurement for the metric.\n        \"\"\"\n        return self._unit\n\n    @unit.setter\n    def unit(self, value: str) -> None:\n        \"\"\"\n        Set the unit of measurement for the metric.\n        \"\"\"\n        self._unit = value\n\n    @abstractmethod\n    def __call__(self, **kwargs) -> Any:\n        \"\"\"\n        Retrieves the current value of the metric.\n\n        Returns:\n            The current value of the metric.\n        \"\"\"\n        return self.value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/CalculateMetricBase.py",
        "content": "```swarmauri/standard/metrics/base/CalculateMetricBase.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.metrics.IMetric import IMetric\nfrom swarmauri.core.metrics.ICalculateMetric import ICalculateMetric\n\nclass CalculateMetricBase(IMetric, ICalculateMetric, ABC):\n    \"\"\"\n    A base implementation of the IMetric interface that provides the foundation\n    for specific metric implementations.\n    \"\"\"\n\n    def __init__(self, name: str, unit: str):\n        \"\"\"\n        Initializes the metric with a name and unit of measurement.\n\n        Args:\n            name (str): The name of the metric.\n            unit (str): The unit of measurement for the metric (e.g., 'seconds', 'accuracy').\n        \"\"\"\n        self._name = name\n        self._unit = unit\n        self._value = None  # Initialize with None, or a default value as appropriate\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        The metric's name identifier.\n        \"\"\"\n        return self._name\n\n    @property\n    def value(self):\n        \"\"\"\n        The current value of the metric.\n        \"\"\"\n        return self._value\n\n    @property\n    def unit(self) -> str:\n        \"\"\"\n        The unit of measurement for the metric.\n        \"\"\"\n        return self._unit\n\n    @unit.setter\n    def unit(self, value: str) -> None:\n        \"\"\"\n        Set the unit of measurement for the metric.\n        \"\"\"\n        self._unit = value\n\n    @abstractmethod\n    def calculate(self, **kwargs) -> Any:\n        \"\"\"\n        Calculate the metric based on the provided data.\n        This method must be implemented by subclasses to define specific calculation logic.\n        \"\"\"\n        raise NotImplementedError('calculate is not implemented yet.')\n\n    def update(self, value) -> None:\n        \"\"\"\n        Update the metric value based on new information.\n        This should be used internally by the `calculate` method or other logic.\n        \"\"\"\n        self._value = value\n\n    def __call__(self, **kwargs) -> Any:\n        \"\"\"\n        Calculates the metric, updates the value, and returns the current value.\n        \"\"\"\n        self.calculate(**kwargs)\n        return self.value\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/AggregateMetricBase.py",
        "content": "```swarmauri/standard/metrics/base/AggregateMetricBase.py\nfrom typing import List, Any\nfrom abc import ABC, abstractmethod\nfrom swarmauri.standard.metrics.base.CalculateMetricBase import CalculateMetricBase\nfrom swarmauri.core.metrics.IAggMeasurements import IAggMeasurements\n\nclass AggregateMetricBase(CalculateMetricBase, IAggMeasurements, ABC):\n    \"\"\"\n    An abstract base class that implements the IMetric interface, providing common \n    functionalities and properties for metrics within SwarmAURI.\n    \"\"\"\n    def __init__(self, name: str, unit: str):\n        CalculateMetricBase.__init__(name, unit)\n        self._measurements = []\n\n    @abstractmethod\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds measurement to the internal store of measurements.\n        \"\"\"\n        self._measurements.append(measurement)\n\n    @property\n    def measurements(self) -> List[Any]:\n        return self._measurements\n\n    @measurements.setter\n    def measurements(self, value) -> None:\n        self._measurements = value\n\n    def reset(self) -> None:\n        \"\"\"\n        Resets the metric's state/value, allowing for fresh calculations.\n        \"\"\"\n        self._measurements.clear()\n        self._value = None\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/ThresholdMetricBase.py",
        "content": "```swarmauri/standard/metrics/base/ThresholdMetricBase.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\nfrom swarmauri.core.metrics.IAggMeasurements import IAggMeasurements\nfrom swarmauri.core.metrics.IThreshold import IThreshold\n\nclass ThresholdMetricBase(AggregateMetricBase, IAggMeasurements, ABC):\n    \"\"\"\n    An abstract base class that implements the IMetric interface, providing common \n    functionalities and properties for metrics within SwarmAURI.\n    \"\"\"\n    def __init__(self, name: str, unit: str, k: int):\n        AggregateMetricBase.__init__(name, unit)\n        self._k = k\n\n    @property\n    @abstractmethod\n    def k(self) -> int:\n        return self._k\n\n    @k.setter\n    @abstractmethod\n    def k(self, value: int) -> None:\n        self._k = value\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/__init__.py",
        "content": "```swarmauri/standard/metrics/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/TaskSuccessRateMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/TaskSuccessRateMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass TaskSuccessRateMetric(AggregateMetricBase):\n    \"\"\"\n    Metric calculating the task success rate over all attempted tasks.\n    \"\"\"\n    \n    def __init__(self):\n        super().__init__(name=\"TaskSuccessRate\", unit=\"percentage\")\n        self.total_tasks = 0\n        self.successful_tasks = 0\n\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds a task outcome to the metrics. Measurement should be a boolean indicating task success.\n        \"\"\"\n        self.total_tasks += 1\n        if measurement:\n            self.successful_tasks += 1\n\n    def calculate(self, **kwargs) -> float:\n        \"\"\"\n        Calculate the success rate of tasks based on the total and successful tasks.\n\n        Returns:\n            float: The success rate as a percentage.\n        \"\"\"\n        if self.total_tasks == 0:\n            return 0.0\n        success_rate = (self.successful_tasks / self.total_tasks) * 100\n        self.update(success_rate)\n        return self.value\n    \n    @property\n    def measurements(self):\n        return {\"total_tasks\": self.total_tasks, \"successful_tasks\": self.successful_tasks} \n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/TimeOnTaskMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/TimeOnTaskMetric.py\nimport statistics\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass TimeOnTaskMetric(AggregateMetricBase):\n    \"\"\"\n    Metric to calculate the average time users spend on a given task.\n    \"\"\"\n    def __init__(self, name=\"Time on Task\", unit=\"seconds\"):\n        super().__init__(name, unit)\n\n    def calculate(self, **kwargs):\n        \"\"\"\n        Calculate the average time on task based on the collected measurements.\n        \"\"\"\n        if not self.measurements:\n            return 0\n        return statistics.mean(self.measurements)\n\n    def add_measurement(self, seconds: float) -> None:\n        \"\"\"\n        Adds a measurement of time (in seconds) that a user spent on a task.\n        \"\"\"\n        if seconds < 0:\n            raise ValueError(\"Time on task cannot be negative.\")\n        super().add_measurement(seconds)\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/StaticValueMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/StaticValueMetric.py\nfrom swarmauri.standard.metrics.base.MetricBase import MetricBase\n\n# Implementing a StaticValueMetric class\nclass StaticValueMetric(MetricBase):\n    \"\"\"\n    A static metric that always returns a fixed, predefined value.\n    \n    Attributes:\n        name (str): The name of the metric.\n        unit (str): The unit of measurement for the metric.\n        _value (Any): The static value of the metric.\n    \"\"\"\n    def __init__(self, name: str, unit: str, value):\n        \"\"\"\n        Initialize the static metric with its name, unit, and static value.\n\n        Args:\n            name (str): The name identifier for the metric.\n            unit (str): The unit of measurement for the metric.\n            value: The static value for this metric.\n        \"\"\"\n        # Initialize attributes from the base class\n        super().__init__(name, unit)\n        # Assign the static value\n        self._value = value\n\n    # Overriding the 'value' property to always return the static value\n    @property\n    def value(self):\n        \"\"\"\n        Overridden to return the predefined static value for this metric.\n        \"\"\"\n        return self._value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/MeanMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/MeanMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass MeanMetric(AggregateMetricBase):\n    \"\"\"\n    A metric that calculates the mean (average) of a list of numerical values.\n\n    Attributes:\n        name (str): The name of the metric.\n        unit (str): The unit of measurement for the mean (e.g., \"degrees\", \"points\").\n        _value (float): The calculated mean of the measurements.\n        _measurements (list): A list of measurements (numerical values) to average.\n    \"\"\"\n    def __init__(self, name: str, unit: str):\n        \"\"\"\n        Initialize the MeanMetric with its name and unit.\n\n        Args:\n            name (str): The name identifier for the metric.\n            unit (str): The unit of measurement for the mean.\n        \"\"\"\n        # Calling the constructor of the base class\n        super().__init__(name, unit)\n    \n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds a measurement to the internal list of measurements.\n\n        Args:\n            measurement (float): A numerical value to be added to the list of measurements.\n        \"\"\"\n        # Append the measurement to the internal list\n        self._measurements.append(measurement)\n\n    def calculate(self) -> float:\n        \"\"\"\n        Calculate the mean of all added measurements.\n        \n        Returns:\n            float: The mean of the measurements or None if no measurements have been added.\n        \"\"\"\n        if not self._measurements:\n            return None  # Return None if there are no measurements\n        # Calculate the mean\n        mean = sum(self._measurements) / len(self._measurements)\n        # Update the metric's value\n        self.update(mean)\n        # Return the calculated mean\n        return mean\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/ThresholdMeanMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/ThresholdMeanMetric.py\nfrom swarmauri.standard.metrics.base.ThresholdMetricBase import ThresholdMetricBase\n\nclass ThresholdMeanMetric(ThresholdMetricBase):\n    \"\"\"\n    Calculates the mean of measurements that fall within a specified threshold from the current mean.\n    \"\"\"\n\n    def is_within_threshold(self, measurement: float) -> bool:\n        if self._value is None:  # If there's no current value, accept the measurement\n            return True\n        return abs(measurement - self._value) <= self.threshold\n    \n    def calculate(self) -> float:\n        # Filtering the measurements based on the threshold\n        filtered_measurements = [m for m in self._measurements if self.is_within_threshold(m)]\n\n        # Calculate the mean of filtered measurements\n        if not filtered_measurements:\n            return None  # Return None if there are no measurements within the threshold\n\n        mean_value = sum(filtered_measurements) / len(filtered_measurements)\n        self.update(mean_value)\n        return mean_value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/ZeroMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/ZeroMetric.py\nfrom swarmauri.standard.metrics.base.MetricBase import MetricBase\n\nclass ZeroMetric(MetricBase):\n    \"\"\"\n    A concrete implementation of MetricBase that statically represents the value 0.\n    This can be used as a placeholder or default metric where dynamic calculation is not required.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(name=\"ZeroMetric\", unit=\"unitless\")\n\n    @property\n    def value(self):\n        \"\"\"\n        Overrides the value property to always return 0.\n        \"\"\"\n        return 0\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/SystemUsabilityScaleMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/SystemUsabilityScaleMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass SystemUsabilityScaleMetric(AggregateMetricBase):\n    \"\"\"\n    Metric calculating the System Usability Scale (SUS) score based on a set of questionnaire responses.\n    \"\"\"\n    \n    def __init__(self):\n        super().__init__(name=\"SystemUsabilityScale\", unit=\"SUS score\")\n\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds individual SUS questionnaire item scores (ranging from 0-4) to the measurements.\n        \"\"\"\n        if isinstance(measurement, list) and all(isinstance(item, int) and 0 <= item <= 4 for item in measurement):\n            self._measurements.extend(measurement)\n        else:\n            raise ValueError(\"Each measurement must be a list of integers between 0 and 4.\")\n\n    def calculate(self, **kwargs) -> float:\n        \"\"\"\n        Calculate the SUS score from the current measurements.\n        \n        Returns:\n            float: The calculated SUS score.\n        \"\"\"\n        if len(self._measurements) != 10:\n            raise ValueError(\"Exactly 10 measurements are required to calculate the SUS score.\")\n        \n        # Adjust scores for negative items: subtract each score from 4\n        adjusted_scores = [self._measurements[i] if i % 2 == 0 else 4 - self._measurements[i] for i in range(10)]\n        \n        # Calculate the SUS score: multiply the sum of scores by 2.5\n        sus_score = sum(adjusted_scores) * 2.5\n        self.update(sus_score)\n        return self.value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/FirstImpressionMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/FirstImpressionMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass FirstImpressionMetric(AggregateMetricBase):\n    \"\"\"\n    Metric for capturing the first impression score from a set of scores.\n    \"\"\"\n\n    def __init__(self, name=\"FirstImpressionScore\", unit=\"points\"):\n        super().__init__(name=name, unit=unit)\n        self._first_impression = None\n\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds a new score as a measurement. Only the first score is considered as the first impression.\n        \"\"\"\n        if self._first_impression is None:\n            if isinstance(measurement, (int, float)):\n                self._first_impression = measurement\n                self._measurements.append(measurement)\n            else:\n                raise ValueError(\"Measurement must be a numerical value.\")\n    \n    def calculate(self) -> float:\n        \"\"\"\n        Returns the first impression score.\n\n        Returns:\n            float: The first impression score.\n        \"\"\"\n        if self._first_impression is None:\n            raise ValueError(\"No measurement added. Unable to calculate first impression score.\")\n        \n        self.update(self._first_impression)\n        return self.value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/HitRateAtK.py",
        "content": "```swarmauri/standard/metrics/concrete/HitRateAtK.py\nfrom typing import List, Tuple, Any\nfrom swarmauri.standard.metrics.base.ThresholdMetricBase import ThresholdMetricBase\n\nclass HitRateAtK(ThresholdMetricBase):\n    \"\"\"\n    Hit Rate at K (HR@K) metric calculates the proportion of times an item of interest \n    appears in the top-K recommendations.\n    \"\"\"\n\n    def __init__(self, name=\"HitRate@K\", unit=\"ratio\", k: int = 5):\n        \"\"\"\n        Initializes the Hit Rate at K metric with a specified k value, name, and unit \n        of measurement.\n        \n        Args:\n            k (int): The k value for the top-K recommendations.\n            name (str): The name of the metric.\n            unit (str): The unit of measurement for the metric.\n        \"\"\"\n        super().__init__(name=name, unit=unit, k=k)\n\n    def add_measurement(self, measurement: Tuple[List[Any], Any]) -> None:\n        \"\"\"\n        Adds a measurement for HR@K calculation. The measurement should be a tuple\n        (recommendations, target), where recommendations is a list of recommended items, \n        and target is the item of interest.\n\n        Args:\n            measurement (Tuple[List[Any], Any]): List of recommended items and the target item.\n        \"\"\"\n        if len(measurement) != 2 or not isinstance(measurement[0], list):\n            raise ValueError(\"Measurement must be a tuple (recommendations, target).\")\n        self._measurements.append(measurement)\n\n    def calculate(self) -> Any:\n        \"\"\"\n        Calculate the HR@K based on the provided measurements.\n\n        Returns:\n            Any: The HR@K score as a floating point number.\n        \"\"\"\n        if not self._measurements:\n            raise ValueError(\"No measurements added to calculate HR@K.\")\n\n        hits = 0\n        for recommendations, target in self._measurements:\n            hits += 1 if target in recommendations[:self.k] else 0\n\n        hit_rate_at_k = hits / len(self._measurements)\n\n        self.update(hit_rate_at_k)\n        return self.value\n\n    def reset(self) -> None:\n        \"\"\"\n        Resets the metric's state/value, allowing for fresh calculations.\n        \"\"\"\n        super().reset()\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/ImpressionAtK.py",
        "content": "```swarmauri/standard/metrics/concrete/ImpressionAtK.py\nfrom swarmauri.standard.metrics.base.ThresholdMetricBase import ThresholdMetricBase\n\nclass ImpressionAtKMetric(ThresholdMetricBase):\n    def __init__(self, k: int):\n        super().__init__(name=\"Impression at K\", unit=\"count\", k=k)\n    \n    def calculate(self, impressions, **kwargs):\n        if not isinstance(impressions, list):\n            raise ValueError(\"Impressions should be provided as a list\")\n        \n        k_impressions = impressions[:self._k] if len(impressions) >= self._k else impressions\n\n        self._value = len([imp for imp in k_impressions if imp > 0])\n        return self._value\n\n    def reset(self):\n        self._value = 0\n    \n    def update(self, value):\n        raise NotImplementedError(\"This Metric does not support update operation directly.\")\n    \n    def __call__(self, **kwargs):\n        \"\"\"\n        Retrieves the current value of the metric.\n        \n        Returns:\n            The current value of the metric if calculated; otherwise, triggers a calculation.\n        \"\"\"\n        if 'impressions' in kwargs:\n            return self.calculate(kwargs['impressions'])\n        return self._value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/__init__.py",
        "content": "```swarmauri/standard/agent_factories/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/base/__init__.py",
        "content": "```swarmauri/standard/agent_factories/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/AgentFactory.py",
        "content": "```swarmauri/standard/agent_factories/concrete/AgentFactory.py\nimport json\nfrom datetime import datetime\nfrom typing import Callable, Dict, Any\nfrom swarmauri.core.agents.IAgent import IAgent\nfrom swarmauri.core.agentfactories.IAgentFactory import IAgentFactory\nfrom swarmauri.core.agentfactories.IExportConf import IExportConf\n\nclass AgentFactory(IAgentFactory, IExportConf):\n    def __init__(self):\n        \"\"\" Initializes the AgentFactory with an empty registry and metadata. \"\"\"\n        self._registry: Dict[str, Callable[..., IAgent]] = {}\n        self._metadata = {\n            'id': None,\n            'name': 'DefaultAgentFactory',\n            'type': 'Generic',\n            'date_created': datetime.now(),\n            'last_modified': datetime.now()\n        }\n    \n    # Implementation of IAgentFactory methods\n    def create_agent(self, agent_type: str, **kwargs) -> IAgent:\n        if agent_type not in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is not registered.\")\n        \n        constructor = self._registry[agent_type]\n        return constructor(**kwargs)\n\n    def register_agent(self, agent_type: str, constructor: Callable[..., IAgent]) -> None:\n        if agent_type in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is already registered.\")\n        self._registry[agent_type] = constructor\n        self._metadata['last_modified'] = datetime.now()\n    \n    # Implementation of IExportConf methods\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Exports the registry metadata as a dictionary.\"\"\"\n        export_data = self._metadata.copy()\n        export_data['registry'] = list(self._registry.keys())\n        return export_data\n\n    def to_json(self) -> str:\n        \"\"\"Exports the registry metadata as a JSON string.\"\"\"\n        return json.dumps(self.to_dict(), default=str, indent=4)\n\n    def export_to_file(self, file_path: str) -> None:\n        \"\"\"Exports the registry metadata to a file.\"\"\"\n        with open(file_path, 'w') as f:\n            f.write(self.to_json())\n    \n    @property\n    def id(self) -> int:\n        return self._metadata['id']\n\n    @id.setter\n    def id(self, value: int) -> None:\n        self._metadata['id'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def name(self) -> str:\n        return self._metadata['name']\n\n    @name.setter\n    def name(self, value: str) -> None:\n        self._metadata['name'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def type(self) -> str:\n        return self._metadata['type']\n\n    @type.setter\n    def type(self, value: str) -> None:\n        self._metadata['type'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def date_created(self) -> datetime:\n        return self._metadata['date_created']\n\n    @property\n    def last_modified(self) -> datetime:\n        return self._metadata['last_modified']\n\n    @last_modified.setter\n    def last_modified(self, value: datetime) -> None:\n        self._metadata['last_modified'] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/ConfDrivenAgentFactory.py",
        "content": "```swarmauri/standard/agent_factories/concrete/ConfDrivenAgentFactory.py\nimport json\nimport importlib\nfrom datetime import datetime\nfrom typing import Any, Dict, Callable\nfrom swarmauri.core.agents.IAgent import IAgent  # Replace with the correct IAgent path\nfrom swarmauri.core.agentfactories.IAgentFactory import IAgentFactory\nfrom swarmauri.core.agentfactories.IExportConf import IExportConf\n\n\nclass ConfDrivenAgentFactory(IAgentFactory, IExportConf):\n    def __init__(self, config_path: str):\n        self._config_path = config_path\n        self._config = self._load_config(config_path)\n        self._registry = {}\n        self._metadata = {\n            'id': None,\n            'name': 'ConfAgentFactory',\n            'type': 'Configurable',\n            'date_created': datetime.now(),\n            'last_modified': datetime.now()\n        }\n        \n        self._initialize_registry()\n\n    def _load_config(self, config_path: str) -> Dict[str, Any]:\n        with open(config_path, 'r') as file:\n            return json.load(file)\n    \n    def _initialize_registry(self) -> None:\n        for agent_type, agent_info in self._config.get(\"agents\", {}).items():\n            module_name, class_name = agent_info[\"class_path\"].rsplit('.', 1)\n            module = importlib.import_module(module_name)\n            cls = getattr(module, class_name)\n            self.register_agent(agent_type, cls)\n    \n    # Implementation of IAgentFactory methods\n    def create_agent(self, agent_type: str, **kwargs) -> IAgent:\n        if agent_type not in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is not registered.\")\n        \n        return self._registry[agent_type](**kwargs)\n\n    def register_agent(self, agent_type: str, constructor: Callable[..., IAgent]) -> None:\n        self._registry[agent_type] = constructor\n        self._metadata['last_modified'] = datetime.now()\n    \n    # Implementation of IExportConf methods\n    def to_dict(self) -> Dict[str, Any]:\n        return self._metadata.copy()\n\n    def to_json(self) -> str:\n        return json.dumps(self.to_dict(), default=str, indent=4)\n\n    def export_to_file(self, file_path: str) -> None:\n        with open(file_path, 'w') as f:\n            f.write(self.to_json())\n\n    # Additional methods to implement required properties and their setters\n    # Implementing getters and setters for metadata properties as needed\n    @property\n    def id(self) -> int:\n        return self._metadata['id']\n\n    @id.setter\n    def id(self, value: int) -> None:\n        self._metadata['id'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def name(self) -> str:\n        return self._metadata['name']\n\n    @name.setter\n    def name(self, value: str) -> None:\n        self._metadata['name'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def type(self) -> str:\n        return self._metadata['type']\n\n    @type.setter\n    def type(self, value: str) -> None:\n        self._metadata['type'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def date_created(self) -> datetime:\n        return self._metadata['date_created']\n\n    @property\n    def last_modified(self) -> datetime:\n        return self._metadata['last_modified']\n\n    @last_modified.setter\n    def last_modified(self, value: datetime) -> None:\n        self._metadata['last_modified'] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/ReflectiveAgentFactory.py",
        "content": "```swarmauri/standard/agent_factories/concrete/ReflectiveAgentFactory.py\nimport importlib\nfrom datetime import datetime\nimport json\nfrom typing import Callable, Dict, Type, Any\nfrom swarmauri.core.agents.IAgent import IAgent  # Update this import path as needed\nfrom swarmauri.core.agentfactories.IAgentFactory import IAgentFactory\nfrom swarmauri.core.agentfactories.IExportConf import IExportConf\n\nclass ReflectiveAgentFactory(IAgentFactory, IExportConf):\n    def __init__(self):\n        self._registry: Dict[str, Type[IAgent]] = {}\n        self._metadata = {\n            'id': None,\n            'name': 'ReflectiveAgentFactory',\n            'type': 'Reflective',\n            'date_created': datetime.now(),\n            'last_modified': datetime.now()\n        }\n\n    def create_agent(self, agent_type: str, **kwargs) -> IAgent:\n        if agent_type not in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is not registered.\")\n        \n        agent_class = self._registry[agent_type]\n        return agent_class(**kwargs)\n\n    def register_agent(self, agent_type: str, class_path: str) -> None:\n        module_name, class_name = class_path.rsplit('.', 1)\n        module = importlib.import_module(module_name)\n        cls = getattr(module, class_name)\n        self._registry[agent_type] = cls\n        self._metadata['last_modified'] = datetime.now()\n\n    # Implementations for the IExportConf interface\n    def to_dict(self) -> Dict[str, Any]:\n        return self._metadata.copy()\n\n    def to_json(self) -> str:\n        return json.dumps(self.to_dict(), default=str, indent=4)\n\n    def export_to_file(self, file_path: str) -> None:\n        with open(file_path, 'w') as file:\n            file.write(self.to_json())\n\n    # Property implementations: id, name, type, date_created, and last_modified\n    @property\n    def id(self) -> int:\n        return self._metadata['id']\n\n    @id.setter\n    def id(self, value: int) -> None:\n        self._metadata['id'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def name(self) -> str:\n        return self._metadata['name']\n\n    @name.setter\n    def name(self, value: str) -> None:\n        self._metadata['name'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def type(self) -> str:\n        return self._metadata['type']\n\n    @type.setter\n    def type(self, value: str) -> None:\n        self._metadata['type'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def date_created(self) -> datetime:\n        return self._metadata['date_created']\n\n    @property\n    def last_modified(self) -> datetime:\n        return self._metadata['last_modified']\n\n    @last_modified.setter\n    def last_modified(self, value: datetime) -> None:\n        self._metadata['last_modified'] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/__init__.py",
        "content": "```swarmauri/standard/agent_factories/concrete/__init__.py\n\n```"
    }
]