[
    {
        "document_name": "swarmauri/__init__.py",
        "content": "```swarmauri/__init__.py\n__version__ = \"0.1.124.dev3\"\n__long_desc__ = \"\"\"\n# swarmaURI sdk\n\nThis repository includes core interfaces, standard ABCs, and standard concrete references of the SwarmaURI Framework.\n\n\n## Core \n- ABCs\n- Utilities\n\n## Standard\n- Concrete Classes\n\n## Community\n- Concrete Classes that utilize third party plug-ins\n\n## Experimental\n- Tools in development\n\n\n\"\"\"\n```"
    },
    {
        "document_name": "swarmauri/community/__init__.py",
        "content": "```swarmauri/community/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/community/tools/__init__.py",
        "content": "```swarmauri/community/tools/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/community/tools/base/__init__.py",
        "content": "```swarmauri/community/tools/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/__init__.py",
        "content": "```swarmauri/community/tools/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/EntityRecognitionTool.py",
        "content": "```swarmauri/community/tools/concrete/EntityRecognitionTool.py\nimport json\nfrom transformers import pipeline, logging as hf_logging\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\nhf_logging.set_verbosity_error()\n\nclass EntityRecognitionTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\"text\",\"string\",\"The text for entity recognition\",True)\n        ]\n        super().__init__(name=\"EntityRecognitionTool\", \n                         description=\"Extracts named entities from text\", \n                         parameters=parameters)\n        \n\n    def __call__(self, text: str) -> dict:\n        try:\n            self.nlp = pipeline(\"ner\")\n            entities = self.nlp(text)\n            organized_entities = {}\n            for entity in entities:\n                if entity['entity'] not in organized_entities:\n                    organized_entities[entity['entity']] = []\n                organized_entities[entity['entity']].append(entity['word'])\n            return json.dumps(organized_entities)\n        except Exception as e:\n            raise e\n        finally:\n            del self.nlp\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/GmailSendTool.py",
        "content": "```swarmauri/community/tools/concrete/GmailSendTool.py\nimport base64\nimport json\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom googleapiclient import discovery\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\nclass GmailSendTool(ToolBase):\n    SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n\n    def __init__(self, credentials_path: str, sender_email: str):\n        \"\"\"\n        Initializes the GmailSendTool with a path to the credentials JSON file and the sender email.\n\n        Parameters:\n        credentials_path (str): The path to the Gmail service JSON file.\n        sender_email (str): The email address being used to send emails.\n        \"\"\"\n        \n        parameters = [\n            Parameter(\n                name=\"recipients\",\n                type=\"string\",\n                description=\"The email addresses of the recipients, separated by commas\",\n                required=True\n            ),\n            Parameter(\n                name=\"subject\",\n                type=\"string\",\n                description=\"The subject of the email\",\n                required=True\n            ),\n            Parameter(\n                name=\"htmlMsg\",\n                type=\"string\",\n                description=\"The HTML message to be sent as the email body\",\n                required=True\n            )\n        ]\n        \n        super().__init__(name=\"GmailSendTool\", \n                         description=\"Sends an email using the Gmail API.\",\n                         parameters=parameters)\n        self.credentials_path = credentials_path\n        self.sender_email = sender_email\n        \n\n    def authenticate(self):\n        \"\"\"\n        Authenticates the user and creates a Gmail API service for sending emails.\n        \"\"\"\n        credentials = service_account.Credentials.from_service_account_file(\n                self.credentials_path, scopes=self.SCOPES)\n        \n        delegated_credentials = credentials.with_subject(self.sender_email)\n        self.service = build('gmail', 'v1', credentials=delegated_credentials)\n\n    def create_message(self, to: str, subject: str, message_text: str):\n        \"\"\"\n        Create a MIMEText message for sending an email.\n\n        Parameters:\n        sender (str): The email address of the sender.\n        to (str): The email address of the recipient.\n        subject (str): The subject of the email.\n        message_text (str): The HTML body of the email.\n\n        Returns:\n        The created MIMEText message.\n        \"\"\"\n        message = MIMEMultipart('alternative')\n        message['from'] = self.sender_email\n        message['to'] = to\n        message['subject'] = subject\n        mime_text = MIMEText(message_text, 'html')\n        message.attach(mime_text)\n        raw_message = base64.urlsafe_b64encode(message.as_string().encode('utf-8'))\n        return {'raw': raw_message.decode('utf-8')}\n\n    def __call__(self, recipients, subject, htmlMsg):\n        \"\"\"\n        Sends an email to the specified recipients with the given subject and HTML message.\n        \n        Parameters:\n        sender (str): The email address of the sender.\n        recipients (str): The email address of the recipients, separated by commas.\n        subject (str): The subject of the email.\n        htmlMsg (str): The HTML content of the email body.\n\n        Returns:\n        The result of sending the email or an error message if the operation fails.\n        \"\"\"\n        self.authenticate()\n        try:\n            message = self.create_message(recipients, subject, htmlMsg)\n            sent_message = (self.service.users().messages().send(userId='me', body=message).execute())\n            return f\"Email sent successfully to {recipients}\"\n\n        except Exception as e:\n            return f\"An error occurred in sending the email: {e}\"\n        finally:\n            del self.service\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/GmailReadTool.py",
        "content": "```swarmauri/community/tools/concrete/GmailReadTool.py\nimport base64\nimport json\nfrom googleapiclient import discovery\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\nclass GmailReadTool(ToolBase):\n    SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n\n    def __init__(self, credentials_path: str, sender_email: str):\n        \"\"\"\n        Initializes the GmailReadTool with a path to the credentials JSON file.\n\n        Parameters:\n        credentials_path (str): The path to the Gmail service JSON file.\n        \"\"\"\n        \n        parameters = [\n            Parameter(\n                name=\"query\",\n                type=\"string\",\n                description='''The query to filter emails. For example, \"is:unread\" or \"from:example@gmail.com\" or \"from:sender@company.com\"''',\n                required=True\n            ),\n            Parameter(\n                name=\"max_results\",\n                type=\"integer\",\n                description='''The number of emails to return. Defaults to 10.'''\n            )\n        ]\n        \n        \n        super().__init__(name=\"GmailReadTool\", \n                         description=\"Read emails from a Gmail account.\", \n                         parameters = parameters)\n        self.credentials_path = credentials_path\n        self.sender_email = sender_email\n        \n\n    def authenticate(self):\n        \"\"\"\n        Authenticates the user and creates a Gmail API service.\n        \"\"\"\n        credentials = service_account.Credentials.from_service_account_file(\n                self.credentials_path, scopes=self.SCOPES)\n        \n        delegated_credentials = credentials.with_subject(self.sender_email)\n        self.service = discovery.build('gmail', 'v1', credentials=delegated_credentials)\n\n\n\n    def __call__(self, query='', max_results=10):\n        \"\"\"\n        Fetches emails from the authenticated Gmail account based on the given query.\n\n        Parameters:\n        query (str): The query to filter emails. For example, \"is:unread\".\n        max_results (int): The maximum number of email messages to fetch.\n\n        Returns:\n        list: A list of email messages.\n        \"\"\"\n        self.authenticate()\n        try:\n            # Call the Gmail API\n            \n            gmail_messages = self.service.users().messages()\n            results = gmail_messages.list(userId='me', q=query, maxResults=max_results).execute()\n            messages = results.get('messages', [])\n            message_data = \"\"\n            for message in messages:\n                \n                msg = gmail_messages.get(userId='me', id=message['threadId'], format=\"full\").execute()\n                headers = msg['payload']['headers']\n                \n                sender = next(header['value'] for header in headers if header['name'] == 'From')\n                subject = next(header['value'] for header in headers if header['name'] == 'Subject')\n                reply_to = next((header['value'] for header in headers if header['name'] == 'Reply-To'), subject)\n                date_time = next(header['value'] for header in headers if header['name'] == 'Date')\n                \n                #part = msg['payload']['parts'][0]\n                #data = part['body']['data']\n                #decoded_data = base64.urlsafe_b64decode(data.encode('ASCII'))\n\n                formatted_msg = f\"\\nsender:{sender} reply-to:{reply_to} subject: {subject} date_time:{date_time}\"\n                \n                message_data += formatted_msg\n                \n            \n            return message_data\n        \n        \n        \n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return []\n        \n        finally:\n            del self.service\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/SentimentAnalysisTool.py",
        "content": "```swarmauri/community/tools/concrete/SentimentAnalysisTool.py\nfrom transformers import pipeline\nfrom transformers import logging as hf_logging\n\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\nhf_logging.set_verbosity_error()\n\nclass SentimentAnalysisTool(ToolBase):\n    def __init__(self):\n        super().__init__(\"SentimentAnalysisTool\", \n                         \"Analyzes the sentiment of the given text.\", \n                         parameters=[\n                             Parameter(\"text\", \"string\", \"The text for sentiment analysis\", True)\n                         ])\n        \n\n    def __call__(self, text: str) -> str:\n        try:\n            self.analyzer = pipeline(\"sentiment-analysis\")\n            result = self.analyzer(text)\n            return result[0]['label']\n        except:\n            raise\n        finally:\n            del self.analyzer\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/WebScrapingTool.py",
        "content": "```swarmauri/community/tools/concrete/WebScrapingTool.py\nimport requests\nfrom bs4 import BeautifulSoup\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\nclass WebScrapingTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"url\",\n                type=\"string\",\n                description=\"URL of the link, website, webpage, etc... to scrape\",\n                required=True\n            ),\n            Parameter(\n                name=\"selector\",\n                type=\"string\",\n                description=\"CSS selector to target specific elements\",\n                required=True\n            )\n        ]\n        \n        super().__init__(name=\"WebScrapingTool\", \n                         description=\"This is a web scraping tool that you can utilize to scrape links, websites, webpages, etc... This tool uses python's requests and BeautifulSoup libraries to parse a URL using a CSS to target specific elements.\", \n                         parameters=parameters)\n\n    def __call__(self, url: str, selector: str) -> str:\n        \"\"\"\n        Fetches content from the specified URL and extracts elements based on the provided CSS selector.\n        \n        Args:\n            url (str): The URL of the webpage to scrape.\n            selector (str): CSS selector to target specific elements in the webpage.\n\n        Returns:\n            str: Extracted text from the selector or an error message.\n        \"\"\"\n        try:\n            response = requests.get(url)\n            response.raise_for_status()  # Raises HTTPError for bad requests (4xx or 5xx)\n\n            html_content = response.content\n            soup = BeautifulSoup(html_content, 'html.parser')\n\n            elements = soup.select(selector)\n            extracted_text = '\\n'.join([element.text for element in elements])\n            return extracted_text\n        except requests.RequestException as e:\n            return f\"Request Exception: {str(e)}\"\n        except Exception as e:\n            return f\"Unexpected error: {str(e)}\"\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/DownloadPdfTool.py",
        "content": "```swarmauri/community/tools/concrete/DownloadPdfTool.py\nimport requests\nfrom typing import Dict\nfrom pathlib import Path\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\nclass DownloadPDFTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"url\",\n                type=\"string\",\n                description=\"The URL of the PDF file to download\",\n                required=True\n            ),\n            Parameter(\n                name=\"destination\",\n                type=\"string\",\n                description=\"The path where the PDF file will be saved\",\n                required=True\n            )\n        ]\n        \n        super().__init__(name=\"DownloadPDFTool\",\n                         description=\"Downloads a PDF from a specified URL and saves it to a specified path.\",\n                         parameters=parameters)\n\n    def __call__(self, url: str, destination: str) -> Dict[str, str]:\n        \"\"\"\n        Download the PDF from the specified URL and saves it to the given destination path.\n\n        Parameters:\n        - url (str): The URL from where to download the PDF.\n        - destination (str): The local file path where the PDF should be saved.\n        \n        Returns:\n        - Dict[str, str]: A dictionary containing the result message and the destination path.\n        \"\"\"\n        try:\n            # Send a GET request to the specified URL\n            response = requests.get(url, stream=True)\n\n            # Raise an HTTPError if the status code is not 200 (OK)\n            response.raise_for_status()\n\n            # Ensure destination directory exists\n            Path(destination).parent.mkdir(parents=True, exist_ok=True)\n\n            # Open a file at the specified destination path and write the content of the response to it\n            with open(Path(destination), 'wb') as file:\n                for chunk in response.iter_content(chunk_size=8192):\n                    file.write(chunk)\n            \n            return {\n                \"message\": \"PDF downloaded successfully.\",\n                \"destination\": destination\n            }\n\n        except requests.exceptions.RequestException as e:\n            # Handle requests-related errors\n            return {\"error\": f\"Failed to download PDF: {e}\"}\n        except IOError as e:\n            # Handle file I/O errors\n            return {\"error\": f\"Failed to save PDF: {e}\"}\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/PaCMAP.py",
        "content": "```swarmauri/community/tools/concrete/PaCMAP.py\nimport numpy as np\nimport pacmap  # Ensure pacmap is installed\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\nclass PaCMAPTool(ToolBase):\n    \"\"\"\n    A tool for applying the PaCMAP method for dimensionality reduction.\n    \"\"\"\n\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"X\",\n                type=\"object\",\n                description=\"X (np.ndarray): The high-dimensional data points to reduce.\",\n                required=True\n            ),\n            Parameter(\n                name=\"n_neighbors\",\n                type=\"integer\",\n                description=\"The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation.\",\n                required=False\n            ),\n            Parameter(\n                name=\"n_components\",\n                type=\"integer\",\n                description=\"The dimension of the space into which to embed the data.\",\n                required=True\n            ),\n            Parameter(\n                name=\"n_iterations\",\n                type=\"integer\",\n                description=\"The number of iterations used for optimization.\",\n                required=False\n            )\n        ]\n        \n        super().__init__(name=\"PaCMAPTool\", \n                         description=\"Applies PaCMAP for dimensionality reduction.\", \n                         parameters=parameters)\n\n    def __call__(self, **kwargs) -> np.ndarray:\n        \"\"\"\n        Applies the PaCMAP algorithm on the provided dataset.\n\n        Parameters:\n        - kwargs: Additional keyword arguments for the PaCMAP algorithm.\n\n        Returns:\n        - np.ndarray: The reduced dimension data points.\n        \"\"\"\n        # Set default values for any unspecified parameters\n        X = kwargs.get('X')\n        n_neighbors = kwargs.get('n_neighbors', 30)\n        n_components = kwargs.get('n_components', 2)\n        n_iterations = kwargs.get('n_iterations', 500)\n        \n        # Instantiate the PaCMAP instance with specified parameters\n        embedder = pacmap.PaCMAP(n_neighbors=n_neighbors, n_components=n_components, \n                                 n_iters=n_iterations, **kwargs)\n                                 \n        # Fit the model and transform the data\n        X_reduced = embedder.fit_transform(X)\n\n        return X_reduced\n```"
    },
    {
        "document_name": "swarmauri/community/tools/concrete/ZapierHookTool.py",
        "content": "```swarmauri/community/tools/concrete/ZapierHookTool.py\nimport json\nimport requests\nfrom typing import Dict\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\n\nclass ZapierHookTool(ToolBase):\n    def __init__(self, auth_token, zap_id):\n        parameters = [\n            Parameter(\n                name=\"payload\",\n                type=\"string\",\n                description=\"A Payload to send when triggering the Zapier webhook\",\n                required=True\n            )\n        ]\n        super().__init__(name=\"ZapierTool\", \n                         description=\"Tool to authenticate with Zapier and execute zaps.\", \n                        parameters=parameters)\n        self._auth_token = auth_token\n        self._zap_id = zap_id\n\n    def authenticate(self):\n        \"\"\"Set up the necessary headers for authentication.\"\"\"\n        self.headers = {\n            \"Authorization\": f\"Bearer {self._auth_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n    def execute_zap(self, payload: str):\n        \"\"\"Execute a zap with given payload.\n\n        Args:\n            zap_id (str): The unique identifier for the Zap to trigger.\n            payload (dict): The data payload to send to the Zap.\n\n        Returns:\n            dict: The response from Zapier API.\n        \"\"\"\n        self.authenticate()\n        response = requests.post(f'https://hooks.zapier.com/hooks/catch/{self._zap_id}/',\n                                     headers=self.headers, json={\"data\":payload})\n        # Checking the HTTP response status for success or failure\n        if response.status_code == 200:\n            return json.dumps(response.json())\n        else:\n            response.raise_for_status()  # This will raise an error for non-200 responses\n\n    def __call__(self, payload: str):\n        \"\"\"Enable the tool to be called with zap_id and payload directly.\"\"\"\n        return self.execute_zap(payload)\n```"
    },
    {
        "document_name": "swarmauri/community/retrievers/__init__.py",
        "content": "```swarmauri/community/retrievers/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/community/retrievers/base/__init__.py",
        "content": "```swarmauri/community/retrievers/base/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/community/retrievers/concrete/__init__.py",
        "content": "```swarmauri/community/retrievers/concrete/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/community/retrievers/concrete/RedisDocumentRetriever.py",
        "content": "```swarmauri/community/retrievers/concrete/RedisDocumentRetriever.py\nfrom typing import List\nfrom redisearch import Client, Query\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.document_stores.concrete.ConcreteDocument import ConcreteDocument\nfrom ....standard.retrievers.base.DocumentRetrieverBase import DocumentRetrieverBase\n\nclass RedisDocumentRetriever(DocumentRetrieverBase):\n    \"\"\"\n    A document retriever that fetches documents from a Redis store.\n    \"\"\"\n    \n    def __init__(self, redis_idx_name, redis_host, redis_port):\n        \"\"\"\n        Initializes a new instance of RedisDocumentRetriever.\n\n        Args:\n            redis_client (Redis): An instance of the Redis client.\n        \"\"\"\n        self._redis_client = None\n        self._redis_idx_name = redis_idx_name\n        self._redis_host = redis_host\n        self._redis_port = redis_port\n\n    @property\n    def redis_client(self):\n        \"\"\"Lazily initialize and return the Redis client using a factory method.\"\"\"\n        if self._redis_client is None:\n            self._redis_client = Client(self.redis_idx_name, host=self.redis_host, port=self.redis_port)\n        return self._redis_client\n    \n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the most relevant documents based on the given query.\n        \n        Args:\n            query (str): The query string used for document retrieval.\n            top_k (int, optional): The number of top relevant documents to retrieve. Defaults to 5.\n        \n        Returns:\n            List[IDocument]: A list of the top_k most relevant documents.\n        \"\"\"\n        query_result = self.redis_client.search(Query(query).paging(0, top_k))\n        \n        documents = [\n            ConcreteDocument(\n                doc_id=doc.id,\n                content=doc.text,  # Note: Adjust 'text' based on actual Redis document schema\n                metadata=doc.__dict__  # Including full document fields and values in metadata\n            )\n            for doc in query_result.docs\n        ]\n\n        return documents\n\n```"
    },
    {
        "document_name": "swarmauri/community/document_stores/__init__.py",
        "content": "```swarmauri/community/document_stores/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/community/document_stores/base/__init__.py",
        "content": "```swarmauri/community/document_stores/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/community/document_stores/concrete/__init__.py",
        "content": "```swarmauri/community/document_stores/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/community/document_stores/concrete/RedisDocumentStore.py",
        "content": "```swarmauri/community/document_stores/concrete/RedisDocumentStore.py\nfrom typing import List, Optional\nfrom ....standard.document_stores.base.DocumentStoreBase import DocumentStoreBase\nfrom ....core.documents.IDocument import IDocument\nimport redis\nimport json\nfrom redis.commands.search.field import TextField, NumericField, TagField\nfrom redis.commands.search.indexDefinition import IndexDefinition, IndexType\n\n\nclass RedisDocumentStore(DocumentStoreBase):\n    def __init__(self, host, password, port, db):\n        \"\"\"Store connection details without initializing the Redis client.\"\"\"\n        self._host = host\n        self._password = password\n        self._port = port\n        self._db = db\n        self._redis_client = None  # Delayed initialization\n\n    @property\n    def redis_client(self):\n        \"\"\"Lazily initialize and return the Redis client using a factory method.\"\"\"\n        if self._redis_client is None:\n            print('here')\n            self._redis_client = redis.Redis(host=self._host, \n                                             password=self._password, \n                                             port=self._port, \n                                             db=self._db)\n            print('there')\n        return self._redis_client\n\n    def add_document(self, document: IDocument) -> None:\n        \n        data = document.as_dict()\n        doc_id = data['id'] \n        del data['id']\n        self.redis_client.json().set(doc_id, '$', json.dumps(data))\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        with self.redis_client.pipeline() as pipe:\n            for document in documents:\n                pipe.set(document.doc_id, document)\n            pipe.execute()\n\n    def get_document(self, doc_id: str) -> Optional[IDocument]:\n        result = self.redis_client.json().get(doc_id)\n        if result:\n            return json.loads(result)\n        return None\n\n    def get_all_documents(self) -> List[IDocument]:\n        keys = self.redis_client.keys('*')\n        documents = []\n        for key in keys:\n            document_data = self.redis_client.get(key)\n            if document_data:\n                documents.append(json.loads(document_data))\n        return documents\n\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        self.add_document(updated_document)\n\n    def delete_document(self, doc_id: str) -> None:\n        self.redis_client.delete(doc_id)\n    \n    def __getstate__(self):\n        \"\"\"Return the object state for serialization, excluding the Redis client.\"\"\"\n        state = self.__dict__.copy()\n        state['_redis_client'] = None  # Exclude Redis client from serialization\n        return state\n\n    def __setstate__(self, state):\n        \"\"\"Restore the object state after serialization, reinitializing the Redis client.\"\"\"\n        self.__dict__.update(state)\n```"
    },
    {
        "document_name": "swarmauri/core/__init__.py",
        "content": "```swarmauri/core/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/models/__init__.py",
        "content": "```swarmauri/core/models/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/models/IPredict.py",
        "content": "```swarmauri/core/models/IPredict.py\nfrom abc import ABC, abstractmethod\n\nclass IPredict(ABC):\n    \"\"\"\n    Interface for making predictions with models.\n    \"\"\"\n\n    @abstractmethod\n    def predict(self, input_data) -> any:\n        \"\"\"\n        Generate predictions based on the input data provided to the model.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/models/IFit.py",
        "content": "```swarmauri/core/models/IFit.py\nfrom abc import ABC, abstractmethod\n\nclass IFit(ABC):\n    \"\"\"\n    Interface for training models.\n    \"\"\"\n\n    @abstractmethod\n    def fit(self, X_train, y_train, epochs: int, batch_size: int) -> None:\n        \"\"\"\n        Train the model on the provided dataset.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/models/IModel.py",
        "content": "```swarmauri/core/models/IModel.py\nfrom abc import ABC, abstractmethod\n\nclass IModel(ABC):\n    \"\"\"\n    Interface focusing on the basic properties and settings essential for defining models.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def model_name(self) -> str:\n        \"\"\"\n        Get the name of the model.\n        \"\"\"\n        pass\n\n    @model_name.setter\n    @abstractmethod\n    def model_name(self, value: str) -> None:\n        \"\"\"\n        Set the name of the model.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agent_apis/__init__.py",
        "content": "```swarmauri/core/agent_apis/__init__.py\nfrom .IAgentCommands import IAgentCommands\nfrom .IAgentRouterCRUD import IAgentRouterCRUD\n\n__all__ = ['IAgentCommands', 'IAgentRouterCRUD']\n```"
    },
    {
        "document_name": "swarmauri/core/agent_apis/IAgentCommands.py",
        "content": "```swarmauri/core/agent_apis/IAgentCommands.py\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Any, List\n\nclass IAgentCommands(ABC):\n    \"\"\"\n    Interface for the API object that enables a SwarmAgent to host various API routes.\n    \"\"\"\n\n\n    @abstractmethod\n    def invoke(self, request: Any) -> Any:\n        \"\"\"\n        Handles invocation requests synchronously.\n        \n        Parameters:\n            request (Any): The incoming request payload.\n\n        Returns:\n            Any: The response payload.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def ainvoke(self, request: Any) -> Any:\n        \"\"\"\n        Handles invocation requests asynchronously.\n        \n        Parameters:\n            request (Any): The incoming request payload.\n\n        Returns:\n            Any: The response payload.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def batch(self, requests: List[Any]) -> List[Any]:\n        \"\"\"\n        Handles batched invocation requests synchronously.\n        \n        Parameters:\n            requests (List[Any]): A list of incoming request payloads.\n\n        Returns:\n            List[Any]: A list of responses.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def abatch(self, requests: List[Any]) -> List[Any]:\n        \"\"\"\n        Handles batched invocation requests asynchronously.\n\n        Parameters:\n            requests (List[Any]): A list of incoming request payloads.\n\n        Returns:\n            List[Any]: A list of responses.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def stream(self, request: Any) -> Any:\n        \"\"\"\n        Handles streaming requests.\n\n        Parameters:\n            request (Any): The incoming request payload.\n\n        Returns:\n            Any: A streaming response.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_schema_config(self) -> dict:\n        \"\"\"\n        Retrieves the schema configuration for the API.\n\n        Returns:\n            dict: The schema configuration.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agent_apis/IAgentRouterCRUD.py",
        "content": "```swarmauri/core/agent_apis/IAgentRouterCRUD.py\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Any, Dict\n\nclass IAgentRouterCRUD(ABC):\n    \"\"\"\n    Interface for managing API routes within a SwarmAgent.\n    \"\"\"\n    \n    @abstractmethod\n    def create_route(self, path: str, method: str, handler: Callable[[Any], Any]) -> None:\n        \"\"\"\n        Create a new route for the API.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method (e.g., 'GET', 'POST').\n        - handler (Callable[[Any], Any]): The function that handles requests to this route.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def read_route(self, path: str, method: str) -> Dict:\n        \"\"\"\n        Retrieve information about a specific route.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method.\n        \n        Returns:\n        - Dict: Information about the route, including path, method, and handler.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def update_route(self, path: str, method: str, new_handler: Callable[[Any], Any]) -> None:\n        \"\"\"\n        Update the handler function for an existing route.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method.\n        - new_handler (Callable[[Any], Any]): The new function that handles requests to this route.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def delete_route(self, path: str, method: str) -> None:\n        \"\"\"\n        Delete a specific route from the API.\n        \n        Parameters:\n        - path (str): The URL path for the route.\n        - method (str): The HTTP method.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/__init__.py",
        "content": "```swarmauri/core/conversations/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/IMaxSize.py",
        "content": "```swarmauri/core/conversations/IMaxSize.py\nfrom abc import ABC, abstractmethod\n\nclass IMaxSize(ABC):\n\n    @property\n    @abstractmethod\n    def max_size(self) -> int:\n        \"\"\"\n        \"\"\"\n        pass\n\n    @max_size.setter\n    @abstractmethod\n    def max_size(self, new_max_size: int) -> None:\n        \"\"\" \n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/IConversation.py",
        "content": "```swarmauri/core/conversations/IConversation.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom ..messages.IMessage import IMessage\n\nclass IConversation(ABC):\n    \"\"\"\n    Interface for managing conversations, defining abstract methods for\n    adding messages, retrieving the latest message, getting all messages, and clearing history.\n    \"\"\"\n\n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_message(self, message: IMessage):\n        \"\"\"\n        Adds a message to the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_last(self) -> Optional[IMessage]:\n        \"\"\"\n        Retrieves the latest message from the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def clear_history(self) -> None:\n        \"\"\"\n        Clears the conversation history.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def as_messages(self) -> List[dict]:\n        \"\"\"\n        Returns all messages from the conversation history in chat completion format.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/conversations/ISystemContext.py",
        "content": "```swarmauri/core/conversations/ISystemContext.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional\nfrom ..messages.IMessage import IMessage\n\nclass ISystemContext(ABC):\n\n    @property\n    @abstractmethod\n    def system_context(self) -> Optional[IMessage]:\n        \"\"\"\n        An abstract property to get the system context message.\n        Subclasses must provide an implementation for storing and retrieving system context.\n        \"\"\"\n        pass\n\n    @system_context.setter\n    @abstractmethod\n    def system_context(self, new_system_message: Optional[IMessage]) -> None:\n        \"\"\"\n        An abstract property setter to update the system context.\n        Subclasses must provide an implementation for how the system context is updated.\n        This might be a direct string, which is converted to an IMessage instance, or directly an IMessage instance.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/documents/__init__.py",
        "content": "```swarmauri/core/documents/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/documents/IDocument.py",
        "content": "```swarmauri/core/documents/IDocument.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\n\nclass IDocument(ABC):\n    @abstractmethod\n    def __init__(self, id: str, content: str, metadata: Dict):\n        pass\n\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"\n        Get the document's ID.\n        \"\"\"\n        pass\n\n    @id.setter\n    @abstractmethod\n    def id(self, value: str) -> None:\n        \"\"\"\n        Set the document's ID.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def content(self) -> str:\n        \"\"\"\n        Get the document's content.\n        \"\"\"\n        pass\n\n    @content.setter\n    @abstractmethod\n    def content(self, value: str) -> None:\n        \"\"\"\n        Set the document's content.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def metadata(self) -> Dict:\n        \"\"\"\n        Get the document's metadata.\n        \"\"\"\n        pass\n\n    @metadata.setter\n    @abstractmethod\n    def metadata(self, value: Dict) -> None:\n        \"\"\"\n        Set the document's metadata.\n        \"\"\"\n        pass\n\n    # Including the abstract methods __str__ and __repr__ definitions for completeness.\n    @abstractmethod\n    def __str__(self) -> str:\n        pass\n\n    @abstractmethod\n    def __repr__(self) -> str:\n        pass\n    \n    def __setitem__(self, key, value):\n        \"\"\"Allow setting items like a dict for metadata.\"\"\"\n        self.metadata[key] = value\n\n    def __getitem__(self, key):\n        \"\"\"Allow getting items like a dict for metadata.\"\"\"\n        return self.metadata.get(key)\n```"
    },
    {
        "document_name": "swarmauri/core/documents/IEmbed.py",
        "content": "```swarmauri/core/documents/IEmbed.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass IEmbed(ABC):\n    @property\n    @abstractmethod\n    def embedding(self) -> IVector:\n        \"\"\"\n        Get the document's embedding.\n        \"\"\"\n        pass\n\n    @embedding.setter\n    @abstractmethod\n    def embedding(self, value: IVector) -> None:\n        \"\"\"\n        Set the document's embedding.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/documents/IExperimentDocument.py",
        "content": "```swarmauri/core/documents/IExperimentDocument.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional\nfrom datetime import datetime\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IExperimentDocument(IDocument, ABC):\n    \"\"\"\n    Interface for an Experiment Document, extending the general IDocument interface\n    with additional properties and methods specific to experimental data.\n    \"\"\"\n    @property\n    @abstractmethod\n    def parameters(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the parameters used in the experiment.\n        \"\"\"\n        pass\n\n    @parameters.setter\n    @abstractmethod\n    def parameters(self, value: Dict[str, Any]) -> None:\n        \"\"\"\n        Set the parameters used in the experiment.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def results(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the results obtained from the experiment.\n        \"\"\"\n        pass\n\n    @results.setter\n    @abstractmethod\n    def results(self, value: Dict[str, Any]) -> None:\n        \"\"\"\n        Set the results obtained from the experiment.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def instruction(self) -> str:\n        \"\"\"\n        An instructional or descriptive text about what the experiment aims to achieve or how.\n        \"\"\"\n        pass\n\n    @instruction.setter\n    @abstractmethod\n    def instruction(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def feature_set(self) -> List[Any]:\n        \"\"\"\n        Description of the set of features or data used in the experiment.\n        \"\"\"\n        pass\n\n    @feature_set.setter\n    @abstractmethod\n    def feature_set(self, value: List[Any]) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def version(self) -> str:\n        \"\"\"\n        The version of the experiment, useful for tracking iterations and changes over time.\n        \"\"\"\n        pass\n\n    @version.setter\n    @abstractmethod\n    def version(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def artifacts(self) -> List[str]:\n        \"\"\"\n        A list of paths or identifiers for any artifacts generated by the experiment,\n        such as models, charts, or data dumps.\n        \"\"\"\n        pass\n\n    @artifacts.setter\n    @abstractmethod\n    def artifacts(self, value: List[str]) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def datetime_created(self) -> datetime:\n        \"\"\"\n        Timestamp marking when the experiment was initiated or created.\n        \"\"\"\n        pass\n\n    @datetime_created.setter\n    @abstractmethod\n    def datetime_created(self, value: datetime) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def datetime_completed(self) -> Optional[datetime]:\n        \"\"\"\n        Timestamp of when the experiment was completed. None if the experiment is still running.\n        \"\"\"\n        pass\n\n    @datetime_completed.setter\n    @abstractmethod\n    def datetime_completed(self, value: Optional[datetime]) -> None:\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/messages/IMessage.py",
        "content": "```swarmauri/core/messages/IMessage.py\nfrom abc import ABC, abstractmethod\n\nclass IMessage(ABC):\n    \"\"\"\n    An abstract interface representing a general message structure.\n\n    This interface defines the basic attributes that all\n    messages should have, including type, name, and content, \n    and requires subclasses to implement representation and formatting methods.\n    \"\"\"\n    @property\n    @abstractmethod\n    def role(self) -> str:\n        pass\n    \n    @property\n    @abstractmethod\n    def content(self) -> str:\n        pass\n\n    @abstractmethod\n    def as_dict(self) -> dict:\n        \"\"\"\n        An abstract method that subclasses must implement to return a dictionary representation of the object.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/messages/__init__.py",
        "content": "```swarmauri/core/messages/__init__.py\nfrom .IMessage import IMessage\n```"
    },
    {
        "document_name": "swarmauri/core/parsers/__init__.py",
        "content": "```swarmauri/core/parsers/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/parsers/IParser.py",
        "content": "```swarmauri/core/parsers/IParser.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union, Any\nfrom ..documents.IDocument import IDocument\n\nclass IParser(ABC):\n    \"\"\"\n    Abstract base class for parsers. It defines a public method to parse input data (str or Message) into documents,\n    and relies on subclasses to implement the specific parsing logic through protected and private methods.\n    \"\"\"\n\n    @abstractmethod\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Public method to parse input data (either a str or a Message) into a list of Document instances.\n        \n        This method leverages the abstract _parse_data method which must be\n        implemented by subclasses to define specific parsing logic.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/prompts/__init__.py",
        "content": "```swarmauri/core/prompts/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/prompts/IPrompt.py",
        "content": "```swarmauri/core/prompts/IPrompt.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Any\n\nclass IPrompt(ABC):\n    \"\"\"\n    A base abstract class representing a prompt system.\n\n    Methods:\n        __call__: Abstract method that subclasses must implement to enable the instance to be called directly.\n    \"\"\"\n\n    @abstractmethod\n    def __call__(self, prompt: Optional[Any]) -> str:\n        \"\"\"\n        Abstract method that subclasses must implement to define the behavior of the prompt when called.\n\n        \"\"\"\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/prompts/ITemplate.py",
        "content": "```swarmauri/core/prompts/ITemplate.py\nfrom typing import Dict, List\nfrom abc import ABC, abstractmethod\n\n\nclass ITemplate(ABC):\n    \"\"\"\n    Interface for template-based prompt generation within the SwarmAURI framework.\n    Defines standard operations and attributes for managing and utilizing templates.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def template(self) -> str:\n        \"\"\"\n        Abstract property to get the current template string.\n        \"\"\"\n        pass\n\n    @template.setter\n    @abstractmethod\n    def template(self, value: str) -> None:\n        \"\"\"\n        Abstract property setter to set or update the current template string.\n\n        Args:\n            value (str): The new template string to be used for generating prompts.\n        \"\"\"\n        pass\n\n\n    @property\n    @abstractmethod\n    def variables(self) -> List[Dict[str, str]]:\n        \"\"\"\n        Abstract property to get the current set of variables for the template.\n        \"\"\"\n        pass\n\n    @variables.setter\n    @abstractmethod\n    def variables(self, value: List[Dict[str, str]]) -> None:\n        \"\"\"\n        Abstract property setter to set or update the variables for the template.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_template(self, template: str) -> None:\n        \"\"\"\n        Sets or updates the current template string.\n\n        Args:\n            template (str): The new template string to be used for generating prompts.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_variables(self, variables: List[Dict[str, str]]) -> None:\n        \"\"\"\n        Sets or updates the variables to be substituted into the template.\n\n        Args:\n            variables (List[Dict[str, str]]): A dictionary of variables where each key-value \n                                        pair corresponds to a placeholder name and its \n                                        replacement value in the template.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_prompt(self, **kwargs) -> str:\n        \"\"\"\n        Generates a prompt string based on the current template and provided keyword arguments.\n\n        Args:\n            **kwargs: Keyword arguments containing variables for template substitution. \n\n        Returns:\n            str: The generated prompt string with template variables replaced by their\n                 corresponding values provided in `kwargs`.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/prompts/IPromptMatrix.py",
        "content": "```swarmauri/core/prompts/IPromptMatrix.py\n# swarmauri/core/prompts/IPromptMatrix.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple, Optional, Any\n\nclass IPromptMatrix(ABC):\n    @property\n    @abstractmethod\n    def matrix(self) -> List[List[Optional[str]]]:\n        \"\"\"Get the entire prompt matrix.\"\"\"\n        pass\n\n    @matrix.setter\n    @abstractmethod\n    def matrix(self, value: List[List[Optional[str]]]) -> None:\n        \"\"\"Set the entire prompt matrix.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def shape(self) -> Tuple[int, int]:\n        \"\"\"Get the shape (number of agents, sequence length) of the prompt matrix.\"\"\"\n        pass\n\n    @abstractmethod\n    def add_prompt_sequence(self, sequence: List[Optional[str]]) -> None:\n        \"\"\"Add a new prompt sequence to the matrix.\"\"\"\n        pass\n\n    @abstractmethod\n    def remove_prompt_sequence(self, index: int) -> None:\n        \"\"\"Remove a prompt sequence from the matrix by index.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_prompt_sequence(self, index: int) -> List[Optional[str]]:\n        \"\"\"Get a prompt sequence from the matrix by index.\"\"\"\n        pass\n\n    @abstractmethod\n    def show_matrix(self) -> List[List[Optional[str]]]:\n        \"\"\"Show the entire prompt matrix.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/__init__.py",
        "content": "```swarmauri/core/agents/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentToolkit.py",
        "content": "```swarmauri/core/agents/IAgentToolkit.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\n\n\nclass IAgentToolkit(ABC):\n\n    @property\n    @abstractmethod\n    def toolkit(self) -> IToolkit:\n        pass\n    \n    @toolkit.setter\n    @abstractmethod\n    def toolkit(self) -> IToolkit:\n        pass\n    \n\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentConversation.py",
        "content": "```swarmauri/core/agents/IAgentConversation.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nclass IAgentConversation(ABC):\n    \n    @property\n    @abstractmethod\n    def conversation(self) -> IConversation:\n        \"\"\"\n        The conversation property encapsulates the agent's ongoing dialogue or interaction context.\n        \"\"\"\n        pass\n\n    @conversation.setter\n    @abstractmethod\n    def conversation(self) -> IConversation:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentParser.py",
        "content": "```swarmauri/core/agents/IAgentParser.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.parsers.IParser import IParser \n\nclass IAgentParser(ABC):\n    \n    @property\n    @abstractmethod\n    def parser(self) -> IParser:\n        pass\n\n    @parser.setter\n    @abstractmethod\n    def parser(self) -> IParser:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentName.py",
        "content": "```swarmauri/core/agents/IAgentName.py\nfrom abc import ABC, abstractmethod\n\nclass IAgentName(ABC):\n    \n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"\n        The conversation property encapsulates the agent's ongoing dialogue or interaction context.\n        \"\"\"\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self) -> str:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgent.py",
        "content": "```swarmauri/core/agents/IAgent.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Optional\nfrom swarmauri.core.models.IModel import IModel\n\nclass IAgent(ABC):\n\n    @abstractmethod\n    def exec(self, input_data: Optional[Any]) -> Any:\n        \"\"\"\n        Executive method that triggers the agent's action based on the input data.\n        \"\"\"\n        pass\n    \n    @property\n    @abstractmethod\n    def model(self) -> IModel:\n        \"\"\"\n        The model property describes the computational model used by the agent.\n        \"\"\"\n        pass\n    \n    @model.setter\n    @abstractmethod\n    def model(self) -> IModel:\n\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentVectorStore.py",
        "content": "```swarmauri/core/agents/IAgentVectorStore.py\nfrom abc import ABC, abstractmethod\n\nclass IAgentVectorStore(ABC):\n    \n    @property\n    @abstractmethod\n    def vector_store(self):\n        pass\n\n    @vector_store.setter\n    @abstractmethod\n    def vector_store(self):\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentRetrieve.py",
        "content": "```swarmauri/core/agents/IAgentRetrieve.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IAgentRetrieve(ABC):\n\n    @property\n    @abstractmethod\n    def last_retrieved(self) -> List[IDocument]:\n        pass\n\n    @last_retrieved.setter\n    @abstractmethod\n    def last_retrieved(self) -> List[IDocument]:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agents/IAgentSystemContext.py",
        "content": "```swarmauri/core/agents/IAgentSystemContext.py\nfrom abc import ABC, abstractmethod\n\nclass IAgentSystemContext(ABC):\n    \n    @property\n    @abstractmethod\n    def system_context(self):\n        pass\n\n    @system_context.setter\n    @abstractmethod\n    def system_context(self):\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/__init__.py",
        "content": "```swarmauri/core/swarms/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarm.py",
        "content": "```swarmauri/core/swarms/ISwarm.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, List, Dict\nfrom datetime import datetime\nfrom swarmauri.core.agents.IAgent import IAgent\nfrom swarmauri.core.chains.ICallableChain import ICallableChain\n\nclass ISwarm(ABC):\n    \"\"\"\n    Interface for a Swarm, representing a collective of agents capable of performing tasks, executing callable chains, and adaptable configurations.\n    \"\"\"\n\n    # Abstract properties and setters\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"Unique identifier for the factory instance.\"\"\"\n        pass\n\n    @id.setter\n    @abstractmethod\n    def id(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def type(self) -> str:\n        pass\n\n    @type.setter\n    @abstractmethod\n    def type(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def date_created(self) -> datetime:\n        pass\n\n    @property\n    @abstractmethod\n    def last_modified(self) -> datetime:\n        pass\n\n    @last_modified.setter\n    @abstractmethod\n    def last_modified(self, value: datetime) -> None:\n        pass\n\n    def __hash__(self):\n        \"\"\"\n        The __hash__ method allows objects of this class to be used in sets and as dictionary keys.\n        __hash__ should return an integer and be defined based on immutable properties.\n        This is generally implemented directly in concrete classes rather than in the interface,\n        but it's declared here to indicate that implementing classes must provide it.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmComponent.py",
        "content": "```swarmauri/core/swarms/ISwarmComponent.py\nfrom abc import ABC, abstractmethod\n\nclass ISwarmComponent(ABC):\n    \"\"\"\n    Interface for defining a general component within a swarm system.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, key: str, name: str):\n        \"\"\"\n        Initializes a swarm component with a unique key and name.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmConfigurationExporter.py",
        "content": "```swarmauri/core/swarms/ISwarmConfigurationExporter.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nclass ISwarmConfigurationExporter(ABC):\n\n    @abstractmethod\n    def to_dict(self) -> Dict:\n        \"\"\"\n        Serializes the swarm configuration to a dictionary.\n\n        Returns:\n            Dict: The serialized configuration as a dictionary.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_json(self) -> str:\n        \"\"\"\n        Serializes the swarm configuration to a JSON string.\n\n        Returns:\n            str: The serialized configuration as a JSON string.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_pickle(self) -> bytes:\n        \"\"\"\n        Serializes the swarm configuration to a Pickle byte stream.\n\n        Returns:\n            bytes: The serialized configuration as a Pickle byte stream.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmFactory.py",
        "content": "```swarmauri/core/swarms/ISwarmFactory.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Callable, Dict, List, NamedTuple, Optional, Type, Union\nfrom swarmauri.core.swarms.ISwarm import ISwarm\nfrom swarmauri.core.chains.ICallableChain import ICallableChain \nfrom swarmauri.core.agents.IAgent import IAgent \n\nclass Step(NamedTuple):\n    description: str\n    callable: Callable  # Reference to the function to execute\n    args: Optional[List[Any]] = None\n    kwargs: Optional[Dict[str, Any]] = None\n\nclass CallableChainItem(NamedTuple):\n    key: str  # Unique identifier for the item within the chain\n    execution_context: Dict[str, Any]  # Execution context and metadata\n    steps: List[Step]\n\nclass AgentDefinition(NamedTuple):\n    type: str\n    configuration: Dict[str, Any]\n    capabilities: List[str]\n    dependencies: List[str]\n    execution_context: Dict[str, Any]\n\nclass FunctionParameter(NamedTuple):\n    name: str\n    type: Type\n    default: Optional[Any] = None\n    required: bool = True\n\nclass FunctionDefinition(NamedTuple):\n    identifier: str\n    parameters: List[FunctionParameter]\n    return_type: Type\n    execution_context: Dict[str, Any]\n    callable_source: Callable\n    \nclass ISwarmFactory(ABC):\n\n    @abstractmethod\n    def create_swarm(self, *args, **kwargs) -> ISwarm:\n        \"\"\"\n        Creates and returns a new swarm instance configured with the provided arguments.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_agent(self, agent_definition: AgentDefinition) -> IAgent:\n        \"\"\"\n        Creates a new agent based on the provided enhanced agent definition.\n        \n        Args:\n            agent_definition: An instance of AgentDefinition detailing the agent's setup.\n        \n        Returns:\n            An instance or identifier of the newly created agent.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def create_callable_chain(self, chain_definition: List[CallableChainItem]) -> ICallableChain:\n        \"\"\"\n        Creates a new callable chain based on the provided definition.\n\n        Args:\n            chain_definition: Details required to build the chain, such as sequence of functions and arguments.\n\n        Returns:\n            ICallableChain: The constructed callable chain instance.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def register_function(self, function_definition: FunctionDefinition) -> None:\n        \"\"\"\n        Registers a function within the factory ecosystem, making it available for callable chains and agents.\n\n        Args:\n            function_definition: An instance of FunctionDefinition detailing the function's specification.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def export_callable_chains(self, format_type: str = 'json') -> Union[dict, str, bytes]:\n        \"\"\"\n        Exports configurations of all callable chains in the specified format.\n        Supported formats: 'json', 'pickle'.\n\n        Args:\n            format_type (str): The format for exporting the configurations.\n\n        Returns:\n            Union[dict, str, bytes]: The callable chain configurations in the specified format.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_callable_chains(self, chains_data, format_type: str = 'json'):\n        \"\"\"\n        Loads callable chain configurations from given data.\n\n        Args:\n            chains_data (Union[dict, str, bytes]): Data containing callable chain configurations.\n            format_type (str): The format of the provided chains data.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def export_configuration(self, format_type: str = 'json') -> Union[dict, str, bytes]:\n        \"\"\"\n        Exports the swarm's and agents' configurations in the specified format.\n        Supported formats: 'json', 'pickle'. Default is 'json'.\n\n        Args:\n            format_type (str): The format for exporting the configurations.\n\n        Returns:\n            Union[dict, str, bytes]: The configurations in the specified format.\n        \"\"\"\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmAgentRegistration.py",
        "content": "```swarmauri/core/swarms/ISwarmAgentRegistration.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Optional\nfrom swarmauri.core.agents.IAgent import IAgent\n\nclass ISwarmAgentRegistration(ABC):\n    \"\"\"\n    Interface for registering agents with the swarm, designed to support CRUD operations on IAgent instances.\n    \"\"\"\n\n    @id.setter\n    @abstractmethod\n    def registry(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def registry(self) -> List[IAgent]:\n        pass\n\n    @abstractmethod\n    def register_agent(self, agent: IAgent) -> bool:\n        \"\"\"\n        Register a new agent with the swarm.\n\n        Parameters:\n            agent (IAgent): An instance of IAgent representing the agent to register.\n\n        Returns:\n            bool: True if the registration succeeded; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_agent(self, agent_id: str, updated_agent: IAgent) -> bool:\n        \"\"\"\n        Update the details of an existing agent. This could include changing the agent's configuration,\n        task assignment, or any other mutable attribute.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent.\n            updated_agent (IAgent): An updated IAgent instance to replace the existing one.\n\n        Returns:\n            bool: True if the update was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_agent(self, agent_id: str) -> bool:\n        \"\"\"\n        Remove an agent from the swarm based on its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent to be removed.\n\n        Returns:\n            bool: True if the removal was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_agent(self, agent_id: str) -> Optional[IAgent]:\n        \"\"\"\n        Retrieve an agent's instance from its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent of interest.\n\n        Returns:\n            Optional[IAgent]: The IAgent instance if found; None otherwise.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarms/ISwarmChainCRUD.py",
        "content": "```swarmauri/core/swarms/ISwarmChainCRUD.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any\n\nclass ISwarmChainCRUD(ABC):\n    \"\"\"\n    Interface to provide CRUD operations for ICallableChain within swarms.\n    \"\"\"\n\n    @abstractmethod\n    def create_chain(self, chain_id: str, chain_definition: Dict[str, Any]) -> None:\n        \"\"\"\n        Creates a callable chain with the provided definition.\n\n        Parameters:\n        - chain_id (str): A unique identifier for the callable chain.\n        - chain_definition (Dict[str, Any]): The definition of the callable chain including steps and their configurations.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def read_chain(self, chain_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Retrieves the definition of a callable chain by its identifier.\n\n        Parameters:\n        - chain_id (str): The unique identifier of the callable chain to be retrieved.\n\n        Returns:\n        - Dict[str, Any]: The definition of the callable chain.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_chain(self, chain_id: str, new_definition: Dict[str, Any]) -> None:\n        \"\"\"\n        Updates an existing callable chain with a new definition.\n\n        Parameters:\n        - chain_id (str): The unique identifier of the callable chain to be updated.\n        - new_definition (Dict[str, Any]): The new definition of the callable chain including updated steps and configurations.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_chain(self, chain_id: str) -> None:\n        \"\"\"\n        Removes a callable chain from the swarm.\n\n        Parameters:\n        - chain_id (str): The unique identifier of the callable chain to be removed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_chains(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Lists all callable chains currently managed by the swarm.\n\n        Returns:\n        - List[Dict[str, Any]]: A list of callable chain definitions.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/toolkits/__init__.py",
        "content": "```swarmauri/core/toolkits/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/toolkits/IToolkit.py",
        "content": "```swarmauri/core/toolkits/IToolkit.py\nfrom typing import Dict\nfrom abc import ABC, abstractmethod\nfrom ..tools.ITool import ITool  # Ensure Tool is correctly imported from your tools package\n\nclass IToolkit(ABC):\n    \"\"\"\n    A class representing a toolkit used by Swarm Agents.\n    Tools are maintained in a dictionary keyed by the tool's name.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def tools(self) -> Dict[str, ITool]:\n        \"\"\"\n        An abstract property that should be implemented by subclasses to return the tools dictionary\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_tools(self, tools: Dict[str, ITool]):\n        \"\"\"\n        An abstract method that should be implemented by subclasses to add multiple tools to the toolkit.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_tool(self, tool: ITool):\n        \"\"\"\n        An abstract method that should be implemented by subclasses to add a single tool to the toolkit.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_tool(self, tool_name: str):\n        \"\"\"\n        An abstract method that should be implemented by subclasses to remove a tool from the toolkit by name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_tool_by_name(self, tool_name: str) -> ITool:\n        \"\"\"\n        An abstract method that should be implemented by subclasses to retrieve a tool from the toolkit by name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def __len__(self) -> int:\n        \"\"\"\n        An abstract method that should be implemented by subclasses to return the number of tools in the toolkit.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tools/__init__.py",
        "content": "```swarmauri/core/tools/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/tools/ITool.py",
        "content": "```swarmauri/core/tools/ITool.py\nfrom abc import ABC, abstractmethod\n\nclass ITool(ABC):\n    \n    @property\n    @abstractmethod\n    def name(self):\n        pass\n    \n    @property\n    @abstractmethod\n    def description(self):\n        pass\n    \n    @property\n    @abstractmethod\n    def parameters(self):\n        pass\n    \n    @abstractmethod\n    def as_dict(self):\n        pass\n\n    @abstractmethod\n    def to_json(obj):\n        pass\n\n    @abstractmethod\n    def __call__(self, *args, **kwargs):\n        pass\n\n\n\n\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/tools/IParameter.py",
        "content": "```swarmauri/core/tools/IParameter.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, List, Any\n\nclass IParameter(ABC):\n    \"\"\"\n    An abstract class to represent a parameter for a tool.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"\n        Abstract property for getting the name of the parameter.\n        \"\"\"\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self, value: str):\n        \"\"\"\n        Abstract setter for setting the name of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def type(self) -> str:\n        \"\"\"\n        Abstract property for getting the type of the parameter.\n        \"\"\"\n        pass\n\n    @type.setter\n    @abstractmethod\n    def type(self, value: str):\n        \"\"\"\n        Abstract setter for setting the type of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def description(self) -> str:\n        \"\"\"\n        Abstract property for getting the description of the parameter.\n        \"\"\"\n        pass\n\n    @description.setter\n    @abstractmethod\n    def description(self, value: str):\n        \"\"\"\n        Abstract setter for setting the description of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def required(self) -> bool:\n        \"\"\"\n        Abstract property for getting the required status of the parameter.\n        \"\"\"\n        pass\n\n    @required.setter\n    @abstractmethod\n    def required(self, value: bool):\n        \"\"\"\n        Abstract setter for setting the required status of the parameter.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def enum(self) -> Optional[List[Any]]:\n        \"\"\"\n        Abstract property for getting the enum list of the parameter.\n        \"\"\"\n        pass\n\n    @enum.setter\n    @abstractmethod\n    def enum(self, value: Optional[List[Any]]):\n        \"\"\"\n        Abstract setter for setting the enum list of the parameter.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/utils/__init__.py",
        "content": "```swarmauri/core/utils/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/utils/ITransactional.py",
        "content": "```swarmauri/core/utils/ITransactional.py\nfrom abc import ABC, abstractmethod\n\nclass ITransactional(ABC):\n\n    @abstractmethod\n    def begin_transaction(self):\n        \"\"\"\n        Initiates a transaction for a series of vector store operations.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def commit_transaction(self):\n        \"\"\"\n        Commits the current transaction, making all operations within the transaction permanent.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def abort_transaction(self):\n        \"\"\"\n        Aborts the current transaction, reverting all operations performed within the transaction.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/ISimiliarityQuery.py",
        "content": "```swarmauri/core/vector_stores/ISimiliarityQuery.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict\n\nclass ISimilarityQuery(ABC):\n    \n    @abstractmethod\n    def search_by_similarity_threshold(self, query_vector: List[float], similarity_threshold: float, space_name: str = None) -> List[Dict]:\n        \"\"\"\n        Search vectors exceeding a similarity threshold to a query vector within an optional vector space.\n\n        Args:\n            query_vector (List[float]): The high-dimensional query vector.\n            similarity_threshold (float): The similarity threshold for filtering results.\n            space_name (str, optional): The name of the vector space to search within.\n\n        Returns:\n            List[Dict]: A list of dictionaries with vector IDs, similarity scores, and optional metadata that meet the similarity threshold.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IGradient.py",
        "content": "```swarmauri/core/vector_stores/IGradient.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Callable\n\nclass IGradient(ABC):\n    \"\"\"\n    Interface for calculating the gradient of a scalar field.\n    \"\"\"\n\n    @abstractmethod\n    def calculate_gradient(self, scalar_field: Callable[[List[float]], float], point: List[float]) -> List[float]:\n        \"\"\"\n        Calculate the gradient of a scalar field at a specific point.\n\n        Parameters:\n        - scalar_field (Callable[[List[float]], float]): The scalar field represented as a function\n                                                         that takes a point and returns a scalar value.\n        - point (List[float]): The point at which the gradient is to be calculated.\n\n        Returns:\n        - List[float]: The gradient vector at the specified point.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IAngleBetweenVectors.py",
        "content": "```swarmauri/core/vector_stores/IAngleBetweenVectors.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IAngleBetweenVectors(ABC):\n    \"\"\"\n    Interface for calculating the angle between two vectors.\n    \"\"\"\n\n    @abstractmethod\n    def angle_between(self, vector_a: List[float], vector_b: List[float]) -> float:\n        \"\"\"\n        Method to calculate and return the angle in radians between two vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector as a list of floats.\n        - vector_b (List[float]): The second vector as a list of floats.\n\n        Returns:\n        - float: The angle between vector_a and vector_b in radians.\n\n        Note: Implementations should handle the vectors' dimensionality and throw appropriate exceptions for incompatible vectors.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IDecompose.py",
        "content": "```swarmauri/core/vector_stores/IDecompose.py\nfrom abc import ABC, abstractmethod\nfrom typing import Tuple, List\nfrom swarmauri.core.vectors.IVector import IVector  # Assuming there's a base IVector interface for vector representations\n\nclass IDecompose(ABC):\n    \"\"\"\n    Interface for decomposing a vector into components along specified basis vectors.\n    This operation is essential in expressing a vector in different coordinate systems or reference frames.\n    \"\"\"\n\n    @abstractmethod\n    def decompose(self, vector: IVector, basis_vectors: List[IVector]) -> List[IVector]:\n        \"\"\"\n        Decompose the given vector into components along the specified basis vectors.\n\n        Parameters:\n        - vector (IVector): The vector to be decomposed.\n        - basis_vectors (List[IVector]): A list of basis vectors along which to decompose the given vector.\n\n        Returns:\n        - List[IVector]: A list of vectors, each representing the component of the decomposed vector along \n                         the corresponding basis vector in the `basis_vectors` list.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IDivergence.py",
        "content": "```swarmauri/core/vector_stores/IDivergence.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IDivergence(ABC):\n    \"\"\"\n    Interface for calculating the divergence of a vector field.\n    \"\"\"\n\n    @abstractmethod\n    def calculate_divergence(self, vector_field: List[List[float]], point: List[float]) -> float:\n        \"\"\"\n        Calculate the divergence of a vector field at a specific point.\n\n        Parameters:\n        - vector_field (List[List[float]]): A representation of the vector field as a list of vectors.\n        - point (List[float]): The point at which the divergence is to be calculated.\n\n        Returns:\n        - float: The divergence value at the specified point.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IOrthogonalProject.py",
        "content": "```swarmauri/core/vector_stores/IOrthogonalProject.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IOrthogonalProject(ABC):\n    \"\"\"\n    Interface for calculating the orthogonal projection of one vector onto another.\n    \"\"\"\n\n    @abstractmethod\n    def orthogonal_project(self, vector_a: List[float], vector_b: List[float]) -> List[float]:\n        \"\"\"\n        Calculates the orthogonal projection of vector_a onto vector_b.\n        \n        Args:\n            vector_a (List[float]): The vector to be projected.\n            vector_b (List[float]): The vector onto which vector_a is orthogonally projected.\n        \n        Returns:\n            List[float]: The orthogonal projection of vector_a onto vector_b.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IProject.py",
        "content": "```swarmauri/core/vector_stores/IProject.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IProject(ABC):\n    \"\"\"\n    Interface for projecting one vector onto another.\n    \"\"\"\n\n    @abstractmethod\n    def project(self, vector_a: List[float], vector_b: List[float]) -> List[float]:\n        \"\"\"\n        Projects vector_a onto vector_b.\n        \n        Args:\n            vector_a (List[float]): The vector to be projected.\n            vector_b (List[float]): The vector onto which vector_a is projected.\n        \n        Returns:\n            List[float]: The projection of vector_a onto vector_b.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IReflect.py",
        "content": "```swarmauri/core/vector_stores/IReflect.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IReflect(ABC):\n    \"\"\"\n    Interface for reflecting a vector across a specified plane or axis.\n    \"\"\"\n\n    @abstractmethod\n    def reflect_vector(self, vector: List[float], normal: List[float]) -> List[float]:\n        \"\"\"\n        Reflects a vector across a plane or axis defined by a normal vector.\n\n        Parameters:\n        - vector (List[float]): The vector to be reflected.\n        - normal (List[float]): The normal vector of the plane across which the vector will be reflected.\n\n        Returns:\n        - List[float]: The reflected vector.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/ISimilarity.py",
        "content": "```swarmauri/core/vector_stores/ISimilarity.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass ISimilarity(ABC):\n    \"\"\"\n    Interface to define operations for computing similarity and distance between vectors.\n    This interface is crucial for systems that need to perform similarity searches, clustering,\n    or any operations where vector similarity plays a key role.\n    \"\"\"\n\n    @abstractmethod\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the similarity between two vectors. The definition of similarity (e.g., cosine similarity)\n        should be implemented in concrete classes.\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector to compare with the first vector.\n\n        Returns:\n            float: A similarity score between vector_a and vector_b.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorSpan.py",
        "content": "```swarmauri/core/vector_stores/IVectorSpan.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass IVectorSpan(ABC):\n    \"\"\"\n    Interface for determining if a vector is within the span of a set of vectors.\n    \"\"\"\n\n    @abstractmethod\n    def in_span(self, vector: Any, basis_vectors: List[Any]) -> bool:\n        \"\"\"\n        Checks if the given vector is in the span of the provided basis vectors.\n\n        Parameters:\n        - vector (Any): The vector to check.\n        - basis_vectors (List[Any]): A list of vectors that might span the vector.\n\n        Returns:\n        - bool: True if the vector is in the span of the basis_vectors, False otherwise.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorArithmetic.py",
        "content": "```swarmauri/core/vector_stores/IVectorArithmetic.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IVectorArithmetic(ABC):\n    @abstractmethod\n    def add(self, vector1: List[float], vector2: List[float]) -> List[float]:\n        \"\"\"\n        Vector addition of 'vector1' and 'vector2'.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def subtract(self, vector1: List[float], vector2: List[float]) -> List[float]:\n        \"\"\"\n        Vector subtraction of 'vector1' - 'vector2'.\n        \"\"\"\n        pass\n   \n    @abstractmethod\n    def multiply(self, vector: List[float], scalar: float) -> List[float]:\n        \"\"\"\n        Scalar multiplication of 'vector' by 'scalar'.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def divide(self, vector: List[float], scalar: float) -> List[float]:\n        \"\"\"\n        Scalar division of 'vector' by 'scalar'.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorLinearCombination.py",
        "content": "```swarmauri/core/vector_stores/IVectorLinearCombination.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass ILinearCombination(ABC):\n    \"\"\"\n    Interface for creating a vector as a linear combination of a set of vectors.\n    \"\"\"\n\n    @abstractmethod\n    def linear_combination(self, coefficients: List[float], vectors: List[Any]) -> Any:\n        \"\"\"\n        Computes the linear combination of the given vectors with the specified coefficients.\n\n        Parameters:\n        - coefficients (List[float]): A list of coefficients for the linear combination.\n        - vectors (List[Any]): A list of vectors to be combined.\n\n        Returns:\n        - Any: The resulting vector from the linear combination.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorNorm.py",
        "content": "```swarmauri/core/vector_stores/IVectorNorm.py\n# core/vectors/IVectorNorm.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union\n\nclass IVectorNorm(ABC):\n    \"\"\"\n    Interface for calculating vector norms.\n    Supports L1 norm, L2 norm, and Max norm calculations.\n    \"\"\"\n\n    @abstractmethod\n    def l1_norm(self, vector: List[Union[int, float]]) -> float:\n        \"\"\"\n        Calculate the L1 norm (Manhattan norm) of a vector.\n\n        Parameters:\n        - vector (List[Union[int, float]]): The vector for which to calculate the L1 norm.\n\n        Returns:\n        - float: The L1 norm of the vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def l2_norm(self, vector: List[Union[int, float]]) -> float:\n        \"\"\"\n        Calculate the L2 norm (Euclidean norm) of a vector.\n\n        Parameters:\n        - vector (List[Union[int, float]]): The vector for which to calculate the L2 norm.\n\n        Returns:\n        - float: The L2 norm of the vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def max_norm(self, vector: List[Union[int, float]]) -> float:\n        \"\"\"\n        Calculate the Max norm (infinity norm) of a vector.\n\n        Parameters:\n        - vector (List[Union[int, float]]): The vector for which to calculate the Max norm.\n\n        Returns:\n        - float: The Max norm of the vector.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorRotate.py",
        "content": "```swarmauri/core/vector_stores/IVectorRotate.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nclass IRotate(ABC):\n    \"\"\"\n    Interface for rotating a vector.\n    \"\"\"\n    \n    @abstractmethod\n    def rotate(self, vector: List[float], angle: float, axis: List[float] = None) -> List[float]:\n        \"\"\"\n        Rotate the given vector by a specified angle around an axis (for 3D) or in a plane (for 2D).\n\n        For 2D vectors, the axis parameter can be omitted.\n\n        Args:\n            vector (List[float]): The vector to rotate.\n            angle (float): The angle of rotation in degrees.\n            axis (List[float], optional): The axis of rotation (applicable in 3D).\n\n        Returns:\n            List[float]: The rotated vector.\n        \"\"\"\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorBasisCheck.py",
        "content": "```swarmauri/core/vector_stores/IVectorBasisCheck.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass IVectorBasisCheck(ABC):\n    \"\"\"\n    Interface for checking if a given set of vectors forms a basis of the vector space.\n    \"\"\"\n\n    @abstractmethod\n    def is_basis(self, vectors: List[Any]) -> bool:\n        \"\"\"\n        Determines whether the given set of vectors forms a basis for their vector space.\n\n        Parameters:\n        - vectors (List[Any]): A list of vectors to be checked.\n\n        Returns:\n        - bool: True if the vectors form a basis, False otherwise.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/__init__.py",
        "content": "```swarmauri/core/vector_stores/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/ISaveLoadStore.py",
        "content": "```swarmauri/core/vector_stores/ISaveLoadStore.py\nfrom abc import ABC, abstractmethod\n\nclass ISaveLoadStore(ABC):\n    \"\"\"\n    Interface to abstract the ability to save and load the state of a vector store.\n    This includes saving/loading the vectorizer's model as well as the documents or vectors.\n    \"\"\"\n\n    @abstractmethod\n    def save_store(self, directory_path: str) -> None:\n        \"\"\"\n        Saves the state of the vector store to the specified directory. This includes\n        both the vectorizer's model and the stored documents or vectors.\n\n        Parameters:\n        - directory_path (str): The directory path where the store's state will be saved.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_store(self, directory_path: str) -> None:\n        \"\"\"\n        Loads the state of the vector store from the specified directory. This includes\n        both the vectorizer's model and the stored documents or vectors.\n\n        Parameters:\n        - directory_path (str): The directory path from where the store's state will be loaded.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def save_parts(self, directory_path: str, chunk_size: int=10485760) -> None:\n        \"\"\"\n        Save the model in parts to handle large files by splitting them.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_parts(self, directory_path: str, file_pattern: str) -> None:\n        \"\"\"\n        Load and combine model parts from a directory.\n\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorStore.py",
        "content": "```swarmauri/core/vector_stores/IVectorStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Union\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IVectorStore(ABC):\n    \"\"\"\n    Interface for a vector store responsible for storing, indexing, and retrieving documents.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Stores a single document in the vector store.\n\n        Parameters:\n        - document (IDocument): The document to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Stores multiple documents in the vector store.\n\n        Parameters:\n        - documents (List[IDocument]): The list of documents to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Union[IDocument, None]:\n        \"\"\"\n        Retrieves a document by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document.\n\n        Returns:\n        - Union[IDocument, None]: The requested document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieves all documents stored in the vector store.\n\n        Returns:\n        - List[IDocument]: A list of all documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Deletes a document from the vector store by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def clear_documents(self) -> None:\n        \"\"\"\n        Deletes all documents from the vector store\n\n        \"\"\"\n        pass\n\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Updates a document in the vector store.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document to update.\n        - updated_document (IDocument): The updated document object.\n\n        Note: It's assumed that the updated_document will retain the same doc_id but may have different content or metadata.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def document_count(self) -> int:\n        pass \n```"
    },
    {
        "document_name": "swarmauri/core/vector_stores/IVectorRetrieve.py",
        "content": "```swarmauri/core/vector_stores/IVectorRetrieve.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IVectorRetrieve(ABC):\n    \"\"\"\n    Abstract base class for document retrieval operations.\n    \n    This class defines the interface for retrieving documents based on a query or other criteria.\n    Implementations may use various indexing or search technologies to fulfill these retrievals.\n    \"\"\"\n\n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the most relevant documents based on the given query.\n        \n        Parameters:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n            \n        Returns:\n            List[Document]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/document_stores/IDocumentStore.py",
        "content": "```swarmauri/core/document_stores/IDocumentStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IDocumentStore(ABC):\n    \"\"\"\n    Interface for a Document Store responsible for storing, indexing, and retrieving documents.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Stores a single document in the document store.\n\n        Parameters:\n        - document (IDocument): The document to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Stores multiple documents in the document store.\n\n        Parameters:\n        - documents (List[IDocument]): The list of documents to store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Union[IDocument, None]:\n        \"\"\"\n        Retrieves a document by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document.\n\n        Returns:\n        - Union[IDocument, None]: The requested document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieves all documents stored in the document store.\n\n        Returns:\n        - List[IDocument]: A list of all documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Deletes a document from the document store by its ID.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Updates a document in the document store.\n\n        Parameters:\n        - doc_id (str): The unique identifier for the document to update.\n        - updated_document (IDocument): The updated document object.\n\n        Note: It's assumed that the updated_document will retain the same doc_id but may have different content or metadata.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def document_count(self) -> int:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/document_stores/__init__.py",
        "content": "```swarmauri/core/document_stores/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/document_stores/IDocumentRetrieve.py",
        "content": "```swarmauri/core/document_stores/IDocumentRetrieve.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass IDocumentRetrieve(ABC):\n    \"\"\"\n    Abstract base class for document retrieval operations.\n    \n    This class defines the interface for retrieving documents based on a query or other criteria.\n    Implementations may use various indexing or search technologies to fulfill these retrievals.\n    \"\"\"\n\n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the most relevant documents based on the given query.\n        \n        Parameters:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n            \n        Returns:\n            List[Document]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chunkers/__init__.py",
        "content": "```swarmauri/core/chunkers/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/chunkers/IChunker.py",
        "content": "```swarmauri/core/chunkers/IChunker.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union, Any\n\nclass IChunker(ABC):\n    \"\"\"\n    Interface for chunking text into smaller pieces.\n\n    This interface defines abstract methods for chunking texts. Implementing classes\n    should provide concrete implementations for these methods tailored to their specific\n    chunking algorithms.\n    \"\"\"\n\n    @abstractmethod\n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[Any]:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVectorMeta.py",
        "content": "```swarmauri/core/vectors/IVectorMeta.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\n\nclass IVectorMeta(ABC):\n    \"\"\"\n    Interface for a high-dimensional data vector. This interface defines the\n    basic structure and operations for interacting with vectors in various applications,\n    such as machine learning, information retrieval, and similarity search.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"\n        Unique identifier for the vector. This ID can be used to reference the vector\n        in a database or a vector store.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def metadata(self) -> Dict[str, Any]:\n        \"\"\"\n        Optional metadata associated with the vector. Metadata can include additional information\n        useful for retrieval, categorization, or description of the vector data.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVectorTransform.py",
        "content": "```swarmauri/core/vectors/IVectorTransform.py\nfrom abc import ABC, abstractmethod\nfrom .IVector import IVector\n\nclass IVectorTransform(ABC):\n    \"\"\"\n    Interface for performing various transformations on vectors.\n    \"\"\"\n\n    @abstractmethod\n    def translate(self, translation_vector: IVector) -> IVector:\n        \"\"\"\n        Translate a vector by a given translation vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def rotate(self, angle: float, axis: IVector) -> IVector:\n        \"\"\"\n        Rotate a vector around a given axis by a certain angle.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def reflect(self, plane_normal: IVector) -> IVector:\n        \"\"\"\n        Reflect a vector across a plane defined by its normal vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def scale(self, scale_factor: float) -> IVector:\n        \"\"\"\n        Scale a vector by a given scale factor.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def shear(self, shear_factor: float, direction: IVector) -> IVector:\n        \"\"\"\n        Shear a vector along a given direction by a shear factor.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def project(self, plane_normal: IVector) -> IVector:\n        \"\"\"\n        Project a vector onto a plane defined by its normal vector.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVector.py",
        "content": "```swarmauri/core/vectors/IVector.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\n\nclass IVector(ABC):\n    \"\"\"\n    Interface for a high-dimensional data vector. This interface defines the\n    basic structure and operations for interacting with vectors in various applications,\n    such as machine learning, information retrieval, and similarity search.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def data(self) -> List[float]:\n        \"\"\"\n        The high-dimensional data that the vector represents. It is typically a list of float values.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/__init__.py",
        "content": "```swarmauri/core/vectors/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/vectors/IVectorProduct.py",
        "content": "```swarmauri/core/vectors/IVectorProduct.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\n\nclass IVectorProduct(ABC):\n    \"\"\"\n    Interface for various vector products including dot product, cross product,\n    and triple products (vector and scalar).\n    \"\"\"\n\n    @abstractmethod\n    def dot_product(self, vector_a: List[float], vector_b: List[float]) -> float:\n        \"\"\"\n        Calculate the dot product of two vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n\n        Returns:\n        - float: The dot product of the two vectors.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def cross_product(self, vector_a: List[float], vector_b: List[float]) -> List[float]:\n        \"\"\"\n        Calculate the cross product of two vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n\n        Returns:\n        - List[float]: The cross product as a new vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def vector_triple_product(self, vector_a: List[float], vector_b: List[float], vector_c: List[float]) -> List[float]:\n        \"\"\"\n        Calculate the vector triple product of three vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n        - vector_c (List[float]): The third vector.\n\n        Returns:\n        - List[float]: The result of the vector triple product as a new vector.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def scalar_triple_product(self, vector_a: List[float], vector_b: List[float], vector_c: List[float]) -> float:\n        \"\"\"\n        Calculate the scalar triple product of three vectors.\n\n        Parameters:\n        - vector_a (List[float]): The first vector.\n        - vector_b (List[float]): The second vector.\n        - vector_c (List[float]): The third vector.\n\n        Returns:\n        - float: The scalar value result of the scalar triple product.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarm_apis/__init__.py",
        "content": "```swarmauri/core/swarm_apis/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/swarm_apis/ISwarmAPI.py",
        "content": "```swarmauri/core/swarm_apis/ISwarmAPI.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any\n\nclass ISwarmAPI(ABC):\n    \"\"\"\n    Interface for managing the swarm's API endpoints.\n    \"\"\"\n    \n    @abstractmethod\n    def dispatch_request(self, request_data: Dict[str, Any]) -> Any:\n        \"\"\"\n        Dispatches an incoming user request to one or more suitable agents based on their capabilities.\n\n        Parameters:\n        - request_data (Dict[str, Any]): Data related to the incoming request.\n\n        Returns:\n        - Any: Response from processing the request.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def broadcast_request(self, request_data: Dict[str, Any]) -> Any:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/swarm_apis/IAgentRegistrationAPI.py",
        "content": "```swarmauri/core/swarm_apis/IAgentRegistrationAPI.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Optional\nfrom swarmauri.core.agents.IAgent import IAgent\n\nclass IAgentRegistrationAPI(ABC):\n    \"\"\"\n    Interface for registering agents with the swarm, designed to support CRUD operations on IAgent instances.\n    \"\"\"\n\n    @abstractmethod\n    def register_agent(self, agent: IAgent) -> bool:\n        \"\"\"\n        Register a new agent with the swarm.\n\n        Parameters:\n            agent (IAgent): An instance of IAgent representing the agent to register.\n\n        Returns:\n            bool: True if the registration succeeded; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_agent(self, agent_id: str, updated_agent: IAgent) -> bool:\n        \"\"\"\n        Update the details of an existing agent. This could include changing the agent's configuration,\n        task assignment, or any other mutable attribute.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent.\n            updated_agent (IAgent): An updated IAgent instance to replace the existing one.\n\n        Returns:\n            bool: True if the update was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_agent(self, agent_id: str) -> bool:\n        \"\"\"\n        Remove an agent from the swarm based on its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent to be removed.\n\n        Returns:\n            bool: True if the removal was successful; False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_agent(self, agent_id: str) -> Optional[IAgent]:\n        \"\"\"\n        Retrieve an agent's instance from its unique identifier.\n\n        Parameters:\n            agent_id (str): The unique identifier for the agent of interest.\n\n        Returns:\n            Optional[IAgent]: The IAgent instance if found; None otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_agents(self) -> List[IAgent]:\n        \"\"\"\n        List all registered agents.\n\n        Returns:\n            List[IAgent]: A list containing instances of all registered IAgents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/__init__.py",
        "content": "```swarmauri/core/vectorizers/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/IVectorize.py",
        "content": "```swarmauri/core/vectorizers/IVectorize.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union, Any\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass IVectorize(ABC):\n    \"\"\"\n    Interface for converting text to vectors. \n    Implementations of this interface transform input text into numerical \n    vectors that can be used in machine learning models, similarity calculations, \n    and other vector-based operations.\n    \"\"\"\n    @abstractmethod\n    def fit(self, data: Union[str, Any]) -> List[IVector]:\n        pass\n    \n    @abstractmethod\n    def transform(self, data: Union[str, Any]) -> List[IVector]:\n        pass\n\n    @abstractmethod\n    def fit_transform(self, data: Union[str, Any]) -> List[IVector]:\n        pass\n\n    @abstractmethod\n    def infer_vector(self, data: Union[str, Any], *args, **kwargs) -> IVector:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/IFeature.py",
        "content": "```swarmauri/core/vectorizers/IFeature.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any\n\nclass IFeature(ABC):\n\n    @abstractmethod\n    def extract_features(self) -> List[Any]:\n        pass\n    \n\n```"
    },
    {
        "document_name": "swarmauri/core/vectorizers/ISaveModel.py",
        "content": "```swarmauri/core/vectorizers/ISaveModel.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any\n\nclass ISaveModel(ABC):\n    \"\"\"\n    Interface to abstract the ability to save and load models.\n    \"\"\"\n\n    @abstractmethod\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the model to the specified directory.\n\n        Parameters:\n        - path (str): The directory path where the model will be saved.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_model(self, path: str) -> Any:\n        \"\"\"\n        Loads a model from the specified directory.\n\n        Parameters:\n        - path (str): The directory path from where the model will be loaded.\n\n        Returns:\n        - Returns an instance of the loaded model.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/__init__.py",
        "content": "```swarmauri/core/tracing/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/ITraceContext.py",
        "content": "```swarmauri/core/tracing/ITraceContext.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any\n\nclass ITraceContext(ABC):\n    \"\"\"\n    Interface for a trace context, representing a single trace instance.\n    This context carries the state and metadata of the trace across different system components.\n    \"\"\"\n\n    @abstractmethod\n    def get_trace_id(self) -> str:\n        \"\"\"\n        Retrieves the unique identifier for this trace.\n\n        Returns:\n            str: The unique trace identifier.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_attribute(self, key: str, value: Any):\n        \"\"\"\n        Adds or updates an attribute associated with this trace.\n\n        Args:\n            key (str): The attribute key or name.\n            value (Any): The value of the attribute.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/ITracer.py",
        "content": "```swarmauri/core/tracing/ITracer.py\nfrom swarmauri.core.tracing.ITraceContext import ITraceContext\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Dict, Any\n\n\nclass ITracer(ABC):\n    \"\"\"\n    Interface for implementing distributed tracing across different components of the system.\n    \"\"\"\n\n    @abstractmethod\n    def start_trace(self, name: str, initial_attributes: Optional[Dict[str, Any]] = None) -> ITraceContext:\n        \"\"\"\n        Starts a new trace with a given name and optional initial attributes.\n\n        Args:\n            name (str): Name of the trace, usually represents the operation being traced.\n            initial_attributes (Optional[Dict[str, Any]]): Key-value pairs to be attached to the trace initially.\n\n        Returns:\n            ITraceContext: A context object representing this particular trace instance.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def end_trace(self, trace_context: ITraceContext):\n        \"\"\"\n        Marks the end of a trace, completing its lifecycle and recording its details.\n\n        Args:\n            trace_context (ITraceContext): The trace context to be ended.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def annotate_trace(self, trace_context: ITraceContext, key: str, value: Any):\n        \"\"\"\n        Adds an annotation to an existing trace, enriching it with more detailed information.\n\n        Args:\n            trace_context (ITraceContext): The trace context to annotate.\n            key (str): The key or name of the annotation.\n            value (Any): The value of the annotation.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/tracing/IChainTracer.py",
        "content": "```swarmauri/core/tracing/IChainTracer.py\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, List, Tuple, Dict, Any\n\nclass IChainTracer(ABC):\n    \"\"\"\n    Interface for a tracer supporting method chaining through a list of tuples.\n    Each tuple in the list contains: trace context, function, args, and kwargs.\n    \"\"\"\n\n    @abstractmethod\n    def process_chain(self, chain: List[Tuple[Any, Callable[..., Any], List[Any], Dict[str, Any]]]) -> \"IChainTracer\":\n        \"\"\"\n        Processes a sequence of operations defined in a chain.\n\n        Args:\n            chain (List[Tuple[Any, Callable[..., Any], List[Any], Dict[str, Any]]]): A list where each tuple contains:\n                - The trace context or reference required by the function.\n                - The function (method of IChainTracer) to execute.\n                - A list of positional arguments for the function.\n                - A dictionary of keyword arguments for the function.\n\n        Returns:\n            IChainTracer: Returns self to allow further method chaining.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/ICallableChain.py",
        "content": "```swarmauri/core/chains/ICallableChain.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Callable, List, Tuple\n\nCallableDefinition = Tuple[Callable, List[Any], dict]\n\nclass ICallableChain(ABC):\n    @abstractmethod\n    def __call__(self, *initial_args: Any, **initial_kwargs: Any) -> Any:\n        \"\"\"Executes the chain of callables.\"\"\"\n        pass\n\n    @abstractmethod\n    def add_callable(self, func: Callable, args: List[Any] = None, kwargs: dict = None) -> None:\n        \"\"\"Adds a new callable to the chain.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/__init__.py",
        "content": "```swarmauri/core/chains/__init__.py\nfrom swarmauri.core.chains.ICallableChain import ICallableChain\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChain.py",
        "content": "```swarmauri/core/chains/IChain.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any, Dict\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass IChain(ABC):\n    \"\"\"\n    Defines the interface for a Chain within a system, facilitating the organized\n    execution of a sequence of tasks or operations. This interface is at the core of\n    orchestrating operations that require coordination between multiple steps, potentially\n    involving decision-making, branching, and conditional execution based on the outcomes\n    of previous steps or external data.\n\n    A chain can be thought of as a workflow or pipeline, where each step in the chain can\n    perform an operation, transform data, or make decisions that influence the flow of\n    execution.\n\n    Implementors of this interface are responsible for managing the execution order,\n    data flow between steps, and any dynamic adjustments to the execution based on\n    runtime conditions.\n\n    Methods:\n        add_step: Adds a step to the chain.\n        remove_step: Removes a step from the chain.\n        execute: Executes the chain, potentially returning a result.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, steps: List[IChainStep] = None, **configs):\n        pass\n\n    @abstractmethod\n    def add_step(self, step: IChainStep, **kwargs) -> None:\n        \"\"\"\n        Adds a new step to the chain. Steps are executed in the order they are added.\n        Each step is represented by a Callable, which can be a function or method, with\n        optional keyword arguments that specify execution aspects or data needed by the step.\n\n        Parameters:\n            step (IChainStep): The Callable representing the step to add to the chain.\n            **kwargs: Optional keyword arguments that provide additional data or configuration\n                      for the step when it is executed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_step(self, step: IChainStep) -> None:\n        \"\"\"\n        Removes an existing step from the chain. This alters the chain's execution sequence\n        by excluding the specified step from subsequent executions of the chain.\n\n        Parameters:\n            step (IChainStep): The Callable representing the step to remove from the chain.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def execute(self, *args, **kwargs) -> Any:\n        \"\"\"\n        Initiates the execution of the chain. This involves invoking each step in the order\n        they have been added to the chain, passing control from one step to the next, and optionally\n        aggregating or transforming results along the way.\n\n        The execution process can incorporate branching, looping, or conditional logic based on the\n        implementation, allowing for complex workflows to be represented and managed within the chain.\n\n        Parameters:\n            *args: Positional arguments passed to the first step in the chain. These can be data inputs\n                   or other values required for the chain's execution.\n            **kwargs: Keyword arguments that provide additional context, data inputs, or configuration\n                      for the chain's execution. These can be passed to individual steps or influence\n                      the execution flow of the chain.\n\n        Returns:\n            Any: The outcome of executing the chain. This could be a value produced by the final\n                 step, a collection of outputs from multiple steps, or any other result type as\n                 determined by the specific chain implementation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_schema_info(self) -> Dict[str, Any]:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChainFactory.py",
        "content": "```swarmauri/core/chains/IChainFactory.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any, Dict\nfrom swarmauri.core.chains.IChain import IChain\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass IChainFactory(ABC):\n    \"\"\"\n    Interface for creating and managing execution chains within the system.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, **configs):\n        pass\n\n    @abstractmethod\n    def create_chain(self, steps: List[IChainStep] = None) -> IChain:\n        pass\n    \n    @abstractmethod\n    def get_schema_info(self) -> Dict[str, Any]:\n        pass\n    \n    @abstractmethod\n    def get_chain_info(self) -> Dict[str, Any]:\n        pass\n    \n    @abstractmethod\n    def get_chain(self) -> IChain:\n        pass\n    \n    @abstractmethod\n    def set_chain(self, chain: IChain):\n        pass\n    \n    @abstractmethod\n    def reset_chain(self):\n        pass\n    \n    @abstractmethod\n    def get_chain_steps(self) -> List[IChainStep]:\n        pass\n    \n    @abstractmethod\n    def set_chain_steps(self, steps: List[IChainStep]):\n        pass\n    \n    @abstractmethod\n    def add_chain_step(self, step: IChainStep):\n        pass\n    \n    @abstractmethod\n    def remove_chain_step(self, key: str):\n        pass\n    \n    \n    @abstractmethod\n    def get_configs(self) -> Dict[str, Any]:\n        pass\n    \n    @abstractmethod\n    def set_configs(self, **configs):\n        pass\n    \n    @abstractmethod\n    \n    def get_config(self, key: str) -> Any:\n        pass\n    \n    @abstractmethod\n    def set_config(self, key: str, value: Any):\n        pass\n    \n    @abstractmethod\n    def get_schema_info(self) -> Dict[str, Any]:\n        pass\n\n    @abstractmethod\n    def get_chain_info(self) -> Dict[str, Any]:\n        pass    \n    \n\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChainStep.py",
        "content": "```swarmauri/core/chains/IChainStep.py\nfrom typing import List, Dict, Any, Callable\n\nclass IChainStep:\n    \"\"\"\n    Represents a single step within an execution chain.\n    \"\"\"\n    def __init__(self, \n        key: str, \n        method: Callable, \n        args: List[Any] = None, \n        kwargs: Dict[str, Any] = None, \n        ref: str = None):\n        \"\"\"\n        Initialize a chain step.\n\n        Args:\n            key (str): Unique key or identifier for the step.\n            method (Callable): The callable object (function or method) to execute in this step.\n            args (List[Any], optional): Positional arguments for the callable.\n            kwargs (Dict[str, Any], optional): Keyword arguments for the callable.\n            ref (str, optional): Reference to another component or context variable, if applicable.\n        \"\"\"\n        self.key = key\n        self.method = method\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.ref = ref\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChainContextLoader.py",
        "content": "```swarmauri/core/chains/IChainContextLoader.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\n\nclass IChainContextLoader(ABC):\n    @abstractmethod\n    def load_context(self, context_id: str) -> Dict[str, Any]:\n        \"\"\"Load the execution context by its identifier.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChainDependencyResolver.py",
        "content": "```swarmauri/core/chains/IChainDependencyResolver.py\nfrom abc import ABC, abstractmethod\nfrom typing import Tuple, Dict, List\n\nclass IChainDependencyResolver(ABC):\n    @abstractmethod\n    def build_dependencies(self) -> List[ChainStep]:\n        \"\"\"\n        Builds the dependencies for a particular sequence in the matrix.\n\n        Args:\n            matrix (List[List[str]]): The prompt matrix.\n            sequence_index (int): The index of the sequence to build dependencies for.\n\n        Returns:\n            Tuple containing indegrees and graph dicts.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def resolve_dependencies(self, matrix: List[List[Optional[str]]], sequence_index: int) -> List[int]:\n        \"\"\"\n        Resolves the execution order based on the provided dependencies.\n\n        Args:\n            indegrees (Dict[int, int]): The indegrees of each node.\n            graph (Dict[int, List[int]]): The graph representing dependencies.\n\n        Returns:\n            List[int]: The resolved execution order.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/chains/IChainContext.py",
        "content": "```swarmauri/core/chains/IChainContext.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any\n\nclass IChainContext(ABC):\n    @property\n    @abstractmethod\n    def context(self) -> Dict[str, Any]:\n        pass\n\n    @context.setter\n    @abstractmethod\n    def context(self, value: Dict[str, Any]) -> None:\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/distances/__init__.py",
        "content": "```swarmauri/core/distances/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/distances/IDistanceSimilarity.py",
        "content": "```swarmauri/core/distances/IDistanceSimilarity.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom ..vectors.IVector import IVector\n\nclass IDistanceSimilarity(ABC):\n    \"\"\"\n    Interface for computing distances and similarities between high-dimensional data vectors. This interface\n    abstracts the method for calculating the distance and similarity, allowing for the implementation of various \n    distance metrics such as Euclidean, Manhattan, Cosine similarity, etc.\n    \"\"\"\n\n    @abstractmethod\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The computed distance between vector_a and vector_b.\n        \"\"\"\n        pass\n    \n\n    @abstractmethod\n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> float:\n        pass\n\n\n    @abstractmethod\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the similarity between two vectors. The definition of similarity (e.g., cosine similarity)\n        should be implemented in concrete classes.\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector to compare with the first vector.\n\n        Returns:\n            float: A similarity score between vector_a and vector_b.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> float:\n        pass\n\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/__init__.py",
        "content": "```swarmauri/core/metrics/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/IMetric.py",
        "content": "```swarmauri/core/metrics/IMetric.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\n\nclass IMetric(ABC):\n    \"\"\"\n    Defines a general interface for metrics within the SwarmaURI system.\n    Metrics can be anything from system performance measurements to\n    machine learning model evaluation metrics.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"\n        The name identifier for the metric.\n\n        Returns:\n            str: The name of the metric.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def value(self) -> Any:\n        \"\"\"\n        Current value of the metric.\n\n        Returns:\n            The metric's value. The type depends on the specific metric implementation.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def unit(self) -> str:\n        \"\"\"\n        The unit of measurement for the metric.\n\n        Returns:\n            str: The unit of measurement (e.g., 'seconds', 'Mbps').\n        \"\"\"\n        pass\n\n    @unit.setter\n    @abstractmethod\n    def unit(self, value: str) -> None:\n        \"\"\"\n        Update the unit of measurement for the metric.\n\n        Args:\n            value (str): The new unit of measurement for the metric.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def __call__(self, **kwargs) -> Any:\n        \"\"\"\n        Retrieves the current value of the metric.\n\n        Returns:\n            The current value of the metric.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/ICalculateMetric.py",
        "content": "```swarmauri/core/metrics/ICalculateMetric.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\n\nclass ICalculateMetric(ABC):\n\n    @abstractmethod\n    def calculate(self, **kwargs) -> Any:\n        \"\"\"\n        Calculate the metric based on the provided data.\n\n        Args:\n            *args: Variable length argument list that the metric calculation might require.\n            **kwargs: Arbitrary keyword arguments that the metric calculation might require.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update(self, value) -> None:\n        \"\"\"\n        Update the metric value based on new information.\n\n        Args:\n            value: The new information used to update the metric. This could be a new\n            measurement or data point that affects the metric's current value.\n\n        Note:\n            This method is intended for internal use and should not be publicly accessible.\n        \"\"\"\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/IAggMeasurements.py",
        "content": "```swarmauri/core/metrics/IAggMeasurements.py\nfrom typing import List, Any\nfrom abc import ABC, abstractmethod\n\nclass IAggMeasurements(ABC):\n\n    @abstractmethod\n    def add_measurement(self, measurement: Any) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def measurements(self) -> List[Any]:\n        pass\n\n    @measurements.setter\n    @abstractmethod\n    def measurements(self, value) -> None:\n        pass\n\n    @abstractmethod\n    def reset(self) -> None:\n        \"\"\"\n        Reset or clear the metric's current state, starting fresh as if no data had been processed.\n        This is useful for metrics that might aggregate or average data over time and need to be reset.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/metrics/IThreshold.py",
        "content": "```swarmauri/core/metrics/IThreshold.py\nfrom abc import ABC, abstractmethod\n\nclass IThreshold(ABC):\n    @property\n    @abstractmethod\n    def k(self) -> int:\n        pass\n\n    @k.setter\n    @abstractmethod\n    def k(self, value: int) -> None:\n        pass\n\n\n```"
    },
    {
        "document_name": "swarmauri/core/experiment_stores/__init__.py",
        "content": "```swarmauri/core/experiment_stores/__init__.py\n# core/experiment_stores/IExperimentStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Union\nfrom swarmauri.core.documents.IExperimentDocument import IExperimentDocument\n\nclass IExperimentStore(ABC):\n    \"\"\"\n    Interface for an Experiment Store that manages experimental documents and supports\n    operations related to experimenting, evaluating, testing, and benchmarking.\n    \"\"\"\n    @abstractmethod\n    def add_experiment(self, experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Stores a single experiment in the experiment store.\n\n        Parameters:\n        - experiment (IExperimentDocument): The experimental document to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_experiments(self, experiments: List[IExperimentDocument]) -> None:\n        \"\"\"\n        Stores multiple experiments in the experiment store.\n\n        Parameters:\n        - experiments (List[IExperimentDocument]): The list of experimental documents to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_experiment(self, experiment_id: str) -> Union[IExperimentDocument, None]:\n        \"\"\"\n        Retrieves an experimental document by its ID.\n\n        Parameters:\n        - id (str): The unique identifier of the experiment.\n\n        Returns:\n        - Union[IExperimentDocument, None]: The requested experimental document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_experiments(self) -> List[IExperimentDocument]:\n        \"\"\"\n        Retrieves all experimental documents stored in the experiment store.\n\n        Returns:\n        - List[IExperimentDocument]: A list of all experimental documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_experiment(self, experiment_id: str, updated_experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Updates an experimental document in the experiment store.\n\n        Parameters:\n        - id (str): The unique identifier of the experiment to update.\n        - updated_experiment (IExperimentDocument): The updated experimental document.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_experiment(self, experiment_id: str) -> None:\n        \"\"\"\n        Deletes an experimental document from the experiment store by its ID.\n\n        Parameters:\n        - id (str): The unique identifier of the experimental document to be deleted.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def evaluate_experiments(self, evaluation_criteria: Dict[str, Any]) -> Any:\n        \"\"\"\n        Evaluates the experiments stored in the experiment store based on given criteria and metrics.\n\n        Parameters:\n        - evaluation_criteria (Dict[str, Any]): The criteria and metrics to evaluate the experiments.\n\n        Returns:\n        - Any: The evaluation results, which may vary depending on the evaluation criteria.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def benchmark_experiments(self, benchmarking_data: Dict[str, Any]) -> Any:\n        \"\"\"\n        Benchmarks the experiments against each other or predefined standards.\n\n        Parameters:\n        - benchmarking_data (Dict[str, Any]): Data and parameters for benchmarking the experiments.\n\n        Returns:\n        - Any: The benchmark results, which may vary depending on the benchmarking methodology.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/experiment_stores/IExperimentStore.py",
        "content": "```swarmauri/core/experiment_stores/IExperimentStore.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Union\nfrom swarmauri.core.documents.IExperimentDocument import IExperimentDocument\n\nclass IExperimentStore(ABC):\n    \"\"\"\n    Interface for an Experiment Store that manages experimental documents and supports\n    operations related to experimenting, evaluating, testing, and benchmarking.\n    \"\"\"\n    @abstractmethod\n    def add_experiment(self, experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Stores a single experiment in the experiment store.\n\n        Parameters:\n        - experiment (IExperimentDocument): The experimental document to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_experiments(self, experiments: List[IExperimentDocument]) -> None:\n        \"\"\"\n        Stores multiple experiments in the experiment store.\n\n        Parameters:\n        - experiments (List[IExperimentDocument]): The list of experimental documents to be stored.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_experiment(self, experiment_id: str) -> Union[IExperimentDocument, None]:\n        \"\"\"\n        Retrieves an experimental document by its ID.\n\n        Parameters:\n        - experiment_id (str): The unique identifier of the experiment.\n\n        Returns:\n        - Union[IExperimentDocument, None]: The requested experimental document, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_experiments(self) -> List[IExperimentDocument]:\n        \"\"\"\n        Retrieves all experimental documents stored in the experiment store.\n\n        Returns:\n        - List[IExperimentDocument]: A list of all experimental documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_experiment(self, experiment_id: str, updated_experiment: IExperimentDocument) -> None:\n        \"\"\"\n        Updates an experimental document in the experiment store.\n\n        Parameters:\n        - experiment_id (str): The unique identifier of the experiment to update.\n        - updated_experiment (IExperimentDocument): The updated experimental document.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_experiment(self, experiment_id: str) -> None:\n        \"\"\"\n        Deletes an experimental document from the experiment store by its ID.\n\n        Parameters:\n        - experiment_id (str): The unique identifier of the experimental document to be deleted.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/core/agent_factories/IAgentFactory.py",
        "content": "```swarmauri/core/agent_factories/IAgentFactory.py\nfrom abc import ABC, abstractmethod\nfrom typing import Type, Any\nfrom datetime import datetime\n\nclass IAgentFactory(ABC):\n    \"\"\"\n    Interface for Agent Factories, extended to include properties like ID, name, type,\n    creation date, and last modification date.\n    \"\"\"\n\n    @abstractmethod\n    def create_agent(self, agent_type: str, **kwargs) -> Any:\n        pass\n\n    @abstractmethod\n    def register_agent(self, agent_type: str, constructor: Type[Any]) -> None:\n        pass\n\n    # Abstract properties and setters\n    @property\n    @abstractmethod\n    def id(self) -> str:\n        \"\"\"Unique identifier for the factory instance.\"\"\"\n        pass\n\n    @id.setter\n    @abstractmethod\n    def id(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"Name of the factory.\"\"\"\n        pass\n\n    @name.setter\n    @abstractmethod\n    def name(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def type(self) -> str:\n        \"\"\"Type of agents this factory produces.\"\"\"\n        pass\n\n    @type.setter\n    @abstractmethod\n    def type(self, value: str) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def date_created(self) -> datetime:\n        \"\"\"The creation date of the factory instance.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def last_modified(self) -> datetime:\n        \"\"\"Date when the factory was last modified.\"\"\"\n        pass\n\n    @last_modified.setter\n    @abstractmethod\n    def last_modified(self, value: datetime) -> None:\n        pass\n\n    def __hash__(self):\n        \"\"\"\n        The __hash__ method allows objects of this class to be used in sets and as dictionary keys.\n        __hash__ should return an integer and be defined based on immutable properties.\n        This is generally implemented directly in concrete classes rather than in the interface,\n        but it's declared here to indicate that implementing classes must provide it.\n        \"\"\"\n        pass\n\n   \n```"
    },
    {
        "document_name": "swarmauri/core/agent_factories/__init__.py",
        "content": "```swarmauri/core/agent_factories/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/core/agent_factories/IExportConf.py",
        "content": "```swarmauri/core/agent_factories/IExportConf.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict\n\nclass IExportConf(ABC):\n    \"\"\"\n    Interface for exporting configurations related to agent factories.\n    \n    Implementing classes are expected to provide functionality for representing\n    the factory's configuration as a dictionary, JSON string, or exporting to a file.\n    \"\"\"\n\n    @abstractmethod\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Serializes the agent factory's configuration to a dictionary.\n        \n        Returns:\n            Dict[str, Any]: A dictionary representation of the factory's configuration.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_json(self) -> str:\n        \"\"\"\n        Serializes the agent factory's configuration to a JSON string.\n        \n        Returns:\n            str: A JSON string representation of the factory's configuration.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_file(self, file_path: str) -> None:\n        \"\"\"\n        Exports the agent factory's configuration to a file in a suitable format.\n        \n        Parameters:\n            file_path (str): The path to the file where the configuration should be saved.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/experimental/__init__.py",
        "content": "```swarmauri/experimental/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/tools/LinkedInArticleTool.py",
        "content": "```swarmauri/experimental/tools/LinkedInArticleTool.py\nimport requests\nfrom ...standard.tools.base.ToolBase import ToolBase\nfrom ...standard.tools.concrete.Parameter import Parameter\n\nclass LinkedInArticleTool(ToolBase):\n    \"\"\"\n    A tool to post articles on LinkedIn using the LinkedIn API.\n    \"\"\"\n    def __init__(self, access_token):\n        \"\"\"\n        Initializes the LinkedInArticleTool with the necessary access token.\n        \n        Args:\n            access_token (str): The OAuth access token for authenticating with the LinkedIn API.\n        \"\"\"\n        super().__init__(name=\"LinkedInArticleTool\",\n                         description=\"A tool for posting articles on LinkedIn.\",\n                         parameters=[\n                             Parameter(name=\"title\", type=\"string\", description=\"The title of the article\", required=True),\n                             Parameter(name=\"text\", type=\"string\", description=\"The body text of the article\", required=True),\n                             Parameter(name=\"visibility\", type=\"string\", description=\"The visibility of the article\", required=True, enum=[\"anyone\", \"connectionsOnly\"])\n                         ])\n        self.access_token = access_token\n        \n    def __call__(self, title: str, text: str, visibility: str = \"anyone\") -> str:\n        \"\"\"\n        Posts an article on LinkedIn.\n\n        Args:\n            title (str): The title of the article.\n            text (str): The body text of the article.\n            visibility (str): The visibility of the article, either \"anyone\" or \"connectionsOnly\".\n\n        Returns:\n            str: A message indicating the success or failure of the post operation.\n        \"\"\"\n        # Construct the request URL and payload according to LinkedIn API documentation\n        url = 'https://api.linkedin.com/v2/ugcPosts'\n        headers = {\n            'Authorization': f'Bearer {self.access_token}',\n            'X-Restli-Protocol-Version': '2.0.0',\n            'Content-Type': 'application/json'\n        }\n        \n        payload = {\n            \"author\": \"urn:li:person:YOUR_PERSON_ID_HERE\",\n            \"lifecycleState\": \"PUBLISHED\",\n            \"specificContent\": {\n                \"com.linkedin.ugc.ShareContent\": {\n                    \"shareCommentary\": {\n                        \"text\": text\n                    },\n                    \"shareMediaCategory\": \"ARTICLE\",\n                    \"media\": [\n                        {\n                            \"status\": \"READY\",\n                            \"description\": {\n                                \"text\": title\n                            },\n                            \"originalUrl\": \"URL_OF_THE_ARTICLE_OR_IMAGE\",\n                            \"visibility\": {\n                                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility.upper()\n                            }\n                        }\n                    ]\n                }\n            },\n            \"visibility\": {\n                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility.upper()\n            }\n        }\n     \n        # Make the POST request to LinkedIn's API\n        response = requests.post(url, headers=headers, json=payload)\n        \n        if response.status_code == 201:\n            return f\"Article posted successfully: {response.json().get('id')}\"\n        else:\n            return f\"Failed to post the article. Status Code: {response.status_code} - {response.text}\"\n```"
    },
    {
        "document_name": "swarmauri/experimental/tools/TwitterPostTool.py",
        "content": "```swarmauri/experimental/tools/TwitterPostTool.py\nfrom tweepy import Client\n\nfrom ...standard.tools.base.ToolBase import ToolBase\nfrom ...standard.tools.concrete.Parameter import Parameter\n\nclass TwitterPostTool(ToolBase):\n    def __init__(self, bearer_token):\n        # Initialize parameters necessary for posting a tweet\n        parameters = [\n            Parameter(\n                name=\"status\",\n                type=\"string\",\n                description=\"The status message to post on Twitter\",\n                required=True\n            )\n        ]\n        \n        super().__init__(name=\"TwitterPostTool\", description=\"Post a status update on Twitter\", parameters=parameters)\n        \n        # Initialize Twitter API Client\n        self.client = Client(bearer_token=bearer_token)\n\n    def __call__(self, status: str) -> str:\n        \"\"\"\n        Posts a status on Twitter.\n\n        Args:\n            status (str): The status message to post.\n\n        Returns:\n            str: A confirmation message including the tweet's URL if successful.\n        \"\"\"\n        try:\n            # Using Tweepy to send a tweet\n            response = self.client.create_tweet(text=status)\n            tweet_id = response.data['id']\n            # Constructing URL to the tweet - Adjust the URL to match Twitter API v2 structure if needed\n            tweet_url = f\"https://twitter.com/user/status/{tweet_id}\"\n            return f\"Tweet successful: {tweet_url}\"\n        except Exception as e:\n            return f\"An error occurred: {e}\"\n```"
    },
    {
        "document_name": "swarmauri/experimental/tools/__init__.py",
        "content": "```swarmauri/experimental/tools/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/tools/OutlookSendMailTool.py",
        "content": "```swarmauri/experimental/tools/OutlookSendMailTool.py\nimport requests\nfrom ....standard.tools.base.ToolBase import ToolBase\nfrom ....standard.tools.concrete.Parameter import Parameter\n\n\nclass OutlookSendMailTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"recipient\",\n                type=\"string\",\n                description=\"The email address of the recipient\",\n                required=True\n            ),\n            Parameter(\n                name=\"subject\",\n                type=\"string\",\n                description=\"The subject of the email\",\n                required=True\n            ),\n            Parameter(\n                name=\"body\",\n                type=\"string\",\n                description=\"The HTML body of the email\",\n                required=True\n            )\n        ]\n        \n        super().__init__(name=\"OutlookSendMailTool\", \n                         description=\"Sends an email using the Outlook service.\",\n                         parameters=parameters)\n\n        # Add your Microsoft Graph API credentials and endpoint URL here\n        self.tenant_id = \"YOUR_TENANT_ID\"\n        self.client_id = \"YOUR_CLIENT_ID\"\n        self.client_secret = \"YOUR_CLIENT_SECRET\"\n        self.scope = [\"https://graph.microsoft.com/.default\"]\n        self.token_url = f\"https://login.microsoftonline.com/{self.tenant_id}/oauth2/v2.0/token\"\n        self.graph_endpoint = \"https://graph.microsoft.com/v1.0\"\n\n    def get_access_token(self):\n        data = {\n            \"client_id\": self.client_id,\n            \"scope\": \" \".join(self.scope),\n            \"client_secret\": self.client_secret,\n            \"grant_type\": \"client_credentials\"\n        }\n        response = requests.post(self.token_url, data=data)\n        response.raise_for_status()\n        return response.json().get(\"access_token\")\n\n    def __call__(self, recipient, subject, body):\n        access_token = self.get_access_token()\n\n        headers = {\n            \"Authorization\": f\"Bearer {access_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        email_data = {\n            \"message\": {\n                \"subject\": subject,\n                \"body\": {\n                    \"contentType\": \"HTML\",\n                    \"content\": body\n                },\n                \"toRecipients\": [\n                    {\n                        \"emailAddress\": {\n                            \"address\": recipient\n                        }\n                    }\n                ]\n            }\n        }\n\n        send_mail_endpoint = f\"{self.graph_endpoint}/users/{self.client_id}/sendMail\"\n        response = requests.post(send_mail_endpoint, json=email_data, headers=headers)\n        if response.status_code == 202:\n            return \"Email sent successfully\"\n        else:\n            return f\"Failed to send email, status code {response.status_code}\"\n```"
    },
    {
        "document_name": "swarmauri/experimental/tools/CypherQueryTool.py",
        "content": "```swarmauri/experimental/tools/CypherQueryTool.py\nfrom ..base.ToolBase import ToolBase\nfrom .Parameter import Parameter\nfrom neo4j import GraphDatabase\nimport json\n\nclass CypherQueryTool(ToolBase):\n    def __init__(self, uri: str, user: str, password: str):\n        self.uri = uri\n        self.user = user\n        self.password = password\n        \n        # Define only the 'query' parameter since uri, user, and password are set at initialization\n        parameters = [\n            Parameter(\n                name=\"query\",\n                type=\"string\",\n                description=\"The Cypher query to execute.\",\n                required=True\n            )\n        ]\n        \n        super().__init__(name=\"CypherQueryTool\",\n                         description=\"Executes a Cypher query against a Neo4j database.\",\n                         parameters=parameters)\n\n    def _get_connection(self):\n        return GraphDatabase.driver(self.uri, auth=(self.user, self.password))\n\n    def __call__(self, query) -> str:\n        # Establish connection to the database\n        driver = self._get_connection()\n        session = driver.session()\n\n        # Execute the query\n        result = session.run(query)\n        records = result.data()\n\n        # Close the connection\n        session.close()\n        driver.close()\n\n        # Convert records to JSON string, assuming it's JSON serializable\n        return json.dumps(records)\n```"
    },
    {
        "document_name": "swarmauri/experimental/tools/FileDownloaderTool.py",
        "content": "```swarmauri/experimental/tools/FileDownloaderTool.py\nimport requests\nfrom ....core.tools.ToolBase import ToolBase\nfrom ....core.tools.Parameter import Parameter\n\n\nclass FileDownloaderTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"url\",\n                type=\"string\",\n                description=\"The URL of the file to download\",\n                required=True\n            )\n        ]\n        \n        super().__init__(name=\"FileDownloaderTool\",\n                         description=\"Downloads a file from a specified URL into memory.\",\n                         parameters=parameters)\n    \n    def __call__(self, url: str) -> bytes:\n        \"\"\"\n        Downloads a file from the given URL into memory.\n        \n        Parameters:\n        - url (str): The URL of the file to download.\n        \n        Returns:\n        - bytes: The content of the downloaded file.\n        \"\"\"\n        try:\n            response = requests.get(url)\n            response.raise_for_status()  # Raises an HTTPError if the request resulted in an error\n            return response.content\n        except requests.RequestException as e:\n            raise RuntimeError(f\"Failed to download file from '{url}'. Error: {e}\")\n```"
    },
    {
        "document_name": "swarmauri/experimental/tools/SQLite3QueryTool.py",
        "content": "```swarmauri/experimental/tools/SQLite3QueryTool.py\nimport sqlite3\nfrom ...base.ToolBase import ToolBase\nfrom ...concrete.Parameter import Parameter\n\nclass SQLite3QueryTool(ToolBase):\n    def __init__(self, db_name: str):\n        parameters = [\n            Parameter(\n                name=\"query\",\n                type=\"string\",\n                description=\"SQL query to execute\",\n                required=True\n            )\n        ]\n        super().__init__(name=\"SQLQueryTool\", \n                         description=\"Executes an SQL query and returns the results.\", \n                         parameters=parameters)\n        self.db_name = db_name\n\n    def __call__(self, query) -> str:\n        \"\"\"\n        Execute the provided SQL query.\n\n        Parameters:\n        - query (str): The SQL query to execute.\n\n        Returns:\n        - str: The results of the SQL query as a string.\n        \"\"\"\n        try:\n            connection = sqlite3.connect(self.db_name)  # Connect to the specific database file\n            cursor = connection.cursor()\n            \n            cursor.execute(query)\n            rows = cursor.fetchall()\n            result = \"\\n\".join(str(row) for row in rows)\n        except Exception as e:\n            result = f\"Error executing query: {e}\"\n        finally:\n            connection.close()\n        \n        return f\"Query Result:\\n{result}\"\n```"
    },
    {
        "document_name": "swarmauri/experimental/conversations/__init__.py",
        "content": "```swarmauri/experimental/conversations/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/conversations/SemanticConversation.py",
        "content": "```swarmauri/experimental/conversations/SemanticConversation.py\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Dict, Union\nfrom ...core.messages.IMessage import IMessage\nfrom ...core.conversations.IConversation import IConversation\n\nclass SemanticConversation(IConversation, ABC):\n    \"\"\"\n    A concrete implementation of the Conversation class that includes semantic routing.\n    Semantic routing involves analyzing the content of messages to understand their intent\n    or category and then routing them to appropriate handlers based on that analysis.\n\n    This class requires subclasses to implement the _analyze_message method for semantic analysis.\n    \"\"\"\n\n\n    @abstractmethod\n    def register_handler(self, category: str, handler: Callable[[IMessage], None]):\n        \"\"\"\n        Registers a message handler for a specific semantic category.\n\n        Args:\n            category (str): The category of messages this handler should process.\n            handler (Callable[[Message], None]): The function to call for messages of the specified category.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_message(self, message: IMessage):\n        \"\"\"\n        Adds a message to the conversation history and routes it to the appropriate handler based on its semantic category.\n\n        Args:\n            message (Message): The message to be added and processed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _analyze_message(self, message: IMessage) -> Union[str, None]:\n        \"\"\"\n        Analyzes the content of a message to determine its semantic category.\n\n        This method must be implemented by subclasses to provide specific logic for semantic analysis.\n\n        Args:\n            message (Message): The message to analyze.\n\n        Returns:\n            Union[str, None]: The semantic category of the message, if determined; otherwise, None.\n\n        Raises:\n            NotImplementedError: If the method is not overridden in a subclass.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement the _analyze_message method to provide semantic analysis.\")\n\n    # Additional methods as needed for message retrieval, history management, etc., inherited from Conversation\n```"
    },
    {
        "document_name": "swarmauri/experimental/conversations/ConsensusBuildingConversation.py",
        "content": "```swarmauri/experimental/conversations/ConsensusBuildingConversation.py\nfrom swarmauri.core.conversations.IConversation import IConversation\nfrom swarmauri.core.messages.IMessage import IMessage\n\n\nclass ConsensusBuildingMessage(IMessage):\n    def __init__(self, sender_id: str, content: str, message_type: str):\n        self._sender_id = sender_id\n        self._content = content\n        self._role = 'consensus_message'\n        self._message_type = message_type\n\n    @property\n    def role(self) -> str:\n        return self._role\n\n    @property\n    def content(self) -> str:\n        return self._content\n\n    def as_dict(self) -> dict:\n        return {\n            \"sender_id\": self._sender_id,\n            \"content\": self._content,\n            \"message_type\": self._message_type\n        }\n\n\nclass ConsensusBuildingConversation(IConversation):\n    def __init__(self, topic: str, participants: list):\n        self.topic = topic\n        self.participants = participants  # List of agent IDs\n        self._history = []  # Stores all messages exchanged in the conversation\n        self.proposal_votes = {}  # Tracks votes for each proposal\n\n    @property\n    def history(self) -> list:\n        return self._history\n\n    def add_message(self, message: IMessage):\n        if not isinstance(message, ConsensusBuildingMessage):\n            raise ValueError(\"Only instances of ConsensusBuildingMessage are accepted\")\n        self._history.append(message)\n\n    def get_last(self) -> IMessage:\n        if self._history:\n            return self._history[-1]\n        return None\n\n    def clear_history(self) -> None:\n        self._history.clear()\n\n    def as_dict(self) -> list:\n        return [message.as_dict() for message in self._history]\n\n    def initiate_consensus(self, initiator_id: str, proposal=None):\n        \"\"\"Starts the conversation with an initial proposal, if any.\"\"\"\n        initiate_message = ConsensusBuildingMessage(initiator_id, proposal, \"InitiateConsensusMessage\")\n        self.add_message(initiate_message)\n\n    def add_proposal(self, sender_id: str, proposal: str):\n        \"\"\"Adds a proposal to the conversation.\"\"\"\n        proposal_message = ConsensusBuildingMessage(sender_id, proposal, \"ProposalMessage\")\n        self.add_message(proposal_message)\n\n    def add_comment(self, sender_id: str, comment: str):\n        \"\"\"Adds a comment or feedback regarding a proposal.\"\"\"\n        comment_message = ConsensusBuildingMessage(sender_id, comment, \"CommentMessage\")\n        self.add_message(comment_message)\n\n    def vote(self, sender_id: str, vote: str):\n        \"\"\"Registers a vote for a given proposal.\"\"\"\n        vote_message = ConsensusBuildingMessage(sender_id, vote, \"VoteMessage\")\n        self.add_message(vote_message)\n        # Count the vote\n        self.proposal_votes[vote] = self.proposal_votes.get(vote, 0) + 1\n\n    def check_agreement(self):\n        \"\"\"\n        Checks if there is a consensus on any proposal.\n        A simple majority (>50% of the participants) is required for consensus.\n        \"\"\"\n        consensus_threshold = len(self.participants) / 2  # Define consensus as a simple majority\n\n        for proposal, votes in self.proposal_votes.items():\n            if votes > consensus_threshold:\n                # A consensus has been reached\n                return True, f\"Consensus reached on proposal: {proposal} with {votes} votes.\"\n\n        # If no consensus is reached\n        return False, \"No consensus reached.\"\n```"
    },
    {
        "document_name": "swarmauri/experimental/models/__init__.py",
        "content": "```swarmauri/experimental/models/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/models/SageMaker.py",
        "content": "```swarmauri/experimental/models/SageMaker.py\nimport json\nimport boto3\nfrom ...core.models.IModel import IModel\n\n\nclass AWSSageMakerModel(IModel):\n    def __init__(self, access_key: str, secret_access_key: str, region_name: str, model_name: str):\n        \"\"\"\n        Initialize the AWS SageMaker model with AWS credentials, region, and the model name.\n\n        Parameters:\n        - access_key (str): AWS access key ID.\n        - secret_access_key (str): AWS secret access key.\n        - region_name (str): The region where the SageMaker model is deployed.\n        - model_name (str): The name of the SageMaker model.\n        \"\"\"\n        self.access_key = access_key\n        self.secret_access_key = secret_access_key\n        self.region_name = region_name\n        self.client = boto3.client('sagemaker-runtime',\n                                   aws_access_key_id=access_key,\n                                   aws_secret_access_key=secret_access_key,\n                                   region_name=region_name)\n        super().__init__(model_name)\n\n    def predict(self, payload: str, content_type: str='application/json') -> dict:\n        \"\"\"\n        Generate predictions using the AWS SageMaker model.\n\n        Parameters:\n        - payload (str): Input data in JSON format.\n        - content_type (str): The MIME type of the input data (default: 'application/json').\n        \n        Returns:\n        - dict: The predictions returned by the model.\n        \"\"\"\n        endpoint_name = self.model_name  # Assuming the model name is also the endpoint name\n        response = self.client.invoke_endpoint(EndpointName=endpoint_name,\n                                               Body=payload,\n                                               ContentType=content_type)\n        result = json.loads(response['Body'].read().decode())\n        return result\n```"
    },
    {
        "document_name": "swarmauri/experimental/models/HierarchicalAttentionModel.py",
        "content": "```swarmauri/experimental/models/HierarchicalAttentionModel.py\nimport tensorflow as tf\nfrom swarmauri.core.models.IModel import IModel\nfrom typing import Any\n\nclass HierarchicalAttentionModel(IModel):\n    def __init__(self, model_name: str):\n        self._model_name = model_name\n        self._model = None  # This will hold the TensorFlow model with attention\n\n    @property\n    def model_name(self) -> str:\n        return self._model_name\n\n    @model_name.setter\n    def model_name(self, value: str) -> None:\n        self._model_name = value\n\n    def load_model(self) -> None:\n        \"\"\"\n        Here, we define and compile the TensorFlow model described earlier.\n        \"\"\"\n        # The following code is adapted from the attention model example provided earlier\n        vocab_size = 10000  # Size of the vocabulary\n        embedding_dim = 256  # Dimension of the embedding layer\n        sentence_length = 100  # Max length of a sentence\n        num_sentences = 10  # Number of sentences in a document\n        units = 128  # Dimensionality of the output space of GRU\n        \n        # Word-level attention layer\n        word_input = tf.keras.layers.Input(shape=(sentence_length,), dtype='int32')\n        embedded_word = tf.keras.layers.Embedding(vocab_size, embedding_dim)(word_input)\n        word_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units, return_sequences=True))(embedded_word)\n        word_attention_layer = tf.keras.layers.Attention(use_scale=True, return_attention_scores=True)\n        word_attention_output, word_attention_weights = word_attention_layer([word_gru, word_gru], return_attention_scores=True)\n        word_encoder_with_attention = tf.keras.Model(inputs=word_input, outputs=[word_attention_output, word_attention_weights])\n        \n        # Sentence-level attention layer\n        sentence_input = tf.keras.layers.Input(shape=(num_sentences, sentence_length), dtype='int32')\n        sentence_encoder_with_attention = tf.keras.layers.TimeDistributed(word_encoder_with_attention)(sentence_input)\n        sentence_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units, return_sequences=True))(sentence_encoder_with_attention[0])\n        sentence_attention_layer = tf.keras.layers.Attention(use_scale=True, return_attention_scores=True)\n        sentence_attention_output, sentence_attention_weights = sentence_attention_layer([sentence_gru, sentence_gru], return_attention_scores=True)\n        doc_representation = tf.keras.layers.Dense(units, activation='tanh')(sentence_attention_output)\n        \n        # Classifier\n        classifier = tf.keras.layers.Dense(1, activation='sigmoid')(doc_representation)\n        \n        # The model\n        self._model = tf.keras.Model(inputs=sentence_input, outputs=[classifier, sentence_attention_weights])\n        self._model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    def predict(self, input_data: Any) -> Any:\n        \"\"\"\n        Predict method to use the loaded model for making predictions.\n\n        This example assumes `input_data` is preprocessed appropriately for the model's expected input.\n        \"\"\"\n        if self._model is None:\n            raise ValueError(\"Model is not loaded. Call `load_model` before prediction.\")\n            \n        # Predicting with the model\n        predictions, attention_weights = self._model.predict(input_data)\n        \n        # Additional logic to handle and package the predictions and attention weights could be added here\n        \n        return predictions, attention_weights\n```"
    },
    {
        "document_name": "swarmauri/experimental/utils/__init__.py",
        "content": "```swarmauri/experimental/utils/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/utils/get_last_frame.py",
        "content": "```swarmauri/experimental/utils/get_last_frame.py\nimport inspect\n\ndef child_function(arg):\n    # Get the stack frame of the caller\n    caller_frame = inspect.currentframe().f_back\n    # Get the name of the caller function\n    caller_name = caller_frame.f_code.co_name\n    # Inspect the arguments of the caller function\n    args, _, _, values = inspect.getargvalues(caller_frame)\n    # Assuming the caller has only one argument for simplicity\n    arg_name = args[0]\n    arg_value = values[arg_name]\n    print(f\"Caller Name: {caller_name}, Argument Name: {arg_name}, Argument Value: {arg_value}\")\n\ndef caller_function(l):\n    child_function(l)\n\n# Example usage\ncaller_function(\"Hello\")\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/utils/save_schema.py",
        "content": "```swarmauri/experimental/utils/save_schema.py\nimport inspect\nimport random\n\nclass Storage:\n    def __init__(self):\n        self.logs = []\n\n    def log(self, log_data):\n        self.logs.append(log_data)\n\n    def print_logs(self):\n        for log in self.logs:\n            print(log)\n\nclass Loggable:\n    def __init__(self, name, storage):\n        self.name = name\n        self.storage = storage\n\n    def log_call(self, *args, **kwargs):\n        # Inspect the call stack to get the caller's details\n        caller_frame = inspect.stack()[2]\n        caller_name = inspect.currentframe().f_back.f_code.co_name\n        #caller_name = caller_frame.function\n        module = inspect.getmodule(caller_frame[0])\n        module_name = module.__name__ if module else 'N/A'\n\n        # Log all relevant details\n        log_data = {\n            'caller_name': caller_name,\n            'module_name': module_name,\n            'called_name': self.name,\n            'called_function': caller_frame[3], # The function in which log_call was invoked\n            'args': args,\n            'kwargs': kwargs\n        }\n        self.storage.log(log_data)\n\nclass Caller(Loggable):\n    def __init__(self, name, storage, others):\n        super().__init__(name, storage)\n        self.others = others\n\n    def __call__(self, *args, **kwargs):\n        if len(self.storage.logs)<10:\n            self.log_call(*args, **kwargs)\n            # Randomly call another without causing recursive calls\n            if args:  # Ensures it's not the first call without actual target\n                next_caller_name = random.choice([name for name in self.others if name != self.name])\n                self.others[next_caller_name](self.name)\n\n# Initialize storage and callers\nstorage = Storage()\nothers = {}\n\n# Creating callers\nalice = Caller('Alice', storage, others)\nbob = Caller('Bob', storage, others)\ncharlie = Caller('Charlie', storage, others)\ndan = Caller('Dan', storage, others)\n\nothers['Alice'] = alice\nothers['Bob'] = bob\nothers['Charlie'] = charlie\nothers['Dan'] = dan\n\n# Simulate the calls\ndan(1, taco=23)\n\n# Print the logs\nstorage.print_logs()\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/utils/ISerializable.py",
        "content": "```swarmauri/experimental/utils/ISerializable.py\n\n# class Serializable:\n#     def serialize(self):\n#         raise NotImplementedError(\"Serialization method not implemented\")\n    \n#     @classmethod\n#     def deserialize(cls, data):\n#         raise NotImplementedError(\"Deserialization method not implemented\")\n        \n        \n# class ToolAgent(Serializable):\n#     def serialize(self):\n#         # Simplified example, adapt according to actual attributes\n#         return {\"type\": self.__class__.__name__, \"state\": {\"model_name\": self.model.model_name}}\n\n#     @classmethod\n#     def deserialize(cls, data):\n#         # This method should instantiate the object based on the serialized state.\n#         # Example assumes the presence of model_name in the serialized state.\n#         model = OpenAIToolModel(api_key=\"api_key_placeholder\", model_name=data[\"state\"][\"model_name\"])\n#         return cls(model=model, conversation=None, toolkit=None)  # Simplify, omit optional parameters for illustration\n```"
    },
    {
        "document_name": "swarmauri/experimental/utils/log_prompt_response.py",
        "content": "```swarmauri/experimental/utils/log_prompt_response.py\nimport sqlite3\nfrom functools import wraps\n\ndef log_prompt_response(db_path):\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            # Extracting the 'message' parameter from args which is assumed to be the first argument\n            message = args[0]  \n            response = await func(*args, **kwargs)\n            conn = sqlite3.connect(db_path)\n            cursor = conn.cursor()\n            \n            # Create table if it doesn't exist\n            cursor.execute('''CREATE TABLE IF NOT EXISTS prompts_responses\n                            (id INTEGER PRIMARY KEY AUTOINCREMENT, \n                             prompt TEXT, \n                             response TEXT)''')\n            \n            # Insert a new record\n            cursor.execute('''INSERT INTO prompts_responses (prompt, response) \n                            VALUES (?, ?)''', (message, response))\n            conn.commit()\n            conn.close()\n            return response\n        \n        return wrapper\n    return decorator\n```"
    },
    {
        "document_name": "swarmauri/experimental/parsers/__init__.py",
        "content": "```swarmauri/experimental/parsers/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/parsers/PDFToTextParser.py",
        "content": "```swarmauri/experimental/parsers/PDFToTextParser.py\nimport fitz  # PyMuPDF\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.ConcreteDocument import ConcreteDocument\n\nclass PDFtoTextParser(IParser):\n    \"\"\"\n    A parser to extract text from PDF files.\n    \"\"\"\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses a PDF file and extracts its text content as Document instances.\n\n        Parameters:\n        - data (Union[str, Any]): The path to the PDF file.\n\n        Returns:\n        - List[IDocument]: A list with a single IDocument instance containing the extracted text.\n        \"\"\"\n        # Ensure data is a valid str path to a PDF file\n        if not isinstance(data, str):\n            raise ValueError(\"PDFtoTextParser expects a file path in str format.\")\n\n        try:\n            # Open the PDF file\n            doc = fitz.open(data)\n            text = \"\"\n\n            # Extract text from each page\n            for page_num in range(len(doc)):\n                page = doc.load_page(page_num)\n                text += page.get_text()\n\n            # Create a document with the extracted text\n            document = ConcreteDocument(doc_id=str(hash(data)), content=text, metadata={\"source\": data})\n            return [document]\n        \n        except Exception as e:\n            print(f\"An error occurred while parsing the PDF: {e}\")\n            return []\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/vector_stores/__init__.py",
        "content": "```swarmauri/experimental/vector_stores/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/vector_stores/Word2VecDocumentStore.py",
        "content": "```swarmauri/experimental/vector_stores/Word2VecDocumentStore.py\nfrom typing import List, Union, Optional\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom swarmauri.core.document_stores.IDocumentStore import IDocumentStore\nfrom swarmauri.core.retrievers.IRetriever import IRetriever\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vector_stores.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nimport gensim.downloader as api\n\nclass Word2VecDocumentStore(IDocumentStore, IRetriever):\n    def __init__(self):\n        \"\"\"\n        Initializes the Word2VecDocumentStore.\n\n        Parameters:\n        - word2vec_model_path (Optional[str]): File path to a pre-trained Word2Vec model. \n                                               Leave None to use Gensim's pre-trained model.\n        - pre_trained (bool): If True, loads a pre-trained Word2Vec model. If False, an uninitialized model is used that requires further training.\n        \"\"\"\n        self.model = Word2Vec(vector_size=100, window=5, min_count=1, workers=4)  # Example parameters; adjust as needed\n        self.documents = []\n        self.metric = CosineDistance()\n\n    def add_document(self, document: EmbeddedDocument) -> None:\n        # Check if the document already has an embedding, if not generate one using _average_word_vectors\n        if not hasattr(document, 'embedding') or document.embedding is None:\n            words = document.content.split()  # Simple tokenization, consider using a better tokenizer\n            embedding = self._average_word_vectors(words)\n            document.embedding = embedding\n            print(document.embedding)\n        self.documents.append(document)\n        \n    def add_documents(self, documents: List[EmbeddedDocument]) -> None:\n        self.documents.extend(documents)\n        \n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n        \n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n        \n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [doc for doc in self.documents if doc.id != doc_id]\n\n    def update_document(self, doc_id: str, updated_document: EmbeddedDocument) -> None:\n        for i, document in enumerate(self.documents):\n            if document.id == doc_id:\n                self.documents[i] = updated_document\n                break\n\n    def _average_word_vectors(self, words: List[str]) -> np.ndarray:\n        \"\"\"\n        Generate document vector by averaging its word vectors.\n        \"\"\"\n        word_vectors = [self.model.wv[word] for word in words if word in self.model.wv]\n        print(word_vectors)\n        if word_vectors:\n            return np.mean(word_vectors, axis=0)\n        else:\n            return np.zeros(self.model.vector_size)\n\n    def retrieve(self, query: str, top_k: int = 5) -> List[EmbeddedDocument]:\n        \"\"\"\n        Retrieve documents similar to the query string based on Word2Vec embeddings.\n        \"\"\"\n        query_vector = self._average_word_vectors(query.split())\n        print('query_vector', query_vector)\n        # Compute similarity scores between the query and each document's stored embedding\n        similarities = self.metric.similarities(SimpleVector(query_vector), [SimpleVector(doc.embedding) for doc in self.documents if doc.embedding])\n        print('similarities', similarities)\n        # Retrieve indices of top_k most similar documents\n        top_k_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:top_k]\n        print('top_k_indices', top_k_indices)\n        return [self.documents[i] for i in top_k_indices]\n```"
    },
    {
        "document_name": "swarmauri/experimental/vector_stores/TriplesDocumentStore.py",
        "content": "```swarmauri/experimental/vector_stores/TriplesDocumentStore.py\nfrom typing import List, Union, Optional\nimport numpy as np\nfrom rdflib import Graph, URIRef, Literal, BNode\nfrom ampligraph.latent_features import ComplEx\nfrom ampligraph.evaluation import train_test_split_no_unseen\nfrom ampligraph.latent_features import EmbeddingModel\nfrom ampligraph.utils import save_model, restore_model\n\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.document_stores.IDocumentStore import IDocumentStore\nfrom swarmauri.core.retrievers.IRetriever import IRetriever\nfrom swarmauri.standard.documents.concrete.Document import Document\nfrom swarmauri.standard.vector_stores.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.standard.vectorizers.concrete.AmpligraphVectorizer import AmpligraphVectorizer\n\n\nclass TriplesDocumentStore(IDocumentStore, IRetriever):\n    def __init__(self, rdf_file_path: str, model_path: Optional[str] = None):\n        \"\"\"\n        Initializes the TriplesDocumentStore.\n        \"\"\"\n        self.graph = Graph()\n        self.rdf_file_path = rdf_file_path\n        self.graph.parse(rdf_file_path, format='turtle')\n        self.documents = []\n        self.vectorizer = AmpligraphVectorizer()\n        self.model_path = model_path\n        if model_path:\n            self.model = restore_model(model_path)\n        else:\n            self.model = None\n        self.metric = CosineDistance()\n        self._load_documents()\n        if not self.model:\n            self._train_model()\n\n    def _train_model(self):\n        \"\"\"\n        Trains a model based on triples in the graph.\n        \"\"\"\n        # Extract triples for embedding model\n        triples = np.array([[str(s), str(p), str(o)] for s, p, o in self.graph])\n        # Split data\n        train, test = train_test_split_no_unseen(triples, test_size=0.1)\n        self.model = ComplEx(batches_count=100, seed=0, epochs=20, k=150, eta=1,\n                             optimizer='adam', optimizer_params={'lr': 1e-3},\n                             loss='pairwise', regularizer='LP', regularizer_params={'p': 3, 'lambda': 1e-5},\n                             verbose=True)\n        self.model.fit(train)\n        if self.model_path:\n            save_model(self.model, self.model_path)\n\n    def _load_documents(self):\n        \"\"\"\n        Load documents into the store from the RDF graph.\n        \"\"\"\n        for subj, pred, obj in self.graph:\n            doc_id = str(hash((subj, pred, obj)))\n            content = f\"{subj} {pred} {obj}\"\n            document = Document(content=content, doc_id=doc_id, metadata={})\n            self.documents.append(document)\n\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Adds a single RDF triple document.\n        \"\"\"\n        subj, pred, obj = document.content.split()  # Splitting content into RDF components\n        self.graph.add((URIRef(subj), URIRef(pred), URIRef(obj) if obj.startswith('http') else Literal(obj)))\n        self.documents.append(document)\n        self._train_model()\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Adds multiple RDF triple documents.\n        \"\"\"\n        for document in documents:\n            subj, pred, obj = document.content.split()  # Assuming each document's content is \"subj pred obj\"\n            self.graph.add((URIRef(subj), URIRef(pred), URIRef(obj) if obj.startswith('http') else Literal(obj)))\n        self.documents.extend(documents)\n        self._train_model()\n\n    # Implementation for get_document, get_all_documents, delete_document, update_document remains same as before\n    \n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve documents similar to the query string.\n        \"\"\"\n        if not self.model:\n            self._train_model()\n        query_vector = self.vectorizer.infer_vector(model=self.model, samples=[query])[0]\n        document_vectors = [self.vectorizer.infer_vector(model=self.model, samples=[doc.content])[0] for doc in self.documents]\n        similarities = self.metric.distances(SimpleVector(data=query_vector), [SimpleVector(vector) for vector in document_vectors])\n        top_k_indices = sorted(range(len(similarities)), key=lambda i: similarities[i])[:top_k]\n        return [self.documents[i] for i in top_k_indices]\n```"
    },
    {
        "document_name": "swarmauri/experimental/tracing/RemoteTrace.py",
        "content": "```swarmauri/experimental/tracing/RemoteTrace.py\nfrom __future__ import ITraceContext\n\nimport requests\nimport json\nimport uuid\nfrom datetime import datetime\n\nfrom swarmauri.core.tracing.ITracer import ITracer\nfrom swarmauri.core.tracing.ITraceContext import ITraceContext\n\n# Implementing the RemoteTraceContext class\nclass RemoteTraceContext(ITraceContext):\n    def __init__(self, trace_id: str, name: str):\n        self.trace_id = trace_id\n        self.name = name\n        self.start_time = datetime.now()\n        self.attributes = {}\n        self.annotations = {}\n\n    def get_trace_id(self) -> str:\n        return self.trace_id\n\n    def add_attribute(self, key: str, value):\n        self.attributes[key] = value\n        \n    def add_annotation(self, key: str, value):\n        self.annotations[key] = value\n\n# Implementing the RemoteAPITracer class\nclass RemoteAPITracer(ITracer):\n    def __init__(self, api_endpoint: str):\n        self.api_endpoint = api_endpoint\n\n    def start_trace(self, name: str, initial_attributes=None) -> 'RemoteTraceContext':\n        trace_id = str(uuid.uuid4())\n        context = RemoteTraceContext(trace_id, name)\n        if initial_attributes:\n            for key, value in initial_attributes.items():\n                context.add_attribute(key, value)\n        return context\n\n    def end_trace(self, trace_context: 'RemoteTraceContext'):\n        trace_context.end_time = datetime.now()\n        # Pretending to serialize the context information to JSON\n        trace_data = {\n            \"trace_id\": trace_context.get_trace_id(),\n            \"name\": trace_context.name,\n            \"start_time\": str(trace_context.start_time),\n            \"end_time\": str(trace_context.end_time),\n            \"attributes\": trace_context.attributes,\n            \"annotations\": trace_context.annotations\n        }\n        json_data = json.dumps(trace_data)\n        # POST the serialized data to the remote REST API\n        response = requests.post(self.api_endpoint, json=json_data)\n        if not response.ok:\n            raise Exception(f\"Failed to send trace data to {self.api_endpoint}. Status code: {response.status_code}\")\n\n    def annotate_trace(self, trace_context: 'RemoteTraceContext', key: str, value):\n        trace_context.add_annotation(key, value)\n```"
    },
    {
        "document_name": "swarmauri/experimental/tracing/__init__.py",
        "content": "```swarmauri/experimental/tracing/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/chains/TypeAgnosticCallableChain.py",
        "content": "```swarmauri/experimental/chains/TypeAgnosticCallableChain.py\nfrom typing import Any, Callable, List, Dict, Optional, Tuple, Union\n\nCallableDefinition = Tuple[Callable, List[Any], Dict[str, Any], Union[str, Callable, None]]\n\nclass TypeAgnosticCallableChain:\n    def __init__(self, callables: Optional[List[CallableDefinition]] = None):\n        self.callables = callables if callables is not None else []\n\n    @staticmethod\n    def _ignore_previous(_previous_result, *args, **kwargs):\n        return args, kwargs\n\n    @staticmethod\n    def _use_first_arg(previous_result, *args, **kwargs):\n        return [previous_result] + list(args), kwargs\n\n    @staticmethod\n    def _use_all_previous_args_first(previous_result, *args, **kwargs):\n        if not isinstance(previous_result, (list, tuple)):\n            previous_result = [previous_result]\n        return list(previous_result) + list(args), kwargs\n\n    @staticmethod\n    def _use_all_previous_args_only(previous_result, *_args, **_kwargs):\n        if not isinstance(previous_result, (list, tuple)):\n            previous_result = [previous_result]\n        return list(previous_result), {}\n\n    @staticmethod\n    def _add_previous_kwargs_overwrite(previous_result, args, kwargs):\n        if not isinstance(previous_result, dict):\n            raise ValueError(\"Previous result is not a dictionary.\")\n        return args, {**kwargs, **previous_result}\n\n    @staticmethod\n    def _add_previous_kwargs_no_overwrite(previous_result, args, kwargs):\n        if not isinstance(previous_result, dict):\n            raise ValueError(\"Previous result is not a dictionary.\")\n        return args, {**previous_result, **kwargs}\n\n    @staticmethod\n    def _use_all_args_all_kwargs_overwrite(previous_result_args, previous_result_kwargs, *args, **kwargs):\n        combined_args = list(previous_result_args) + list(args) if isinstance(previous_result_args, (list, tuple)) else list(args)\n        combined_kwargs = previous_result_kwargs if isinstance(previous_result_kwargs, dict) else {}\n        combined_kwargs.update(kwargs)\n        return combined_args, combined_kwargs\n\n    @staticmethod\n    def _use_all_args_all_kwargs_no_overwrite(previous_result_args, previous_result_kwargs, *args, **kwargs):\n        combined_args = list(previous_result_args) + list(args) if isinstance(previous_result_args, (list, tuple)) else list(args)\n        combined_kwargs = kwargs if isinstance(kwargs, dict) else {}\n        combined_kwargs = {**combined_kwargs, **(previous_result_kwargs if isinstance(previous_result_kwargs, dict) else {})}\n        return combined_args, combined_kwargs\n\n    def add_callable(self, func: Callable, args: List[Any] = None, kwargs: Dict[str, Any] = None, input_handler: Union[str, Callable, None] = None) -> None:\n        if isinstance(input_handler, str):\n            # Map the string to the corresponding static method\n            input_handler_method = getattr(self, f\"_{input_handler}\", None)\n            if input_handler_method is None:\n                raise ValueError(f\"Unknown input handler name: {input_handler}\")\n            input_handler = input_handler_method\n        elif input_handler is None:\n            input_handler = self._ignore_previous\n        self.callables.append((func, args or [], kwargs or {}, input_handler))\n\n    def __call__(self, *initial_args, **initial_kwargs) -> Any:\n        result = None\n        for func, args, kwargs, input_handler in self.callables:\n            if isinstance(input_handler, str):\n                # Map the string to the corresponding static method\n                input_handler_method = getattr(self, f\"_{input_handler}\", None)\n                if input_handler_method is None:\n                    raise ValueError(f\"Unknown input handler name: {input_handler}\")\n                input_handler = input_handler_method\n            elif input_handler is None:\n                input_handler = self._ignore_previous\n                \n            args, kwargs = input_handler(result, *args, **kwargs) if result is not None else (args, kwargs)\n            result = func(*args, **kwargs)\n        return result\n\n    def __or__(self, other: \"TypeAgnosticCallableChain\") -> \"TypeAgnosticCallableChain\":\n        if not isinstance(other, TypeAgnosticCallableChain):\n            raise TypeError(\"Operand must be an instance of TypeAgnosticCallableChain\")\n        \n        new_chain = TypeAgnosticCallableChain(self.callables + other.callables)\n        return new_chain\n```"
    },
    {
        "document_name": "swarmauri/experimental/chains/__init__.py",
        "content": "```swarmauri/experimental/chains/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/experimental/chains/IChainScheduler.py",
        "content": "```swarmauri/experimental/chains/IChainScheduler.py\nfrom abc import ABC, abstractmethod\nfrom core.chains.IChain import IChain\n\nclass IChainScheduler(ABC):\n    @abstractmethod\n    def schedule_chain(self, chain: IChain, schedule: str) -> None:\n        \"\"\"Schedule the execution of the given chain.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/experimental/chains/IChainFormatter.py",
        "content": "```swarmauri/experimental/chains/IChainFormatter.py\nfrom abc import ABC, abstractmethod\nfrom core.chains.IChainStep import IChainStep\n\nclass IChainFormatter(ABC):\n    @abstractmethod\n    def format_output(self, step: IChainStep, output: Any) -> str:\n        \"\"\"Format the output of a specific chain step.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/experimental/chains/IChainNotification.py",
        "content": "```swarmauri/experimental/chains/IChainNotification.py\nfrom abc import ABC, abstractmethod\n\nclass IChainNotifier(ABC):\n    @abstractmethod\n    def send_notification(self, message: str) -> None:\n        \"\"\"Send a notification message based on chain execution results.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/experimental/chains/IChainPersistence.py",
        "content": "```swarmauri/experimental/chains/IChainPersistence.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.chains.IChain import IChain\n\nclass IChainPersistence(ABC):\n    @abstractmethod\n    def save_state(self, chain: IChain, state: Dict[str, Any]) -> None:\n        \"\"\"Save the state of the given chain.\"\"\"\n        pass\n\n    @abstractmethod\n    def load_state(self, chain_id: str) -> Dict[str, Any]:\n        \"\"\"Load the state of a chain by its identifier.\"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/experimental/vectorizers/DGLVectorizer.py",
        "content": "```swarmauri/experimental/vectorizers/DGLVectorizer.py\nimport dgl\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom dgl.nn import GraphConv\nfrom typing import List, Union, Any\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\n\nclass DGLGraphConv(torch.nn.Module):\n    def __init__(self, in_feats, out_feats, activation=F.relu):\n        super(DGLGraphConv, self).__init__()\n        self.conv1 = GraphConv(in_feats, 128)\n        self.conv2 = GraphConv(128, out_feats)\n        self.activation = activation\n\n    def forward(self, g, inputs):\n        # Apply graph convolution and activation.\n        h = self.conv1(g, inputs)\n        h = self.activation(h)\n        h = self.conv2(g, h)\n        return h\n\nclass DGLVectorizer(IVectorize):\n    def __init__(self, in_feats, out_feats, model=None):\n        self.in_feats = in_feats\n        self.out_feats = out_feats\n        self.model = model or DGLGraphConv(in_feats, out_feats)\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n    def fit(self, graphs, features, epochs=10, learning_rate=0.01):\n        self.model.to(self.device)\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n        for epoch in range(epochs):\n            for g, feat in zip(graphs, features):\n                g = g.to(self.device)\n                feat = feat.to(self.device)\n                outputs = self.model(g, feat)\n                loss = F.mse_loss(outputs, feat)  # Example loss; adjust as needed\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n    \n    def infer_vector(self, graph, features):\n        graph = graph.to(self.device)\n        features = features.to(self.device)\n        with torch.no_grad():\n            embeddings = self.model(graph, features)\n        return SimpleVector(embeddings.cpu().numpy())\n```"
    },
    {
        "document_name": "swarmauri/experimental/vectorizers/__init__.py",
        "content": "```swarmauri/experimental/vectorizers/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/document_stores/TriplesDocumentStore.py",
        "content": "```swarmauri/experimental/document_stores/TriplesDocumentStore.py\nfrom typing import List, Union, Optional\nimport numpy as np\nfrom rdflib import Graph, URIRef, Literal, BNode\nfrom ampligraph.latent_features import ComplEx\nfrom ampligraph.evaluation import train_test_split_no_unseen\nfrom ampligraph.latent_features import EmbeddingModel\nfrom ampligraph.utils import save_model, restore_model\n\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.document_stores.IDocumentStore import IDocumentStore\nfrom swarmauri.core.retrievers.IRetriever import IRetriever\nfrom swarmauri.standard.documents.concrete.Document import Document\nfrom swarmauri.standard.vector_stores.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.standard.vectorizers.concrete.AmpligraphVectorizer import AmpligraphVectorizer\n\n\nclass TriplesDocumentStore(IDocumentStore, IRetriever):\n    def __init__(self, rdf_file_path: str, model_path: Optional[str] = None):\n        \"\"\"\n        Initializes the TriplesDocumentStore.\n        \"\"\"\n        self.graph = Graph()\n        self.rdf_file_path = rdf_file_path\n        self.graph.parse(rdf_file_path, format='turtle')\n        self.documents = []\n        self.vectorizer = AmpligraphVectorizer()\n        self.model_path = model_path\n        if model_path:\n            self.model = restore_model(model_path)\n        else:\n            self.model = None\n        self.metric = CosineDistance()\n        self._load_documents()\n        if not self.model:\n            self._train_model()\n\n    def _train_model(self):\n        \"\"\"\n        Trains a model based on triples in the graph.\n        \"\"\"\n        # Extract triples for embedding model\n        triples = np.array([[str(s), str(p), str(o)] for s, p, o in self.graph])\n        # Split data\n        train, test = train_test_split_no_unseen(triples, test_size=0.1)\n        self.model = ComplEx(batches_count=100, seed=0, epochs=20, k=150, eta=1,\n                             optimizer='adam', optimizer_params={'lr': 1e-3},\n                             loss='pairwise', regularizer='LP', regularizer_params={'p': 3, 'lambda': 1e-5},\n                             verbose=True)\n        self.model.fit(train)\n        if self.model_path:\n            save_model(self.model, self.model_path)\n\n    def _load_documents(self):\n        \"\"\"\n        Load documents into the store from the RDF graph.\n        \"\"\"\n        for subj, pred, obj in self.graph:\n            doc_id = str(hash((subj, pred, obj)))\n            content = f\"{subj} {pred} {obj}\"\n            document = Document(content=content, doc_id=doc_id, metadata={})\n            self.documents.append(document)\n\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Adds a single RDF triple document.\n        \"\"\"\n        subj, pred, obj = document.content.split()  # Splitting content into RDF components\n        self.graph.add((URIRef(subj), URIRef(pred), URIRef(obj) if obj.startswith('http') else Literal(obj)))\n        self.documents.append(document)\n        self._train_model()\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Adds multiple RDF triple documents.\n        \"\"\"\n        for document in documents:\n            subj, pred, obj = document.content.split()  # Assuming each document's content is \"subj pred obj\"\n            self.graph.add((URIRef(subj), URIRef(pred), URIRef(obj) if obj.startswith('http') else Literal(obj)))\n        self.documents.extend(documents)\n        self._train_model()\n\n    # Implementation for get_document, get_all_documents, delete_document, update_document remains same as before\n    \n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve documents similar to the query string.\n        \"\"\"\n        if not self.model:\n            self._train_model()\n        query_vector = self.vectorizer.infer_vector(model=self.model, samples=[query])[0]\n        document_vectors = [self.vectorizer.infer_vector(model=self.model, samples=[doc.content])[0] for doc in self.documents]\n        similarities = self.metric.distances(SimpleVector(data=query_vector), [SimpleVector(vector) for vector in document_vectors])\n        top_k_indices = sorted(range(len(similarities)), key=lambda i: similarities[i])[:top_k]\n        return [self.documents[i] for i in top_k_indices]\n```"
    },
    {
        "document_name": "swarmauri/experimental/document_stores/Word2VecDocumentStore.py",
        "content": "```swarmauri/experimental/document_stores/Word2VecDocumentStore.py\nfrom typing import List, Union, Optional\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom swarmauri.core.document_stores.IDocumentStore import IDocumentStore\nfrom swarmauri.core.retrievers.IRetriever import IRetriever\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vector_stores.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nimport gensim.downloader as api\n\nclass Word2VecDocumentStore(IDocumentStore, IRetriever):\n    def __init__(self):\n        \"\"\"\n        Initializes the Word2VecDocumentStore.\n\n        Parameters:\n        - word2vec_model_path (Optional[str]): File path to a pre-trained Word2Vec model. \n                                               Leave None to use Gensim's pre-trained model.\n        - pre_trained (bool): If True, loads a pre-trained Word2Vec model. If False, an uninitialized model is used that requires further training.\n        \"\"\"\n        self.model = Word2Vec(vector_size=100, window=5, min_count=1, workers=4)  # Example parameters; adjust as needed\n        self.documents = []\n        self.metric = CosineDistance()\n\n    def add_document(self, document: EmbeddedDocument) -> None:\n        # Check if the document already has an embedding, if not generate one using _average_word_vectors\n        if not hasattr(document, 'embedding') or document.embedding is None:\n            words = document.content.split()  # Simple tokenization, consider using a better tokenizer\n            embedding = self._average_word_vectors(words)\n            document.embedding = embedding\n            print(document.embedding)\n        self.documents.append(document)\n        \n    def add_documents(self, documents: List[EmbeddedDocument]) -> None:\n        self.documents.extend(documents)\n        \n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n        \n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n        \n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [doc for doc in self.documents if doc.id != doc_id]\n\n    def update_document(self, doc_id: str, updated_document: EmbeddedDocument) -> None:\n        for i, document in enumerate(self.documents):\n            if document.id == doc_id:\n                self.documents[i] = updated_document\n                break\n\n    def _average_word_vectors(self, words: List[str]) -> np.ndarray:\n        \"\"\"\n        Generate document vector by averaging its word vectors.\n        \"\"\"\n        word_vectors = [self.model.wv[word] for word in words if word in self.model.wv]\n        print(word_vectors)\n        if word_vectors:\n            return np.mean(word_vectors, axis=0)\n        else:\n            return np.zeros(self.model.vector_size)\n\n    def retrieve(self, query: str, top_k: int = 5) -> List[EmbeddedDocument]:\n        \"\"\"\n        Retrieve documents similar to the query string based on Word2Vec embeddings.\n        \"\"\"\n        query_vector = self._average_word_vectors(query.split())\n        print('query_vector', query_vector)\n        # Compute similarity scores between the query and each document's stored embedding\n        similarities = self.metric.similarities(SimpleVector(query_vector), [SimpleVector(doc.embedding) for doc in self.documents if doc.embedding])\n        print('similarities', similarities)\n        # Retrieve indices of top_k most similar documents\n        top_k_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:top_k]\n        print('top_k_indices', top_k_indices)\n        return [self.documents[i] for i in top_k_indices]\n```"
    },
    {
        "document_name": "swarmauri/experimental/document_stores/__init__.py",
        "content": "```swarmauri/experimental/document_stores/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/CanberraDistance.py",
        "content": "```swarmauri/experimental/distances/CanberraDistance.py\nimport numpy as np\nfrom typing import List\nfrom swarmauri.core.vector_stores.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\n\nclass CanberraDistance(IDistanceSimilarity):\n    \"\"\"\n    Concrete implementation of the IDistanceSimiliarity interface using the Canberra distance metric.\n    This class now processes IVector instances instead of raw lists.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Canberra distance between two IVector instances.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The computed Canberra distance between the vectors.\n        \"\"\"\n        # Extract data from IVector\n        data_a = np.array(vector_a.data)\n        data_b = np.array(vector_b.data)\n\n        # Checking dimensions match\n        if data_a.shape != data_b.shape:\n            raise ValueError(\"Vectors must have the same dimensionality.\")\n\n        # Computing Canberra distance\n        distance = np.sum(np.abs(data_a - data_b) / (np.abs(data_a) + np.abs(data_b)))\n        # Handling the case where both vectors have a zero value for the same dimension\n        distance = np.nan_to_num(distance)\n        return distance\n    \n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute similarity using the Canberra distance. Since this distance metric isn't\n        directly interpretable as a similarity, a transformation is applied to map the distance\n        to a similarity score.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector to compare with the first vector.\n\n        Returns:\n            float: A similarity score between vector_a and vector_b.\n        \"\"\"\n        # One way to derive a similarity from distance is through inversion or transformation.\n        # Here we use an exponential decay based on the computed distance. This is a placeholder\n        # that assumes closer vectors (smaller distance) are more similar.\n        distance = self.distance(vector_a, vector_b)\n\n        # Transform the distance into a similarity score\n        similarity = np.exp(-distance)\n\n        return similarity\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/ChebyshevDistance.py",
        "content": "```swarmauri/experimental/distances/ChebyshevDistance.py\nfrom typing import List\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.core.vector_stores.IDistanceSimilarity import IDistanceSimilarity\n\nclass ChebyshevDistance(IDistanceSimilarity):\n    \"\"\"\n    Concrete implementation of the IDistanceSimiliarity interface using the Chebyshev distance metric.\n    Chebyshev distance is the maximum absolute distance between two vectors' elements.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Chebyshev distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The computed Chebyshev distance between vector_a and vector_b.\n        \"\"\"\n        max_distance = 0\n        for a, b in zip(vector_a.data, vector_b.data):\n            max_distance = max(max_distance, abs(a - b))\n        return max_distance\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the similarity between two vectors based on the Chebyshev distance.\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector.\n\n        Returns:\n            float: The similarity score between the two vectors.\n        \"\"\"\n\n        return 1 / (1 + self.distance(vector_a, vector_b))\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/HaversineDistance.py",
        "content": "```swarmauri/experimental/distances/HaversineDistance.py\nfrom typing import List\nfrom math import radians, cos, sin, sqrt, atan2\nfrom swarmauri.core.vector_stores.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\n\nclass HaversineDistance(IDistanceSimilarity):\n    \"\"\"\n    Concrete implementation of IDistanceSimiliarity interface using the Haversine formula.\n    \n    Haversine formula determines the great-circle distance between two points on a sphere given their \n    longitudes and latitudes. This implementation is particularly useful for geo-spatial data.\n    \"\"\" \n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Haversine distance between two geo-spatial points.\n\n        Args:\n            vector_a (IVector): The first point in the format [latitude, longitude].\n            vector_b (IVector): The second point in the same format [latitude, longitude].\n\n        Returns:\n            float: The Haversine distance between vector_a and vector_b in kilometers.\n        \"\"\"\n        # Earth radius in kilometers\n        R = 6371.0\n\n        lat1, lon1 = map(radians, vector_a.data)\n        lat2, lon2 = map(radians, vector_b.data)\n\n        dlat = lat2 - lat1\n        dlon = lon2 - lon1\n\n        # Haversine formula\n        a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n        distance = R * c\n\n        return distance\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        raise NotImplementedError(\"Similarity not implemented for Haversine distance.\")\n        \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        raise NotImplementedError(\"Similarity not implemented for Haversine distance.\")\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/ManhattanDistance.py",
        "content": "```swarmauri/experimental/distances/ManhattanDistance.py\nfrom typing import List\nfrom swarmauri.core.vector_stores.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass ManhattanDistance(IDistanceSimilarity):\n    \"\"\"\n    Concrete implementation of the IDistanceSimiliarity interface using the Manhattan distance.\n    \n    The Manhattan distance between two points is the sum of the absolute differences of their Cartesian coordinates.\n    This is also known as L1 distance.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Manhattan distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The Manhattan distance between vector_a and vector_b.\n        \"\"\"\n        if vector_a.dimensions != vector_b.dimensions:\n            raise ValueError(\"Vectors must have the same dimensionality.\")\n        \n        return sum(abs(a - b) for a, b in zip(vector_a.data, vector_b.data))\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        The similarity based on Manhattan distance can be inversely related to the distance for some applications,\n        but this method intentionally returns NotImplementedError to signal that Manhattan distance is typically\n        not directly converted to similarity in the conventional sense used in this context.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            NotImplementedError: This is intended as this distance metric doesn't directly offer a similarity measure.\n        \"\"\"\n        raise NotImplementedError(\"ManhattanDistance does not directly provide a similarity measure.\")\n        \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        raise NotImplementedError(\"ManhattanDistance does not directly provide a similarity measure.\")\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/MinkowskiDistance.py",
        "content": "```swarmauri/experimental/distances/MinkowskiDistance.py\nfrom typing import List\nfrom scipy.spatial.distance import minkowski\nfrom swarmauri.core.vector_stores.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass MinkowskiDistance(IDistanceSimilarity):\n    \"\"\"\n    Implementation of the IDistanceSimiliarity interface using the Minkowski distance metric.\n    Minkowski distance is a generalized metric form that includes Euclidean distance,\n    Manhattan distance, and others depending on the order (p) parameter.\n\n    The class provides methods to compute the Minkowski distance between two vectors.\n    \"\"\"\n\n    def __init__(self, p: int = 2):\n        \"\"\"\n        Initializes the MinkowskiDistance calculator with the specified order.\n\n        Parameters:\n        - p (int): The order of the Minkowski distance. p=2 corresponds to the Euclidean distance,\n                   while p=1 corresponds to the Manhattan distance. Default is 2.\n        \"\"\"\n        self.p = p\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Minkowski distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The computed Minkowski distance between vector_a and vector_b.\n        \"\"\"\n        # Check if both vectors have the same dimensionality\n        if vector_a.dimensions != vector_b.dimensions:\n            raise ValueError(\"Vectors must have the same dimensionality.\")\n\n        # Extract data from IVector instances\n        data_a = vector_a.data\n        data_b = vector_b.data\n\n        # Calculate and return the Minkowski distance\n        return minkowski(data_a, data_b, p=self.p)\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the similarity between two vectors based on the Minkowski distance.\n        The similarity is inversely related to the distance.\n\n        Args:\n            vector_a (IVector): The first vector to compare for similarity.\n            vector_b (IVector): The second vector to compare with the first vector.\n\n        Returns:\n            float: A similarity score between vector_a and vector_b.\n        \"\"\"\n        dist = self.distance(vector_a, vector_b)\n        return 1 / (1 + dist)  # An example similarity score\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/ScannVectorStore.py",
        "content": "```swarmauri/experimental/distances/ScannVectorStore.py\nimport numpy as np\nimport scann\nfrom typing import List, Dict, Union\n\nfrom swarmauri.core.vector_stores.IVectorStore import IVectorStore\nfrom swarmauri.core.vector_stores.ISimiliarityQuery import ISimilarityQuery\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\n\n\nclass ScannVectorStore(IVectorStore, ISimilarityQuery):\n    \"\"\"\n    A vector store that utilizes ScaNN (Scalable Nearest Neighbors) for efficient similarity searches.\n    \"\"\"\n\n    def __init__(self, dimension: int, num_leaves: int = 100, num_leaves_to_search: int = 10, reordering_num_neighbors: int = 100):\n        \"\"\"\n        Initialize the ScaNN vector store with given parameters.\n\n        Parameters:\n        - dimension (int): The dimensionality of the vectors being stored.\n        - num_leaves (int): The number of leaves for the ScaNN partitioning tree.\n        - num_leaves_to_search (int): The number of leaves to search for query time. Must be <= num_leaves.\n        - reordering_num_neighbors (int): The number of neighbors to re-rank based on the exact distance after searching leaves.\n        \"\"\"\n        self.dimension = dimension\n        self.num_leaves = num_leaves\n        self.num_leaves_to_search = num_leaves_to_search\n        self.reordering_num_neighbors = reordering_num_neighbors\n\n        self.searcher = None  # Placeholder for the ScaNN searcher initialized during building\n        self.dataset_vectors = []\n        self.id_to_metadata = {}\n\n    def _build_scann_searcher(self):\n        \"\"\"Build the ScaNN searcher based on current dataset vectors.\"\"\"\n        self.searcher = scann.ScannBuilder(np.array(self.dataset_vectors, dtype=np.float32), num_neighbors=self.reordering_num_neighbors, distance_measure=\"dot_product\").tree(\n            num_leaves=self.num_leaves, num_leaves_to_search=self.num_leaves_to_search, training_sample_size=25000\n        ).score_ah(\n            dimensions_per_block=2\n        ).reorder(self.reordering_num_neighbors).build()\n\n    def add_vector(self, vector_id: str, vector: Union[np.ndarray, List[float]], metadata: Dict = None) -> None:\n        \"\"\"\n        Adds a vector along with its identifier and optional metadata to the store.\n\n        Args:\n            vector_id (str): Unique identifier for the vector.\n            vector (Union[np.ndarray, List[float]]): The high-dimensional vector to be stored.\n            metadata (Dict, optional): Optional metadata related to the vector.\n        \"\"\"\n        if not isinstance(vector, np.ndarray):\n            vector = np.array(vector, dtype=np.float32)\n        \n        if self.searcher is None:\n            self.dataset_vectors.append(vector)\n        else:\n            raise Exception(\"Cannot add vectors after building the index. Rebuild the index to include new vectors.\")\n\n        if metadata is None:\n            metadata = {}\n        self.id_to_metadata[vector_id] = metadata\n\n    def build_index(self):\n        \"\"\"Builds or rebuilds the ScaNN searcher to reflect the current dataset vectors.\"\"\"\n        self._build_scann_searcher()\n\n    def get_vector(self, vector_id: str) -> Union[IVector, None]:\n        \"\"\"\n        Retrieve a vector by its identifier.\n\n        Args:\n            vector_id (str): The unique identifier for the vector.\n\n        Returns:\n            Union[IVector, None]: The vector associated with the given id, or None if not found.\n        \"\"\"\n        if vector_id in self.id_to_metadata:\n            metadata = self.id_to_metadata[vector_id]\n            return SimpleVector(data=metadata.get('vector'), metadata=metadata)\n        return None\n\n    def delete_vector(self, vector_id: str) -> None:\n        \"\"\"\n        Deletes a vector from the ScannVectorStore and marks the index for rebuilding.\n        Note: For simplicity, this function assumes vectors are uniquely identifiable by their metadata.\n\n        Args:\n            vector_id (str): The unique identifier for the vector to be deleted.\n        \"\"\"\n        if vector_id in self.id_to_metadata:\n            # Identify index of the vector to be deleted\n            vector = self.id_to_metadata[vector_id]['vector']\n            index = self.dataset_vectors.index(vector)\n\n            # Remove vector and its metadata\n            del self.dataset_vectors[index]\n            del self.id_to_metadata[vector_id]\n\n            # Since vector order is important for matching ids, rebuild the searcher to reflect deletion\n            self.searcher = None\n        else:\n            # Handle case where vector_id is not found\n            print(f\"Vector ID {vector_id} not found.\")\n\n    def update_vector(self, vector_id: str, new_vector: Union[np.ndarray, List[float]], new_metadata: Dict = None) -> None:\n        \"\"\"\n        Updates an existing vector in the ScannVectorStore and marks the index for rebuilding.\n\n        Args:\n            vector_id (str): The unique identifier for the vector to be updated.\n            new_vector (Union[np.ndarray, List[float]]): The updated vector.\n            new_metadata (Dict, optional): Optional updated metadata for the vector.\n        \"\"\"\n        # Ensure new_vector is numpy array for consistency\n        if not isinstance(new_vector, np.ndarray):\n            new_vector = np.array(new_vector, dtype=np.float32)\n\n        if vector_id in self.id_to_metadata:\n            # Update operation follows delete then add strategy because vector order matters in ScaNN\n            self.delete_vector(vector_id)\n            self.add_vector(vector_id, new_vector, new_metadata)\n        else:\n            # Handle case where vector_id is not found\n            print(f\"Vector ID {vector_id} not found.\")\n\n\n\n    def search_by_similarity_threshold(self, query_vector: Union[np.ndarray, List[float]], similarity_threshold: float, space_name: str = None) -> List[Dict]:\n        \"\"\"\n        Search vectors exceeding a similarity threshold to a query vector within an optional vector space.\n\n        Args:\n            query_vector (Union[np.ndarray, List[float]]): The high-dimensional query vector.\n            similarity_threshold (float): The similarity threshold for filtering results.\n            space_name (str, optional): The name of the vector space to search within. Not used in this implementation.\n\n        Returns:\n            List[Dict]: A list of dictionaries with vector IDs, similarity scores, and optional metadata that meet the similarity threshold.\n        \"\"\"\n        if not isinstance(query_vector, np.ndarray):\n            query_vector = np.array(query_vector, dtype=np.float32)\n        \n        if self.searcher is None:\n            self._build_scann_searcher()\n        \n        _, indices = self.searcher.search(query_vector, final_num_neighbors=self.reordering_num_neighbors)\n        results = [{\"id\": str(idx), \"metadata\": self.id_to_metadata.get(str(idx), {})} for idx in indices if idx < similarity_threshold]\n        return results\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/SorensenDiceDistance.py",
        "content": "```swarmauri/experimental/distances/SorensenDiceDistance.py\nimport numpy as np\nfrom typing import List\nfrom collections import Counter\n\nfrom swarmauri.core.vector_stores.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass SorensenDiceDistance(IDistanceSimilarity):\n    \"\"\"\n    Implementing a concrete Vector Store class for calculating S\u00c3\u00b6rensen-Dice Index Distance.\n    The S\u00c3\u00b6rensen-Dice Index, or Dice's coefficient, is a measure of the similarity between two sets.\n    \"\"\"\n\n    def distance(self, vector_a: List[float], vector_b: List[float]) -> float:\n        \"\"\"\n        Compute the S\u00c3\u00b6rensen-Dice distance between two vectors.\n        \n        Args:\n            vector_a (List[float]): The first vector in the comparison.\n            vector_b (List[float]): The second vector in the comparison.\n        \n        Returns:\n            float: The computed S\u00c3\u00b6rensen-Dice distance between vector_a and vector_b.\n        \"\"\"\n        # Convert vectors to binary sets\n        set_a = set([i for i, val in enumerate(vector_a) if val])\n        set_b = set([i for i, val in enumerate(vector_b) if val])\n        \n        # Calculate the intersection size\n        intersection_size = len(set_a.intersection(set_b))\n        \n        # Sorensen-Dice Index calculation\n        try:\n            sorensen_dice_index = (2 * intersection_size) / (len(set_a) + len(set_b))\n        except ZeroDivisionError:\n            sorensen_dice_index = 0.0\n        \n        # Distance is inverse of similarity for S\u00c3\u00b6rensen-Dice\n        distance = 1 - sorensen_dice_index\n        \n        return distance\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarity(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        raise NotImplementedError(\"Similarity calculation is not implemented for SorensenDiceDistance.\")\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        raise NotImplementedError(\"Similarity calculation is not implemented for SorensenDiceDistance.\")\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/SquaredEuclideanDistance.py",
        "content": "```swarmauri/experimental/distances/SquaredEuclideanDistance.py\nfrom typing import List\nfrom swarmauri.core.vector_stores.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass SquaredEuclideanDistance(IDistanceSimilarity):\n    \"\"\"\n    A concrete class for computing the squared Euclidean distance between two vectors.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the squared Euclidean distance between vectors `vector_a` and `vector_b`.\n\n        Parameters:\n        - vector_a (IVector): The first vector in the comparison.\n        - vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n        - float: The computed squared Euclidean distance between vector_a and vector_b.\n        \"\"\"\n        if vector_a.dimensions != vector_b.dimensions:\n            raise ValueError(\"Vectors must be of the same dimensionality.\")\n\n        squared_distance = sum((a - b) ** 2 for a, b in zip(vector_a.data, vector_b.data))\n        return squared_distance\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Squared Euclidean distance is not used for calculating similarity.\n        \n        Parameters:\n        - vector_a (IVector): The first vector.\n        - vector_b (IVector): The second vector.\n\n        Raises:\n        - NotImplementedError: Indicates that similarity calculation is not implemented.\n        \"\"\"\n        raise NotImplementedError(\"Similarity calculation is not implemented for Squared Euclidean distance.\")\n        \n        \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        raise NotImplementedError(\"Similarity calculation is not implemented for Squared Euclidean distance.\")\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/SSASimilarity.py",
        "content": "```swarmauri/experimental/distances/SSASimilarity.py\nfrom typing import Set, List, Dict\nfrom ....core.vector_stores.ISimilarity import ISimilarity\nfrom ....core.vectors.IVector import IVector\n\n\nclass SSASimilarity(ISimilarity):\n    \"\"\"\n    Implements the State Similarity in Arity (SSA) similarity measure to\n    compare states (sets of variables) for their similarity.\n    \"\"\"\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Calculate the SSA similarity between two documents by comparing their metadata,\n        assumed to represent states as sets of variables.\n\n        Args:\n        - vector_a (IDocument): The first document.\n        - vector_b (IDocument): The second document to compare with the first document.\n\n        Returns:\n        - float: The SSA similarity measure between vector_a and vector_b, ranging from 0 to 1\n                 where 0 represents no similarity and 1 represents identical states.\n        \"\"\"\n        state_a = set(vector_a.metadata.keys())\n        state_b = set(vector_b.metadata.keys())\n\n        return self.calculate_ssa(state_a, state_b)\n\n    @staticmethod\n    def calculate_ssa(state_a: Set[str], state_b: Set[str]) -> float:\n        \"\"\"\n        Calculate the State Similarity in Arity (SSA) between two states.\n\n        Parameters:\n        - state_a (Set[str]): A set of variables representing state A.\n        - state_b (Set[str]): A set of variables representing state B.\n\n        Returns:6\n        - float: The SSA similarity measure, ranging from 0 (no similarity) to 1 (identical states).\n        \"\"\"\n        # Calculate the intersection (shared variables) between the two states\n        shared_variables = state_a.intersection(state_b)\n        \n        # Calculate the union (total unique variables) of the two states\n        total_variables = state_a.union(state_b)\n        \n        # Calculate the SSA measure as the ratio of shared to total variables\n        ssa = len(shared_variables) / len(total_variables) if total_variables else 1\n        \n        return ssa\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/SSIVSimilarity.py",
        "content": "```swarmauri/experimental/distances/SSIVSimilarity.py\nfrom typing import List, Dict, Set\nfrom ....core.vector_stores.ISimilarity import ISimilarity\n\nclass SSIVSimilarity(ISimilarity):\n    \"\"\"\n    Concrete class that implements ISimilarity interface using\n    State Similarity of Important Variables (SSIV) as the similarity measure.\n    \"\"\"\n\n    def similarity(self, state_a: Set[str], state_b: Set[str], importance_a: Dict[str, float], importance_b: Dict[str, float]) -> float:\n        \"\"\"\n        Calculate the SSIV between two states represented by sets of variables.\n\n        Parameters:\n        - state_a (Set[str]): A set of variables representing state A.\n        - state_b (Set[str]): A set of variables representing state B.\n        - importance_a (Dict[str, float]): A dictionary where keys are variables in state A and values are their importance weights.\n        - importance_b (Dict[str, float]): A dictionary where keys are variables in state B and values are their importance weights.\n\n        Returns:\n        - float: The SSIV similarity measure, ranging from 0 to 1.\n        \"\"\"\n        return self.calculate_ssiv(state_a, state_b, importance_a, importance_b)\n\n    @staticmethod\n    def calculate_ssiv(state_a: Set[str], state_b: Set[str], importance_a: Dict[str, float], importance_b: Dict[str, float]) -> float:\n        \"\"\"\n        Calculate the State Similarity of Important Variables (SSIV) between two states.\n\n        Parameters:\n        - state_a (Set[str]): A set of variables representing state A.\n        - state_b (Set[str]): A set of variables representing state B.\n        - importance_a (Dict[str, float]): A dictionary where keys are variables in state A and values are their importance weights.\n        - importance_b (Dict[str, float]): A dictionary where keys are variables in state B and values are their importance weights.\n\n        Returns:\n        - float: The SSIV similarity measure, ranging from 0 to 1.\n        \n        Note: It is assumed that the importance weights are non-negative.\n        \"\"\"\n        shared_variables = state_a.intersection(state_b)\n        \n        # Calculate the summed importance of shared variables\n        shared_importance_sum = sum(importance_a[var] for var in shared_variables) + sum(importance_b[var] for var in shared_variables)\n        \n        # Calculate the total importance of all variables in both states\n        total_importance_sum = sum(importance_a.values()) + sum(importance_b.values())\n        \n        # Calculate and return the SSIV\n        ssiv = (2 * shared_importance_sum) / total_importance_sum if total_importance_sum != 0 else 0\n        return ssiv\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/distances/__init__.py",
        "content": "```swarmauri/experimental/distances/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/experimental/apis/CeleryAgentCommands.py",
        "content": "```swarmauri/experimental/apis/CeleryAgentCommands.py\nfrom celery import Celery\nfrom swarmauri.core.agent_apis.IAgentCommands import IAgentCommands\nfrom typing import Callable, Any, Dict\n\nclass CeleryAgentCommands(IAgentCommands):\n    def __init__(self, broker_url: str, backend_url: str):\n        \"\"\"\n        Initializes the Celery application with the specified broker and backend URLs.\n        \"\"\"\n        self.app = Celery('swarmauri_agent_tasks', broker=broker_url, backend=backend_url)\n\n    def register_command(self, command_name: str, function: Callable[..., Any], *args, **kwargs) -> None:\n        \"\"\"\n        Registers a new command as a Celery task.\n        \"\"\"\n        self.app.task(name=command_name, bind=True)(function)\n\n    def execute_command(self, command_name: str, *args, **kwargs) -> Any:\n        \"\"\"\n        Executes a registered command by name asynchronously.\n        \"\"\"\n        result = self.app.send_task(command_name, args=args, kwargs=kwargs)\n        return result.get()\n\n    def get_status(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Fetches the status of a command execution via its task ID.\n        \"\"\"\n        async_result = self.app.AsyncResult(task_id)\n        return {\"status\": async_result.status, \"result\": async_result.result if async_result.ready() else None}\n\n    def revoke_command(self, task_id: str) -> None:\n        \"\"\"\n        Revokes or terminates a command execution by its task ID.\n        \"\"\"\n        self.app.control.revoke(task_id, terminate=True)\n```"
    },
    {
        "document_name": "swarmauri/standard/__init__.py",
        "content": "```swarmauri/standard/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/__init__.py",
        "content": "```swarmauri/standard/models/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/base/__init__.py",
        "content": "```swarmauri/standard/models/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/base/ModelBase.py",
        "content": "```swarmauri/standard/models/base/ModelBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any\nfrom ....core.models.IModel import IModel\n\nclass ModelBase(IModel, ABC):\n    \"\"\"\n    Concrete implementation of the IModel abstract base class.\n    This version includes managing the model name through a property and a setter.\n    \"\"\"\n    @abstractmethod\n    def __init__(self, model_name: str):\n        self._model_name = model_name\n    \n    @property\n    def model_name(self):\n        return self._model_name\n    \n    @model_name.setter\n    def model_name(self, value: str) -> None:\n        \"\"\"\n        Property setter that sets the name of the model.\n\n        Parameters:\n        - value (str): The new name of the model.\n        \"\"\"\n        self._model_name = value\n       \n    \n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/__init__.py",
        "content": "```swarmauri/standard/models/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/OpenAIModel.py",
        "content": "```swarmauri/standard/models/concrete/OpenAIModel.py\nimport json\nfrom typing import List\nfrom openai import OpenAI\nfrom swarmauri.core.models.IPredict import IPredict\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\n\n\nclass OpenAIModel(ModelBase, IPredict):\n    allowed_models = ['gpt-4o', \n    'gpt-4-turbo', \n    'gpt-4-0125-preview',\n    'gpt-4',\n    'gpt-4-0613',\n    'gpt-4-32k',\n    'gpt-4-32k-0613',\n    'gpt-3.5-turbo-0125',\n    'gpt-3.5-turbo-16k',\n    'gpt-3.5-turbo']\n\n    def __init__(self, api_key: str, model_name: str):\n        \"\"\"\n        Initialize the OpenAI model with an API key.\n\n        Parameters:\n        - api_key (str): Your OpenAI API key.\n        \"\"\"\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        self.client = OpenAI(api_key=api_key)\n        super().__init__(model_name)\n        \n    \n    def predict(self, messages, temperature=0.7, max_tokens=256, enable_json=False, stop: List[str] = None):\n        \"\"\"\n        Generate predictions using the OpenAI model.\n\n        Parameters:\n        - messages: Input data/messages for the model.\n        - temperature (float): Sampling temperature.\n        - max_tokens (int): Maximum number of tokens to generate.\n        - enable_json (bool): Format response as JSON.\n        \n        Returns:\n        - The generated message content.\n        \"\"\"\n        \n        if enable_json:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                response_format={ \"type\": \"json_object\" },\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=stop\n            )\n        else:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=stop\n            )\n        \n        result = json.loads(response.json())\n        message_content = result['choices'][0]['message']['content']\n        \n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/AzureGPT.py",
        "content": "```swarmauri/standard/models/concrete/AzureGPT.py\nimport json\nfrom openai import AzureOpenAI\nfrom ..base.ModelBase import ModelBase\nfrom ....core.models.IPredict import IPredict\n\nclass AzureGPT(ModelBase, IPredict):\n    def __init__(self, azure_endpoint: str, api_key: str, api_version: str, model_name: str):\n        \"\"\"\n        Initialize the Azure model with an API key.\n\n        Parameters:\n        - api_key (str): Your OpenAI API key.\n        \"\"\"\n        self.azure_endpoint = azure_endpoint\n        self.api_key = api_key\n        self.api_version = api_version\n        self.client = AzureOpenAI(\n                azure_endpoint = azure_endpoint, \n                api_key = api_key,  \n                api_version = api_version\n            )\n        super().__init__(model_name)\n       \n\n    \n    def predict(self, messages, temperature=0.7, max_tokens=256, enable_json=True):\n        \"\"\"\n        Generate predictions using the OpenAI model.\n\n        Parameters:\n        - messages: Input data/messages for the model.\n        - temperature (float): Sampling temperature.\n        - max_tokens (int): Maximum number of tokens to generate.\n        - enable_json (bool): Format response as JSON.\n        \n        Returns:\n        - The generated message content.\n        \"\"\"\n        \n        if enable_json:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                response_format={ \"type\": \"json_object\" },\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=None\n            )\n        else:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=None\n            )\n        \n        result = response.json()\n        message_content = json.loads(result['choices'][0]['message']['content'])\n        \n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/OpenAIImageGenerator.py",
        "content": "```swarmauri/standard/models/concrete/OpenAIImageGenerator.py\nimport json\nfrom openai import OpenAI\nfrom ..base.ModelBase import ModelBase\nfrom ....core.models.IPredict import IPredict\n\nclass OpenAIImageGenerator(ModelBase, IPredict):\n    def __init__(self, api_key: str, model_name: str = \"dall-e\"):\n        \"\"\"\n        Initializes the OpenAI image generator model.\n\n        Parameters:\n        - api_key (str): The API key provided by OpenAI for access to their services.\n        - model_name (str): Name of the image generation model provided by OpenAI.\n                            Defaults to \"dall-e\" for DALL\u00c2\u00b7E, their image generation model.\n        \"\"\"\n        self.client = OpenAI(api_key=api_key)\n        super().__init__(model_name)\n\n    def predict(self, prompt: str, size: str = \"1024x1024\", \n                quality: str = \"standard\", n: int = 1) -> str:\n        \"\"\"\n        Generates an image based on the given prompt and other parameters.\n\n        Parameters:\n        - prompt (str): A description of the image you want to generate.\n        - **kwargs: Additional parameters that the image generation endpoint might use.\n\n        Returns:\n        - str: A URL or identifier for the generated image.\n        \"\"\"\n        try:\n            response = self.client.images.generate(\n                model=self.model_name,\n                prompt=prompt,\n                size=size,\n                quality=quality,\n                n=n\n            )\n            result = response.json()\n            return result\n        \n        except Exception as e:\n            return str(e)\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/OpenAIToolModel.py",
        "content": "```swarmauri/standard/models/concrete/OpenAIToolModel.py\nfrom openai import OpenAI\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\nfrom swarmauri.core.models.IPredict import IPredict\n\nclass OpenAIToolModel(ModelBase, IPredict):\n    def __init__(self, api_key: str, model_name: str = \"gpt-3.5-turbo-0125\"):\n        self.client = OpenAI(api_key=api_key)\n        super().__init__(model_name)\n\n    def predict(self, messages, tools=None, tool_choice=None, temperature=0.7, max_tokens=1024):\n        if tools and not tool_choice:\n            tool_choice = \"auto\"\n        response = self.client.chat.completions.create(\n            model=self.model_name,\n            messages=messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            tools=tools,\n            tool_choice=tool_choice,\n        )\n        return response\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/GroqModel.py",
        "content": "```swarmauri/standard/models/concrete/GroqModel.py\nimport json\nfrom typing import List\nfrom groq import Groq\nfrom swarmauri.core.models.IPredict import IPredict\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\n\n\nclass GroqModel(ModelBase, IPredict):\n    allowed_models = ['llama3-8b-8192', 'llama3-70b-8192', 'mixtral-8x7b-32768', 'gemma-7b-it']\n\n    def __init__(self, api_key: str, model_name: str = 'mixtral-8x7b-32768'):\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        self.client = Groq(api_key=api_key)\n        super().__init__(model_name)\n        \n    \n    def predict(self, messages, \n        temperature=0.7, \n        max_tokens=256, \n        top_p=1, \n        enable_json=False, \n        stop: List[str] = None):\n        if enable_json:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                response_format={ \"type\": \"json_object\" },\n                max_tokens=max_tokens,\n                top_p=top_p,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=stop\n            )\n        else:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=top_p,\n                frequency_penalty=0,\n                presence_penalty=0,\n                stop=stop\n            )\n        \n        result = json.loads(response.json())\n        message_content = result['choices'][0]['message']['content']\n        \n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/GroqToolModel.py",
        "content": "```swarmauri/standard/models/concrete/GroqToolModel.py\nfrom groq import Groq\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\nfrom swarmauri.core.models.IPredict import IPredict\n\nclass GroqToolModel(ModelBase, IPredict):\n    allowed_models = ['llama3-8b-8192', 'llama3-70b-8192', 'mixtral-8x7b-32768', 'gemma-7b-it']\n\n    def __init__(self, api_key: str, model_name: str = 'mixtral-8x7b-32768'):\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        self.client = Groq(api_key=api_key)\n        super().__init__(model_name)\n        \n\n    def predict(self, messages, tools=None, tool_choice=None, temperature=0.7, max_tokens=1024):\n        if tools and not tool_choice:\n            tool_choice = \"auto\"\n        response = self.client.chat.completions.create(\n            model=self.model_name,\n            messages=messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            tools=tools,\n            tool_choice=tool_choice,\n        )\n        return response\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/MistralModel.py",
        "content": "```swarmauri/standard/models/concrete/MistralModel.py\nimport json\nfrom typing import List\nfrom mistralai.client import MistralClient\nfrom swarmauri.core.models.IPredict import IPredict\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\n\n\nclass MistralModel(ModelBase, IPredict):\n    allowed_models = ['open-mistral-7b', \n    'open-mixtral-8x7b', \n    'open-mixtral-8x22b', \n    'mistral-small-latest',\n    'mistral-medium-latest',\n    'mistral-large-latest',\n    ]\n\n    def __init__(self, api_key: str, model_name: str = 'open-mixtral-8x7b'):\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        self.client = MistralClient(api_key=api_key)\n        super().__init__(model_name)\n        \n    \n    def predict(self, messages, \n        temperature: int = 0.7, \n        max_tokens: int = 256, \n        top_p: int = 1,\n        enable_json: bool=False, \n        safe_prompt: bool=False):\n        \n        if enable_json:\n            response = self.client.chat(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                response_format={ \"type\": \"json_object\" },\n                max_tokens=max_tokens,\n                top_p=top_p,\n                safe_prompt=safe_prompt\n            )\n        else:\n            response = self.client.chat(\n                model=self.model_name,\n                messages=messages,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=top_p,                \n                safe_prompt=safe_prompt\n            )\n        \n        result = json.loads(response.json())\n        message_content = result['choices'][0]['message']['content']\n        \n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/MistralToolModel.py",
        "content": "```swarmauri/standard/models/concrete/MistralToolModel.py\nfrom mistralai.client import MistralClient\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\nfrom swarmauri.core.models.IPredict import IPredict\n\nclass MistralToolModel(ModelBase, IPredict):\n    allowed_models = ['open-mixtral-8x22b', \n    'mistral-small-latest',\n    'mistral-large-latest',\n    ]\n\n    def __init__(self, api_key: str, model_name: str = 'open-mixtral-8x22b'):\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        self.client = MistralClient(api_key=api_key)\n        super().__init__(model_name)\n        \n\n    def predict(self, messages, tools=None, tool_choice=None, temperature=0.7, \n        max_tokens=1024, safe_prompt: bool = False):\n\n        if tools and not tool_choice:\n            tool_choice = \"auto\"\n        response = self.client.chat.completions.create(\n            model=self.model_name,\n            messages=messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            tools=tools,\n            tool_choice=tool_choice,\n            safe_prompt=safe_prompt\n        )\n        return response\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/CohereModel.py",
        "content": "```swarmauri/standard/models/concrete/CohereModel.py\nimport json\nfrom typing import List\nimport cohere\nfrom swarmauri.core.models.IPredict import IPredict\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\n\n\nclass CohereModel(ModelBase, IPredict):\n    allowed_models = ['command-light',\n    'command', \n    'command-r',\n    'command-r-plus']\n\n    def __init__(self, api_key: str, model_name: str = 'command-light'):\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        self.client = cohere.Client(api_key=api_key)\n        super().__init__(model_name)\n        \n    \n    def predict(self, messages, temperature=0.7, max_tokens=256):\n        response = self.client.chat(\n            model=self.model_name,\n            messages=messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            prompt_truncation='OFF',\n            connectors=[]\n        )\n        \n        result = json.loads(response.json())\n        message_content = result['choices'][0]['message']['content']\n        \n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/GeminiProModel.py",
        "content": "```swarmauri/standard/models/concrete/GeminiProModel.py\nimport json\nfrom typing import List\nimport google.generativeai as genai\nfrom swarmauri.core.models.IPredict import IPredict\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\n\n\nclass GeminiProModel(ModelBase, IPredict):\n    allowed_models = ['gemini-1.5-pro-latest']\n\n    def __init__(self, api_key: str, model_name: str = 'gemini-1.5-pro-latest'):\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        genai.configure(api_key=api_key)\n        self.safety_settings = [\n          {\n            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n          {\n            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n          {\n            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n          {\n            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n        ]\n        self.safety_settings = [\n          {\n            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n          {\n            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n          {\n            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n          {\n            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n          },\n        ]\n        self.client = None\n        super().__init__(model_name)\n        \n    \n    def predict(self, messages, temperature=0.7, max_tokens=256):\n        generation_config = {\n            \"temperature\": temperature,\n            \"top_p\": 0.95,\n            \"top_k\": 0,\n            \"max_output_tokens\": max_tokens,\n            }\n\n        system_context = None\n        for message in messages:\n\n            # update role naming\n            role = message.pop('role')\n            if role == 'assistant':\n                role = 'model'\n\n            if role == 'system':\n                system_context = message['content']\n\n            # rename role\n            message['role'] = role\n\n            # update content naming\n            message['parts'] = message.pop('content')\n\n        \n        # Remove system instruction from messages\n        sanitized_messages = [message for message in messages if message['role'] != 'system'] \n\n        # if we remove more than one system message from the array\n        # then we know we were given too many system messages\n        # we raise an error in this scenario.\n        # Examples:\n        # 10 - 1 = 9 so if 9 + 1 < 10  then negative is good\n        # 10 - 2 = 8, so if 8 + 1 < 10 then positive is bad\n        if len(sanitized_messages) + 1 > len(messages):\n            raise ValueError('cannot send an array of conversations containing more than one system instruction.')\n\n\n        next_message = sanitized_messages.pop()\n\n        self.client = genai.GenerativeModel(model_name=self.model_name,\n            safety_settings=self.safety_settings,\n            generation_config=generation_config)\n\n        convo = self.client.start_chat(\n            history=sanitized_messages,\n            )\n\n        convo.send_message(next_message['parts'])\n\n        message_content = convo.last.text\n        \n        return message_content\n\n```"
    },
    {
        "document_name": "swarmauri/standard/models/concrete/AnthropicModel.py",
        "content": "```swarmauri/standard/models/concrete/AnthropicModel.py\nimport json\nfrom typing import List\nimport anthropic\nfrom swarmauri.core.models.IPredict import IPredict\nfrom swarmauri.standard.models.base.ModelBase import ModelBase\n\n\nclass AnthropicModel(ModelBase, IPredict):\n    allowed_models = ['claude-3-opus-20240229', \n    'claude-3-sonnet-20240229', \n    'claude-3-haiku-20240307',\n    'claude-2.1',\n    'claude-2.0',\n    'claude-instant-1.2']\n\n    def __init__(self, api_key: str, model_name: str = 'claude-3-haiku-20240307'):\n        if model_name not in self.allowed_models:\n            raise ValueError(f\"Model name '{model_name}' is not supported. Choose from {self.allowed_models}\")\n        \n        self.client = anthropic.Anthropic(api_key=api_key)\n        super().__init__(model_name)\n        \n    \n    def predict(self, messages, temperature=0.7, max_tokens=256):\n\n\n\n        # Get system_context\n        system_context = None\n        for message in messages:\n            if message['role'] == 'system':\n                system_context = message['content']\n\n        # Remove system instruction from messages\n        sanitized_messages = [message for message in messages if message['role'] != 'system'] \n\n        # we should only remove one message for system instruction\n        if len(sanitized_messages) + 1 > len(messages):\n            raise ValueError('cannot send an array of conversations containing more than one system instruction.')\n\n        # Chat\n        response = self.client.messages.create(\n            model=self.model_name,\n            messages=sanitized_messages,\n            system=system_context,\n            temperature=temperature,\n            max_tokens=max_tokens\n        )\n        \n        \n        message_content = response.content[0].text\n        return message_content\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/__init__.py",
        "content": "```swarmauri/standard/agents/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/__init__.py",
        "content": "```swarmauri/standard/agents/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/NamedAgentBase.py",
        "content": "```swarmauri/standard/agents/base/NamedAgentBase.py\nfrom abc import ABC\nfrom swarmauri.core.agents.IAgentName import IAgentName\n\n\nclass NamedAgentBase(IAgentName, ABC):\n    def __init__(self, name: str):\n        self._name = name\n\n    @property\n    def name(self) -> str:\n        return self._name\n    \n    @name.setter\n    def name(self, value) -> None:\n        self._name = value     \n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/ConversationAgentBase.py",
        "content": "```swarmauri/standard/agents/base/ConversationAgentBase.py\nfrom abc import ABC\n\nfrom swarmauri.core.agents.IAgentConversation import IAgentConversation\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nclass ConversationAgentBase(IAgentConversation, ABC):\n    def __init__(self, conversation: IConversation):\n        self._conversation = conversation\n\n    @property\n    def conversation(self) -> IConversation:\n        return self._conversation\n\n    @conversation.setter\n    def conversation(self, value) -> None:\n        self._conversation = value\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/ToolAgentBase.py",
        "content": "```swarmauri/standard/agents/base/ToolAgentBase.py\nfrom abc import ABC\nfrom swarmauri.core.agents.IAgentToolkit import IAgentToolkit\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\n\n\nclass ToolAgentBase(IAgentToolkit, ABC):\n    \n    def __init__(self, toolkit: IToolkit):\n        self._toolkit = toolkit\n\n    @property\n    def toolkit(self) -> IToolkit:\n        return self._toolkit\n    \n    @toolkit.setter\n    def toolkit(self, value) -> None:\n        self._toolkit = value        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/AgentBase.py",
        "content": "```swarmauri/standard/agents/base/AgentBase.py\nfrom typing import Any, Optional\nfrom abc import ABC\nfrom swarmauri.core.agents.IAgent import IAgent\nfrom swarmauri.core.models.IModel import IModel\n\n\n\nclass AgentBase(IAgent, ABC):\n    def __init__(self, model: IModel):\n        self._model = model\n\n    @property\n    def model(self) -> IModel:\n        return self._model\n    \n    @model.setter\n    def model(self, value) -> None:\n        self._model = value        \n\n    def exec(self, input_str: Optional[Any]) -> Any:\n        raise NotImplementedError('The `exec` function has not been implemeneted on this class.')\n    \n    def __getattr__(self, name):\n        # Example of transforming attribute name from simplified to internal naming convention\n        internal_name = f\"_{name}\"\n        if internal_name in self.__dict__:\n            return self.__dict__[internal_name]\n        raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n    \n    def __setattr__(self, name, value):\n        # Direct assignment to the __dict__ to bypass any potential infinite recursion\n        # from setting attributes that do not explicitly exist.\n        object.__setattr__(self, name, value) \n        \n        \n    def __str__(self):\n        class_name = self.__class__.__name__\n        variables_str = \", \".join(f\"{k}={v}\" for k, v in self.__dict__.items())\n        return f\"<{class_name} {variables_str}>\"\n        \n    def __repr__(self):\n        class_name = self.__class__.__name__\n        variables_str = \", \".join(f\"{k}={v}\" for k, v in self.__dict__.items())\n        return f\"{class_name} ({variables_str})\"\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/VectorStoreAgentBase.py",
        "content": "```swarmauri/standard/agents/base/VectorStoreAgentBase.py\nfrom swarmauri.core.agents.IAgentVectorStore import IAgentVectorStore\nfrom swarmauri.core.vector_stores.IVectorStore import IVectorStore\n\n\nclass VectorStoreAgentBase(IAgentVectorStore):\n    def __init__(self, vector_store: IVectorStore):\n        self._vector_store = vector_store  # vector store initialization\n\n    @property\n    def vector_store(self) -> IVectorStore:\n        \"\"\"\n        Gets the vector store associated with this agent.\n        \n        Returns:\n            IVectorStore: The new vector store to be associated with the agent.\n        \"\"\"\n        return self._vector_store\n\n    @vector_store.setter\n    def vector_store(self, value: IVectorStore) -> None:\n        \"\"\"\n        Sets the vector store for this agent.\n\n        Args:\n            value (IVectorStore): The new vector store to be associated with the agent.\n        \"\"\"\n        self._vector_store = value\n    \n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/AgentRetrieveBase.py",
        "content": "```swarmauri/standard/agents/base/AgentRetrieveBase.py\nfrom abc import ABC\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.agents.IAgentRetrieve import IAgentRetrieve\n\nclass AgentRetrieveBase(IAgentRetrieve, ABC):\n\n    def __init__(self):\n        self._last_retrieved = []\n        \n    @property\n    def last_retrieved(self) -> List[IDocument]:\n        return self._last_retrieved\n\n    @last_retrieved.setter\n    def last_retrieved(self, value: List[IDocument]) -> None:\n        self._last_retrieved = value\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/base/SystemContextAgentBase.py",
        "content": "```swarmauri/standard/agents/base/SystemContextAgentBase.py\nfrom typing import Union\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\nfrom swarmauri.core.agents.IAgentSystemContext import IAgentSystemContext\n\n\nclass SystemContextAgentBase(IAgentSystemContext):\n    def __init__(self, system_context: Union[SystemMessage, str]):\n        if isinstance(system_context, SystemMessage):\n            self._system_context\n        else:    \n            self._system_context = SystemMessage(system_context)\n\n    @property\n    def system_context(self) -> SystemMessage:\n        return self._system_context\n\n    @system_context.setter\n    def system_context(self, value: Union[SystemMessage, str]) -> None:\n        if isinstance(value, SystemMessage):\n            self._system_context\n        else:    \n            self._system_context = SystemMessage(value)\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/__init__.py",
        "content": "```swarmauri/standard/agents/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/ToolAgent.py",
        "content": "```swarmauri/standard/agents/concrete/ToolAgent.py\nfrom typing import Any, Optional, Union, Dict\nimport json\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\nfrom swarmauri.core.conversations.IConversation import IConversation\nfrom swarmauri.core.messages import IMessage\n\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.ToolAgentBase import ToolAgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage, FunctionMessage\n\n\nclass ToolAgent(AgentBase, ConversationAgentBase, ToolAgentBase):\n    def __init__(self, \n                 model: IModel, \n                 conversation: IConversation, \n                 toolkit: IToolkit):\n        AgentBase.__init__(self, model=model)\n        ConversationAgentBase.__init__(self, conversation=conversation)\n        ToolAgentBase.__init__(self, toolkit=toolkit)\n\n    def exec(self, input_data: Union[str, IMessage],  model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n        toolkit = self.toolkit\n        \n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        # Add the human message to the conversation\n        conversation.add_message(human_message)\n\n            \n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_messages()\n        \n        prediction = model.predict(messages=messages, \n                                   tools=toolkit.tools, \n                                   tool_choice=\"auto\", \n                                   **model_kwargs)\n        \n        prediction_message = prediction.choices[0].message\n        \n        agent_response = prediction_message.content\n        \n        agent_message = AgentMessage(content=prediction_message.content, \n                                     tool_calls=prediction_message.tool_calls)\n        conversation.add_message(agent_message)\n        \n        tool_calls = prediction.choices[0].message.tool_calls\n        if tool_calls:\n        \n            for tool_call in tool_calls:\n                func_name = tool_call.function.name\n                \n                func_call = toolkit.get_tool_by_name(func_name)\n                func_args = json.loads(tool_call.function.arguments)\n                func_result = func_call(**func_args)\n                \n                func_message = FunctionMessage(func_result, \n                                               name=func_name, \n                                               tool_call_id=tool_call.id)\n                conversation.add_message(func_message)\n            \n            \n            messages = conversation.as_messages()\n            rag_prediction = model.predict(messages=messages, \n                                           tools=toolkit.tools, \n                                           tool_choice=\"none\",\n                                           **model_kwargs)\n            \n            prediction_message = rag_prediction.choices[0].message\n            \n            agent_response = prediction_message.content\n            agent_message = AgentMessage(agent_response)\n            conversation.add_message(agent_message)\n            prediction = rag_prediction\n            \n        return agent_response \n    \n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/ChatSwarmAgent.py",
        "content": "```swarmauri/standard/agents/concrete/ChatSwarmAgent.py\nfrom typing import Any, Optional, Union, Dict\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.messages import IMessage\nfrom swarmauri.core.conversations import IConversation\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage\n\nclass ChatSwarmAgent(AgentBase, ConversationAgentBase, NamedAgentBase):\n    def __init__(self, name: str, model: IModel, conversation: IConversation):\n        AgentBase.__init__(self, model=model)\n        ConversationAgentBase.__init__(self, conversation=conversation)\n        NamedAgentBase.__init__(self, name=name)\n\n    def exec(self, input_data: Union[str, IMessage], model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        # Add the human message to the conversation\n        conversation.add_message(human_message)\n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_messages()\n        if model_kwargs:\n            prediction = model.predict(messages=messages, **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n        # Create an AgentMessage instance with the model's response and update the conversation\n        agent_message = AgentMessage(prediction)\n        conversation.add_message(agent_message)\n        \n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/SimpleConversationAgent.py",
        "content": "```swarmauri/standard/agents/concrete/SimpleConversationAgent.py\nfrom typing import Any, Optional, Dict\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage\n\nclass SimpleConversationAgent(AgentBase, ConversationAgentBase, NamedAgentBase):\n    def __init__(self, model: IModel, conversation: IConversation, name: str):\n        AgentBase.__init__(self, model=model)\n        ConversationAgentBase.__init__(self, conversation=conversation)\n        NamedAgentBase.__init__(self, name=str)\n\n    def exec(self, \n        input_str: Optional[str] = None,\n        model_kwargs: Optional[Dict] = {}\n        ) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Construct a new human message (for example purposes)\n        if input_str:\n            human_message = HumanMessage(input_str)\n            conversation.add_message(human_message)\n        \n        messages = conversation.as_messages()\n        prediction = model.predict(messages=messages, **model_kwargs)\n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/MultiPartyChatSwarmAgent.py",
        "content": "```swarmauri/standard/agents/concrete/MultiPartyChatSwarmAgent.py\nfrom typing import Any, Optional, Union, Dict\n\n\nfrom swarmauri.standard.conversations.concrete.SharedConversation import SharedConversation\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage\n\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.messages import IMessage\n\n\nclass MultiPartyChatSwarmAgent(AgentBase, ConversationAgentBase, NamedAgentBase):\n    def __init__(self, name: str, model: IModel, conversation: SharedConversation):\n        AgentBase.__init__(self, model=model)\n        ConversationAgentBase.__init__(self, conversation=conversation)\n        NamedAgentBase.__init__(self, name=name)\n\n    def exec(self, input_data: Union[str, IMessage] = \"\", model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        if input_data != \"\":\n            # we add the sender's name as the id so we can keep track of who said what in the conversation\n            conversation.add_message(human_message, sender_id=self.name)\n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_messages()\n\n        \n        if model_kwargs:\n            prediction = model.predict(messages=messages, **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n        # Create an AgentMessage instance with the model's response and update the conversation\n        if prediction != '':\n            agent_message = AgentMessage(prediction)\n            conversation.add_message(agent_message, sender_id=self.name)\n        \n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/MultiPartyToolAgent.py",
        "content": "```swarmauri/standard/agents/concrete/MultiPartyToolAgent.py\nfrom typing import Any, Optional, Union, Dict\nimport json\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.toolkits.IToolkit import IToolkit\nfrom swarmauri.standard.conversations.concrete.SharedConversation import SharedConversation\nfrom swarmauri.core.messages import IMessage\n\nfrom swarmauri.standard.agents.base.ToolAgentBase import ToolAgentBase\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\nfrom swarmauri.standard.messages.concrete import HumanMessage, AgentMessage, FunctionMessage\n\n\nclass MultiPartyToolAgent(AgentBase, ConversationAgentBase, NamedAgentBase, ToolAgentBase):\n    def __init__(self, \n                 model: IModel, \n                 conversation: SharedConversation, \n                 toolkit: IToolkit,\n                 name: str):\n        AgentBase.__init__(self, model=model)\n        ConversationAgentBase.__init__(self, conversation=conversation)\n        NamedAgentBase.__init__(self, name=name)\n        ToolAgentBase.__init__(self, toolkit=toolkit)\n        \n\n    def exec(self, input_data: Union[str, IMessage], model_kwargs: Optional[Dict] = {}) -> Any:\n        conversation = self.conversation\n        model = self.model\n        toolkit = self.toolkit\n        \n\n        # Check if the input is a string, then wrap it in a HumanMessage\n        if isinstance(input_data, str):\n            human_message = HumanMessage(input_data)\n        elif isinstance(input_data, IMessage):\n            human_message = input_data\n        else:\n            raise TypeError(\"Input data must be a string or an instance of Message.\")\n\n        if input_data != \"\":\n            # we add the sender's name as the id so we can keep track of who said what in the conversation\n            conversation.add_message(human_message, sender_id=self.name) \n            \n        \n        # Retrieve the conversation history and predict a response\n        messages = conversation.as_messages()\n        \n\n        if model_kwargs:\n            prediction = model.predict(messages=messages, \n                                   tools=toolkit.tools, \n                                   tool_choice=\"auto\",\n                                   **model_kwargs)\n        else:\n            prediction = model.predict(messages=messages)\n        \n        \n        prediction_message = prediction.choices[0].message\n        agent_response = prediction_message.content\n        \n        agent_message = AgentMessage(content=prediction_message.content, \n                                     tool_calls=prediction_message.tool_calls)\n        conversation.add_message(agent_message, sender_id=self.name)\n        \n        tool_calls = prediction.choices[0].message.tool_calls\n        if tool_calls:\n        \n            for tool_call in tool_calls:\n                func_name = tool_call.function.name\n                \n                func_call = toolkit.get_tool_by_name(func_name)\n                func_args = json.loads(tool_call.function.arguments)\n                func_result = func_call(**func_args)\n                \n                func_message = FunctionMessage(func_result, \n                                               name=func_name, \n                                               tool_call_id=tool_call.id)\n                conversation.add_message(func_message, sender_id=self.name)\n            \n            \n            messages = conversation.as_dict()\n            rag_prediction = model.predict(messages=messages, \n                                           tools=toolkit.tools, \n                                           tool_choice=\"none\")\n            \n            prediction_message = rag_prediction.choices[0].message\n            \n            agent_response = prediction_message.content\n            if agent_response != \"\":\n                agent_message = AgentMessage(agent_response)\n                conversation.add_message(agent_message, sender_id=self.name)\n            prediction = rag_prediction\n            \n        return agent_response \n    \n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/RagAgent.py",
        "content": "```swarmauri/standard/agents/concrete/RagAgent.py\nfrom typing import Any, Optional, Union, Dict\nfrom swarmauri.core.messages import IMessage\nfrom swarmauri.core.models.IModel import IModel\n\nfrom swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\nfrom swarmauri.standard.agents.base.AgentRetrieveBase import AgentRetrieveBase\nfrom swarmauri.standard.agents.base.ConversationAgentBase import ConversationAgentBase\nfrom swarmauri.standard.agents.base.NamedAgentBase import NamedAgentBase\nfrom swarmauri.standard.agents.base.VectorStoreAgentBase import VectorStoreAgentBase\nfrom swarmauri.standard.agents.base.SystemContextAgentBase import SystemContextAgentBase\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\n\nfrom swarmauri.standard.messages.concrete import (HumanMessage, \n                                                  SystemMessage,\n                                                  AgentMessage)\n\n\nclass RagAgent(AgentBase, \n    AgentRetrieveBase,\n    ConversationAgentBase, \n    NamedAgentBase, \n    SystemContextAgentBase, \n    VectorStoreAgentBase):\n    \"\"\"\n    RagAgent (Retriever-And-Generator Agent) extends DocumentAgentBase,\n    specialized in retrieving documents based on input queries and generating responses.\n    \"\"\"\n\n    def __init__(self, name: str, \n            system_context: Union[SystemMessage, str], \n            model: IModel, \n            conversation: SystemContextBase, \n            vector_store: VectorDocumentStoreRetrieveBase):\n        AgentBase.__init__(self, model=model)\n        AgentRetrieveBase.__init__(self)\n        ConversationAgentBase.__init__(self, conversation=conversation)\n        NamedAgentBase.__init__(self, name=name)\n        SystemContextAgentBase.__init__(self, system_context=system_context)\n        VectorStoreAgentBase.__init__(self, vector_store=vector_store)\n\n    def _create_preamble_context(self):\n        substr = self.system_context.content\n        substr += '\\n\\n'\n        substr += '\\n'.join([doc.content for doc in self.last_retrieved])\n        return substr\n\n    def _create_post_context(self):\n        substr = '\\n'.join([doc.content for doc in self.last_retrieved])\n        substr += '\\n\\n'\n        substr += self.system_context.content\n        return substr\n\n    def exec(self, \n             input_data: Union[str, IMessage], \n             top_k: int = 5, \n             preamble: bool = True,\n             fixed: bool = False,\n             model_kwargs: Optional[Dict] = {}\n             ) -> Any:\n        try:\n            conversation = self.conversation\n            model = self.model\n\n            # Check if the input is a string, then wrap it in a HumanMessage\n            if isinstance(input_data, str):\n                human_message = HumanMessage(input_data)\n            elif isinstance(input_data, IMessage):\n                human_message = input_data\n            else:\n                raise TypeError(\"Input data must be a string or an instance of Message.\")\n            \n            # Add the human message to the conversation\n            conversation.add_message(human_message)\n\n            # Retrieval and set new substr for system context\n            if top_k > 0:\n                self.last_retrieved = self.vector_store.retrieve(query=input_data, top_k=top_k)\n\n                if preamble:\n                    substr = self._create_preamble_context()\n                else:\n                    substr = self._create_post_context()\n\n            else:\n                if fixed:\n                    if preamble:\n                        substr = self._create_preamble_context()\n                    else:\n                        substr = self._create_post_context()\n                else:\n                    substr = self.system_context.content\n                    self.last_retrieved = []\n                \n                \n\n            \n            # Use substr to set system context\n            system_context = SystemMessage(substr)\n            conversation.system_context = system_context\n            \n\n            # Retrieve the conversation history and predict a response\n            messages = conversation.as_messages()\n            if model_kwargs:\n                prediction = model.predict(messages=messages, **model_kwargs)\n            else:\n                prediction = model.predict(messages=messages)\n                \n            # Create an AgentMessage instance with the model's response and update the conversation\n            agent_message = AgentMessage(prediction)\n            conversation.add_message(agent_message)\n            \n            return prediction\n        except Exception as e:\n            print(f\"RagAgent error: {e}\")\n            raise e\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agents/concrete/QAAgent.py",
        "content": "```swarmauri/standard/agents/concrete/QAAgent.py\nfrom typing import Any, Optional\n\nfrom swarmauri.core.models.IModel import IModel\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nfrom swarmauri.standard.agents.base.AgentBase import AgentBase\n\nclass QAAgent(AgentBase):\n    def __init__(self, model: IModel):\n        AgentBase.__init__(self, model=model)\n\n    def exec(self, input_str: Optional[str] = None) -> Any:\n        model = self.model\n        prediction = model.predict(input_str)\n        \n        return prediction\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/__init__.py",
        "content": "```swarmauri/standard/utils/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/load_documents_from_json.py",
        "content": "```swarmauri/standard/utils/load_documents_from_json.py\nimport json\nfrom typing import List\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\n\ndef load_documents_from_json_file(json_file_path):\n    documents = []\n    with open(json_file_path, 'r') as f:\n        data = json.load(f)\n\n    documents = [\n        EmbeddedDocument(id=str(_), \n        content=doc['content'], \n        metadata={\"document_name\": doc['document_name']}) \n        for _, doc in enumerate(data) if doc['content']\n        ]\n\n    return documents\n\ndef load_documents_from_json(json):\n    documents = []\n    data = json.loads(json)\n    documents = [\n        EmbeddedDocument(id=str(_), \n        content=doc['content'], \n        metadata={\"document_name\": doc['document_name']}) \n        for _, doc in enumerate(data) if doc['content']\n        ]\n    return documents\n\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/get_class_hash.py",
        "content": "```swarmauri/standard/utils/get_class_hash.py\nimport hashlib\nimport inspect\n\ndef get_class_hash(cls):\n    \"\"\"\n    Generates a unique hash value for a given class.\n\n    This function uses the built-in `hashlib` and `inspect` modules to create a hash value based on the class' methods\n    and properties. The members of the class are first sorted to ensure a consistent order, and then the hash object is\n    updated with each member's name and signature.\n\n    Parameters:\n    - cls (type): The class object to calculate the hash for.\n\n    Returns:\n    - str: The generated hexadecimal hash value.\n    \"\"\"\n    hash_obj = hashlib.sha256()\n\n    # Get the list of methods and properties of the class\n    members = inspect.getmembers(cls, predicate=inspect.isfunction)\n    members += inspect.getmembers(cls, predicate=inspect.isdatadescriptor)\n\n    # Sort members to ensure consistent order\n    members.sort()\n\n    # Update the hash with each member's name and signature\n    for name, member in members:\n        hash_obj.update(name.encode('utf-8'))\n        if inspect.isfunction(member):\n            sig = inspect.signature(member)\n            hash_obj.update(str(sig).encode('utf-8'))\n\n    # Return the hexadecimal digest of the hash\n    return hash_obj.hexdigest()\n\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/sql_log.py",
        "content": "```swarmauri/standard/utils/sql_log.py\nimport sqlite3\nfrom datetime import datetime\nimport asyncio\n\n\ndef sql_log(self, db_path: str, conversation_id, model_name, prompt, response, start_datetime, end_datetime):\n    try:\n        duration = (end_datetime - start_datetime).total_seconds()\n        start_datetime = start_datetime.isoformat()\n        end_datetime = end_datetime.isoformat()\n        conversation_id = conversation_id\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        cursor.execute('''CREATE TABLE IF NOT EXISTS conversations\n                        (id INTEGER PRIMARY KEY AUTOINCREMENT, \n                        conversation_id TEXT, \n                        model_name TEXT, \n                        prompt TEXT, \n                        response TEXT, \n                        start_datetime TEXT, \n                        end_datetime TEXT,\n                        duration NUMERIC)''')\n        cursor.execute('''INSERT INTO conversations (\n                        conversation_id, \n                        model_name, \n                        prompt, \n                        response, \n                        start_datetime, \n                        end_datetime,\n                        duration) VALUES (?, ?, ?, ?, ?, ?, ?)''', \n                       (conversation_id, \n                        model_name, \n                        prompt, \n                        response, \n                        start_datetime, \n                        end_datetime, \n                        duration))\n        conn.commit()\n        conn.close()\n    except:\n        raise\n\n\n\ndef sql_log_decorator(func):\n    async def wrapper(self, *args, **kwargs):\n        start_datetime = datetime.now()\n        try:\n            # Execute the function\n            result = await func(self, *args, **kwargs)\n        except Exception as e:\n            # Handle errors within the decorated function\n            self.agent.conversation._history.pop(0)\n            print(f\"chatbot_function error: {e}\")\n            return \"\", [], kwargs['history']  \n\n        end_datetime = datetime.now()\n        \n        # SQL logging\n        # Unpacking the history and other required parameters from kwargs if they were used\n        history = kwargs.get('history', [])\n        message = kwargs.get('message', '')\n        response = result[1]  # Assuming the response is the second item in the returned tuple\n        model_name = kwargs.get('model_name', '')\n        conversation_id = str(self.agent.conversation.id)\n        sql_log(conversation_id, model_name, message, response, start_datetime, end_datetime)\n        return result\n    return wrapper\n\n\nclass SqlLogMeta(type):\n    def __new__(cls, name, bases, dct):\n        for key, value in dct.items():\n            if callable(value) and not key.startswith('__'):\n                dct[key] = sql_log(value)\n        return super().__new__(cls, name, bases, dct)\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/memoize.py",
        "content": "```swarmauri/standard/utils/memoize.py\ndef memoize(func):\n    cache = {}\n    def memoized_func(*args):\n        if args in cache:\n            return cache[args]\n        result = func(*args)\n        cache[args] = result\n        return result\n    return memoized_func\n    \nclass MemoizingMeta(type):\n    def __new__(cls, name, bases, dct):\n        for key, value in dct.items():\n            if callable(value) and not key.startswith('__'):\n                dct[key] = memoize(value)\n        return super().__new__(cls, name, bases, dct)\n\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/apply_metaclass.py",
        "content": "```swarmauri/standard/utils/apply_metaclass.py\ndef apply_metaclass_to_cls(cls, metaclass):\n    # Create a new class using the metaclass, with the same name, bases, and attributes as the original class\n    new_class = metaclass(cls.__name__, cls.__bases__, dict(cls.__dict__))\n    return new_class\n\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/decorate.py",
        "content": "```swarmauri/standard/utils/decorate.py\ndef decorate_cls(cls, decorator_fn):\n    import types\n    for attr_name in dir(cls):\n        attr = getattr(cls, attr_name)\n        if isinstance(attr, types.FunctionType):\n            setattr(cls, attr_name, decorator_fn(attr))\n    return cls\n\ndef decorate_instance(instance, decorator_fn):\n    import types\n    for attr_name in dir(instance):\n        attr = getattr(instance, attr_name)\n        if isinstance(attr, types.MethodType):\n            setattr(instance, attr_name, decorator_fn(attr.__func__).__get__(instance))\n\ndef decorate_instance_method(instance, method_name, decorator_fn):\n    # Get the method from the instance\n    original_method = getattr(instance, method_name)\n    \n    # Decorate the method\n    decorated_method = decorator_fn(original_method)\n    \n    # Rebind the decorated method to the instance\n    setattr(instance, method_name, decorated_method.__get__(instance, instance.__class__))\n```"
    },
    {
        "document_name": "swarmauri/standard/utils/json_validator.py",
        "content": "```swarmauri/standard/utils/json_validator.py\n# swarmauri/standard/utils/json_validator.py\nimport json\nimport jsonschema\nfrom jsonschema import validate\n\ndef load_json_file(file_path: str) -> dict:\n    with open(file_path, 'r') as file:\n        return json.load(file)\n\ndef validate_json(data: dict, schema_file: str) -> bool:\n    schema = load_json_file(schema_file)\n    try:\n        validate(instance=data, schema=schema)\n    except jsonschema.exceptions.ValidationError as err:\n        print(f\"JSON validation error: {err.message}\")\n        return False\n    return True\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/__init__.py",
        "content": "```swarmauri/standard/conversations/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/base/__init__.py",
        "content": "```swarmauri/standard/conversations/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/base/ConversationBase.py",
        "content": "```swarmauri/standard/conversations/base/ConversationBase.py\nimport warnings\nimport uuid\nfrom abc import ABC\nfrom typing import List, Union\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.core.conversations.IConversation import IConversation\n\nclass ConversationBase(IConversation, ABC):\n    \"\"\"\n    Concrete implementation of IConversation, managing conversation history and operations.\n    \"\"\"\n    \n    def __init__(self):\n        self._history: List[IMessage] = []\n        self._id = uuid.uuid4()  # Assign a unique UUID to each instance\n\n    @property\n    def id(self) -> str:\n        return self._id\n\n    @id.setter\n    def id(self, value: str) -> None:\n        self._id = value\n\n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        return self._history\n    \n    def add_message(self, message: IMessage):\n        self._history.append(message)\n\n    def get_last(self) -> Union[IMessage, None]:\n        if self._history:\n            return self._history[-1]\n        return None\n\n    def clear_history(self):\n        self._history.clear()\n\n    def as_messages(self) -> List[dict]:\n        return [message.as_dict() for message in self.history]\n\n    def as_dict(self) -> List[dict]:\n        print('USE TO_DICT NOW')\n        warnings.warn(\"\"\"This function is deprecated and will be removed in a future version.\n            USE .to_dict() now\n            \"\"\",\n                  DeprecationWarning, stacklevel=2)\n        return [message.as_dict() for message in self.history]\n    \n    def to_dict(self) -> List[dict]:\n        # We will need to update this to enable the ability to export and import functions\n        # We need to use a new interface besides to_dict() that enables conversations\n        return [message.as_dict() for message in self.history]\n\n    @classmethod\n    def from_dict(cls, data):\n        #data.pop(\"type\", None)\n        #return cls(**data)\n        raise NotImplementedError('from_dict load not implemented on this class yet')\n\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/base/SystemContextBase.py",
        "content": "```swarmauri/standard/conversations/base/SystemContextBase.py\nfrom abc import ABC\nfrom typing import Optional, Union\nfrom swarmauri.core.conversations.ISystemContext import ISystemContext\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\nfrom swarmauri.standard.conversations.base.ConversationBase import ConversationBase\n\nclass SystemContextBase(ConversationBase, ISystemContext, ABC):\n    def __init__(self, *args, system_message_content: Optional[SystemMessage] = None):\n        ConversationBase.__init__(self)\n        # Automatically handle both string and SystemMessage types for initializing system context\n        self._system_context = None  # Initialize with None\n        if system_message_content:\n            self.system_context = system_message_content\n    \n    @property\n    def system_context(self) -> Union[SystemMessage, None]:\n        \"\"\"Get the system context message. Raises an error if it's not set.\"\"\"\n        if self._system_context is None:\n            raise ValueError(\"System context has not been set.\")\n        return self._system_context\n    \n    @system_context.setter\n    def system_context(self, new_system_message: Union[SystemMessage, str]) -> None:\n        \"\"\"\n        Set a new system context message. The new system message can be a string or \n        an instance of SystemMessage. If it's a string, it converts it to a SystemMessage.\n        \"\"\"\n        if isinstance(new_system_message, SystemMessage):\n            self._system_context = new_system_message\n        elif isinstance(new_system_message, str):\n            self._system_context = SystemMessage(new_system_message)\n        else:\n            raise ValueError(\"System context must be a string or a SystemMessage instance.\")\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/__init__.py",
        "content": "```swarmauri/standard/conversations/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/LimitedSizeConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/LimitedSizeConversation.py\nimport warnings\nfrom swarmauri.converastions.base.ConversationBase import ConversationBase\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.core.conversations.IMaxSize import IMaxSize\n\nclass LimitedSizeConversation(ConversationBase, IMaxSize):\n    def __init__(self, max_size: int):\n        super().__init__()\n        warnings.warn(\"\"\"LimitedSizeConversation is deprecating, use MaxSizeConversation\"\"\")\n        self._max_size = max_size\n        \n    @property\n    def max_size(self) -> int:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        return self._max_size\n    \n    @max_size.setter\n    def max_size(self, new_max_size: int) -> int:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        if new_max_size > 0:\n            self._max_size = int\n        else:\n            raise ValueError('Cannot set conversation size to 0.')\n\n\n    def add_message(self, message: IMessage):\n        \"\"\"Adds a message and ensures the conversation does not exceed the max size.\"\"\"\n        super().add_message(message)\n        self._enforce_max_size_limit()\n\n    def _enforce_max_size_limit(self):\n        \"\"\"\n        Enforces the maximum size limit of the conversation history.\n        If the current history size exceeds the maximum size, the oldest messages are removed.\n        We pop two messages (one for the user's prompt, one for the assistant's response)\n        \"\"\"\n        while len(self._history) > self.max_size:\n            \n            self._history.pop(0)\n            self._history.pop(0)\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/SimpleConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/SimpleConversation.py\nfrom typing import List, Union\nfrom ....core.messages.IMessage import IMessage\nfrom ..base.ConversationBase import ConversationBase\n\nclass SimpleConversation(ConversationBase):\n    \"\"\"\n    Concrete implementation of IConversation, managing conversation history and operations.\n    \"\"\"\n    \n    def __init__(self):\n       super().__init__()\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/SharedConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/SharedConversation.py\nimport inspect\nfrom threading import Lock\nfrom typing import Optional, Dict, List, Tuple\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.standard.conversations.base.ConversationBase import ConversationBase\nfrom swarmauri.standard.messages.concrete.HumanMessage import HumanMessage\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\n\nclass SharedConversation(ConversationBase):\n    \"\"\"\n    A thread-safe conversation class that supports individual system contexts for each SwarmAgent.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self._lock = Lock()  # A lock to ensure thread safety\n        self._agent_system_contexts: Dict[str, SystemMessage] = {}  # Store system contexts for each agent\n        self._history: List[Tuple[str, IMessage]] = []  # Stores tuples of (sender_id, IMessage)\n\n\n    @property\n    def history(self):\n        history = []\n        for each in self._history:\n            history.append((each[0], each[1]))\n        return history\n\n    def add_message(self, message: IMessage, sender_id: str):\n        with self._lock:\n            self._history.append((sender_id, message))\n\n    def reset_messages(self) -> None:\n        self._history = []\n        \n\n    def _get_caller_name(self) -> Optional[str]:\n        for frame_info in inspect.stack():\n            # Check each frame for an instance with a 'name' attribute in its local variables\n            local_variables = frame_info.frame.f_locals\n            for var_name, var_value in local_variables.items():\n                if hasattr(var_value, 'name'):\n                    # Found an instance with a 'name' attribute. Return its value.\n                    return getattr(var_value, 'name')\n        # No suitable caller found\n        return None\n\n    def as_dict(self) -> List[Dict]:\n        caller_name = self._get_caller_name()\n        history = []\n\n        with self._lock:\n            # If Caller is not one of the agents, then give history\n            if caller_name not in self._agent_system_contexts.keys():\n                for sender_id, message in self._history:\n                    history.append((sender_id, message.as_dict()))\n                \n                \n            else:\n                system_context = self.get_system_context(caller_name)\n                #print(caller_name, system_context, type(system_context))\n                if type(system_context) == str:\n                    history.append(SystemMessage(system_context).as_dict())\n                else:\n                    history.append(system_context.as_dict())\n                    \n                for sender_id, message in self._history:\n                    #print(caller_name, sender_id, message, type(message))\n                    if sender_id == caller_name:\n                        if message.__class__.__name__ == 'AgentMessage' or 'FunctionMessage':\n                            # The caller is the sender; treat as AgentMessage\n                            history.append(message.as_dict())\n                            \n                            # Print to see content that is empty.\n                            #if not message.content:\n                                #print('\\n\\t\\t\\t=>', message, message.content)\n                    else:\n                        if message.content:\n                            # The caller is not the sender; treat as HumanMessage\n                            history.append(HumanMessage(message.content).as_dict())\n        return history\n    \n    def get_last(self) -> IMessage:\n        with self._lock:\n            return super().get_last()\n\n\n    def clear_history(self):\n        with self._lock:\n            super().clear_history()\n\n\n        \n\n    def set_system_context(self, agent_id: str, context: SystemMessage):\n        \"\"\"\n        Sets the system context for a specific agent.\n\n        Args:\n            agent_id (str): Unique identifier for the agent.\n            context (SystemMessage): The context message to be set for the agent.\n        \"\"\"\n        with self._lock:\n            self._agent_system_contexts[agent_id] = context\n\n    def get_system_context(self, agent_id: str) -> Optional[SystemMessage]:\n        \"\"\"\n        Retrieves the system context for a specific agent.\n\n        Args:\n            agent_id (str): Unique identifier for the agent.\n\n        Returns:\n            Optional[SystemMessage]: The context message of the agent, or None if not found.\n        \"\"\"\n        return self._agent_system_contexts.get(agent_id, None)\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/LimitedSystemContextConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/LimitedSystemContextConversation.py\nimport warnings\nfrom typing import Optional, Union, List\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.core.conversations.IMaxSize import IMaxSize\nfrom swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\n\nclass LimitedSystemContextConversation(SystemContextBase, IMaxSize):\n    def __init__(self, max_size: int, system_message_content: Optional[SystemMessage] = None):\n        \"\"\"\n        Initializes the conversation with a system context message and a maximum history size.\n        \n        Parameters:\n            max_size (int): The maximum number of messages allowed in the conversation history.\n            system_message_content (Optional[str], optional): The initial system message content. Can be a string.\n        \"\"\"\n        warnings.warn(\"\"\"LimitedSystemContextConversation is deprecating, use MaxSystemContextConversation\"\"\")\n        SystemContextBase.__init__(self, system_message_content=system_message_content if system_message_content else \"\")  # Initialize SystemContext with a SystemMessage\n        self._max_size = max_size  # Set the maximum size\n    \n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        \n        \n        res = [] \n        res.append(self.system_context)\n        res.extend(self._history)\n        return res\n        \n        \n    @property\n    def max_size(self) -> int:\n        \"\"\"\n        Provides access to the max_size property.\n        \"\"\"\n        return self._max_size\n    \n    @max_size.setter\n    def max_size(self, new_max_size: int) -> None:\n        \"\"\"\n        Sets a new maximum size for the conversation history.\n        \"\"\"\n        if new_max_size <= 0:\n            raise ValueError(\"max_size must be greater than 0.\")\n        self._max_size = new_max_size\n\n    def add_message(self, message: IMessage):\n        \"\"\"\n        Adds a message to the conversation history and ensures history does not exceed the max size.\n        \"\"\"\n        if isinstance(message, SystemMessage):\n            raise ValueError(f\"System context cannot be set through this method on {self.__class_name__}.\")\n        else:\n            super().add_message(message)\n        self._enforce_max_size_limit()\n        \n    def _enforce_max_size_limit(self):\n        \"\"\"\n        Remove messages from the beginning of the conversation history if the limit is exceeded.\n        \"\"\"\n        while len(self._history) + 1 > self._max_size:\n            self._history.pop(0)\n\n    @property\n    def system_context(self) -> Union[SystemMessage, None]:\n        \"\"\"Get the system context message. Raises an error if it's not set.\"\"\"\n        if self._system_context is None:\n            raise ValueError(\"System context has not been set.\")\n        return self._system_context\n\n\n    @system_context.setter\n    def system_context(self, new_system_message: Union[SystemMessage, str]) -> None:\n        \"\"\"\n        Set a new system context message. The new system message can be a string or \n        an instance of SystemMessage. If it's a string, it converts it to a SystemMessage.\n        \"\"\"\n        if isinstance(new_system_message, SystemMessage):\n            self._system_context = new_system_message\n        elif isinstance(new_system_message, str):\n            self._system_context = SystemMessage(new_system_message)\n        else:\n            raise ValueError(\"System context must be a string or a SystemMessage instance.\")\n            \n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/MaxSizeConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/MaxSizeConversation.py\nfrom swarmauri.converastions.base.ConversationBase import ConversationBase\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.core.conversations.IMaxSize import IMaxSize\n\nclass MaxSizeConversation(ConversationBase, IMaxSize):\n    def __init__(self, max_size: int):\n        super().__init__()\n\n        self._max_size = max_size\n        \n    @property\n    def max_size(self) -> int:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        return self._max_size\n    \n    @max_size.setter\n    def max_size(self, new_max_size: int) -> int:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        if new_max_size > 0:\n            self._max_size = int\n        else:\n            raise ValueError('Cannot set conversation size to 0.')\n\n\n    def add_message(self, message: IMessage):\n        \"\"\"Adds a message and ensures the conversation does not exceed the max size.\"\"\"\n        super().add_message(message)\n        self._enforce_max_size_limit()\n\n    def _enforce_max_size_limit(self):\n        \"\"\"\n        Enforces the maximum size limit of the conversation history.\n        If the current history size exceeds the maximum size, the oldest messages are removed.\n        We pop two messages (one for the user's prompt, one for the assistant's response)\n        \"\"\"\n        while len(self._history) > self.max_size:\n            \n            self._history.pop(0)\n            self._history.pop(0)\n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/MaxSystemContextConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/MaxSystemContextConversation.py\nfrom typing import Optional, Union, List\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.core.conversations.IMaxSize import IMaxSize\nfrom swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\nfrom swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\nfrom swarmauri.standard.exceptions.concrete import IndexErrorWithContext\n\nclass MaxSystemContextConversation(SystemContextBase, IMaxSize):\n    def __init__(self, max_size: int, system_message_content: Optional[SystemMessage] = None):\n        \"\"\"\n        Initializes the conversation with a system context message and a maximum history size.\n        \n        Parameters:\n            max_size (int): The maximum number of messages allowed in the conversation history.\n            system_message_content (Optional[str], optional): The initial system message content. Can be a string.\n        \"\"\"\n        SystemContextBase.__init__(self, system_message_content=system_message_content if system_message_content else \"\")  # Initialize SystemContext with a SystemMessage\n        self._max_size = max_size  # Set the maximum size\n    \n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Provides read-only access to the conversation history.\n        \"\"\"\n        \n        \n        res = [] \n        res.append(self.system_context)\n        res.extend(self._history)\n        return res\n        \n        \n    @property\n    def max_size(self) -> int:\n        \"\"\"\n        Provides access to the max_size property.\n        \"\"\"\n        return self._max_size\n    \n    @max_size.setter\n    def max_size(self, new_max_size: int) -> None:\n        \"\"\"\n        Sets a new maximum size for the conversation history.\n        \"\"\"\n        if new_max_size <= 0:\n            raise ValueError(\"max_size must be greater than 0.\")\n        self._max_size = new_max_size\n\n    def add_message(self, message: IMessage):\n        \"\"\"\n        Adds a message to the conversation history and ensures history does not exceed the max size.\n        \"\"\"\n        if isinstance(message, SystemMessage):\n            raise ValueError(f\"System context cannot be set through this method on {self.__class_name__}.\")\n        else:\n            super().add_message(message)\n        self._enforce_max_size_limit()\n        \n    def _enforce_max_size_limit(self):\n        \"\"\"\n        Remove messages from the beginning of the conversation history if the limit is exceeded.\n        We add one to max_size to account for the system context message\n        \"\"\"\n        try:\n            while len(self._history) > self._max_size + 1:\n                self._history.pop(0)\n                self._history.pop(0)\n        except IndexError as e:\n            raise IndexErrorWithContext(e)\n\n\n    @property\n    def system_context(self) -> Union[SystemMessage, None]:\n        \"\"\"Get the system context message. Raises an error if it's not set.\"\"\"\n        if self._system_context is None:\n            raise ValueError(\"System context has not been set.\")\n        return self._system_context\n\n\n    @system_context.setter\n    def system_context(self, new_system_message: Union[SystemMessage, str]) -> None:\n        \"\"\"\n        Set a new system context message. The new system message can be a string or \n        an instance of SystemMessage. If it's a string, it converts it to a SystemMessage.\n        \"\"\"\n        if isinstance(new_system_message, SystemMessage):\n            self._system_context = new_system_message\n        elif isinstance(new_system_message, str):\n            self._system_context = SystemMessage(new_system_message)\n        else:\n            raise ValueError(\"System context must be a string or a SystemMessage instance.\")\n            \n```"
    },
    {
        "document_name": "swarmauri/standard/conversations/concrete/SessionCacheConversation.py",
        "content": "```swarmauri/standard/conversations/concrete/SessionCacheConversation.py\nfrom typing import Optional, Union, List\nfrom collections import deque\nfrom swarmauri.core.messages.IMessage import IMessage\nfrom swarmauri.core.conversations.IMaxSize import IMaxSize\nfrom swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\nfrom swarmauri.standard.messages.concrete import SystemMessage, AgentMessage, HumanMessage\nfrom swarmauri.standard.exceptions.concrete import IndexErrorWithContext\n\nclass SessionCacheConversation(SystemContextBase, IMaxSize):\n    def __init__(self, max_size: int = 2, \n        system_message_content: Optional[SystemMessage] = None, \n        session_cache_max_size: int = -1):\n        \"\"\"\n        Initializes the conversation with a system context message and a maximum history size. Also initializes the conversation with\n        a session cache with its own maximum size.\n\n        Parameters:\n            max_size (int): The maximum number of messages allowed in the conversation history.\n            system_message_content (Optional[str], optional): The initial system message content. Can be a string.\n            session_cache_max_size (int): The maximum number of messages allowed in the session cache.\n        \"\"\"\n        SystemContextBase.__init__(self, system_message_content=system_message_content if system_message_content else \"\")\n        self._max_size = max_size  # Set the maximum size\n        if session_cache_max_size:\n            self._session_cache_max_size = session_cache_max_size\n        else:\n            self._session_cache_max_size = self._max_size\n        self._history = []\n\n    @property\n    def session_cache_max_size(self) -> int:\n        return self._session_cache_max_size\n\n    @property\n    def max_size(self) -> int:\n        return self._max_size\n\n    @max_size.setter\n    def max_size(self, new_max_size: int) -> None:\n        if new_max_size <= 0:\n            raise ValueError(\"max_size must be greater than 0.\")\n        self._max_size = new_max_size\n\n    @session_cache_max_size.setter\n    def session_cache_max_size(self, new_max_cache_size: int) -> None:\n        if new_max_cache_size <= 0:\n            raise ValueError(\"session_cache_max_size must be greater than 0.\")\n        self._session_cache_max_size = new_max_cache_size\n\n    def add_message(self, message: IMessage):\n        \"\"\"\n        Adds a message to the conversation history and ensures history does not exceed the max size.\n        This only allows system context to be set through the system context method.\n        We are forcing the SystemContext to be a preamble only.\n        \"\"\"\n        if isinstance(message, SystemMessage):\n            raise ValueError(f\"System context cannot be set through this method on {self.__class_name__}.\")\n        else:\n            super().add_message(message)\n\n    @property\n    def history(self) -> List[IMessage]:\n        \"\"\"\n        Get the conversation history, ensuring it starts with a 'user' message and alternates correctly between 'user' and 'assistant' roles.\n        \"\"\"\n        res = []  # Start with an empty list to build the proper history\n\n        # Attempt to find the first 'user' message in the history.\n        user_start_index = -1\n        for index, message in enumerate(self._history):\n            if isinstance(message, HumanMessage):  # Identify user message\n                user_start_index = index\n                break\n\n        # If no 'user' message is found, just return the system context.\n        if user_start_index == -1:\n            return [self.system_context]\n\n        # Build history from the first 'user' message ensuring alternating roles.\n        res.append(self.system_context)\n        alternating = True\n        for message in self._history[user_start_index:user_start_index + 2 * self._max_size]:\n            if alternating and isinstance(message, HumanMessage) or not alternating and isinstance(message, AgentMessage):\n                res.append(message)\n                alternating = not alternating\n            elif not alternating and isinstance(message, HumanMessage):\n                # If we find two 'user' messages in a row when expecting an 'assistant' message, we skip this 'user' message.\n                continue\n            else:\n                # If there is no valid alternate message to append, break the loop\n                break\n\n        return res\n\n    def session_to_dict(self) -> List[dict]:\n        \"\"\"\n        Converts session messages to a list of dictionaries.\n        \"\"\"\n        return [message.as_dict() for message in self.session]\n\n    @property\n    def session(self) -> List[IMessage]:\n        return self._history[-self._session_cache_max_size:]\n\n    @property\n    def system_context(self) -> Union[SystemMessage, None]:\n        \"\"\"Get the system context message. Raises an error if it's not set.\"\"\"\n        if self._system_context is None:\n            raise ValueError(\"System context has not been set.\")\n        return self._system_context\n\n    @system_context.setter\n    def system_context(self, new_system_message: Union[SystemMessage, str]) -> None:\n        \"\"\"\n        Set a new system context message. The new system message can be a string or \n        an instance of SystemMessage. If it's a string, it converts it to a SystemMessage.\n        \"\"\"\n        if isinstance(new_system_message, SystemMessage):\n            self._system_context = new_system_message\n        elif isinstance(new_system_message, str):\n            self._system_context = SystemMessage(new_system_message)\n        else:\n            raise ValueError(\"System context must be a string or a SystemMessage instance.\")\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/__init__.py",
        "content": "```swarmauri/standard/documents/__init__.py\nfrom .concrete import *\nfrom .base import *\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/base/__init__.py",
        "content": "```swarmauri/standard/documents/base/__init__.py\nfrom .DocumentBase import DocumentBase\nfrom .EmbeddedBase import EmbeddedBase\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/base/EmbeddedBase.py",
        "content": "```swarmauri/standard/documents/base/EmbeddedBase.py\nfrom abc import ABC\nfrom typing import List, Any, Optional\nimport importlib\nfrom swarmauri.core.documents.IEmbed import IEmbed\nfrom swarmauri.standard.vectors.base.VectorBase import VectorBase\nfrom swarmauri.standard.documents.base.DocumentBase import DocumentBase\n\nclass EmbeddedBase(DocumentBase, IEmbed, ABC):\n    def __init__(self, id: str = \"\", content: str = \"\", metadata: dict = {}, embedding: VectorBase = None):\n        DocumentBase.__init__(self, id, content, metadata)\n        self._embedding = embedding\n        \n    @property\n    def embedding(self) -> VectorBase:\n        return self._embedding\n\n    @embedding.setter\n    def embedding(self, value: VectorBase) -> None:\n        self._embedding = value\n\n    def __str__(self):\n        return f\"EmbeddedDocument ID: {self.id}, Content: {self.content}, Metadata: {self.metadata}, embedding={self.embedding}\"\n\n    def __repr__(self):\n        return f\"EmbeddedDocument(id={self.id}, content={self.content}, metadata={self.metadata}, embedding={self.embedding})\"\n\n    def to_dict(self):\n        document_dict = super().to_dict()\n        document_dict.update({\n            \"type\": self.__class__.__name__,\n            \"embedding\": self.embedding.to_dict() if hasattr(self.embedding, 'to_dict') else self.embedding\n            })\n\n        return document_dict\n\n    @classmethod\n    def from_dict(cls, data):\n        vector_data = data.pop(\"embedding\", None)\n        if vector_data:\n            vector_type = vector_data.pop('type', None)\n            if vector_type:\n                module = importlib.import_module(f\"swarmauri.standard.vectors.concrete.{vector_type}\")\n                vector_class = getattr(module, vector_type)\n                vector = vector_class.from_dict(vector_data)\n            else:\n                vector = None\n        else:\n            vector = None \n        return cls(**data, embedding=vector)\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/base/DocumentBase.py",
        "content": "```swarmauri/standard/documents/base/DocumentBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nfrom swarmauri.core.documents.IDocument import IDocument\n\nclass DocumentBase(IDocument, ABC):\n    \n    def __init__(self, id: str = \"\", content: str = \"\", metadata: dict = {}):\n        self._id = id\n        self._content = content\n        self._metadata = metadata\n\n    @property\n    def id(self) -> str:\n        \"\"\"\n        Get the document's ID.\n        \"\"\"\n        return self._id\n\n    @id.setter\n    def id(self, value: str) -> None:\n        \"\"\"\n        Set the document's ID.\n        \"\"\"\n        self._id = value\n\n    @property\n    def content(self) -> str:\n        \"\"\"\n        Get the document's content.\n        \"\"\"\n        return self._content\n\n    @content.setter\n    def content(self, value: str) -> None:\n        \"\"\"\n        Set the document's content.\n        \"\"\"\n        if value:\n            self._content = value\n        else:\n            raise ValueError('Cannot create a document with no content.')\n\n    @property\n    def metadata(self) -> Dict:\n        \"\"\"\n        Get the document's metadata.\n        \"\"\"\n        return self._metadata\n\n    @metadata.setter\n    def metadata(self, value: Dict) -> None:\n        \"\"\"\n        Set the document's metadata.\n        \"\"\"\n        self._metadata = value\n\n    def __str__(self):\n        return f\"Document ID: {self.id}, Content: {self.content}, Metadata: {self.metadata}\"\n\n    def __repr__(self):\n        return f\"Document(id={self.id}, content={self.content}, metadata={self.metadata})\"\n\n    def to_dict(self):\n        return {'type': self.__class__.__name__,\n                'id': self.id, \n                'content': self.content, \n                'metadata': self.metadata}\n      \n    @classmethod\n    def from_dict(cls, data):\n        data.pop(\"type\", None)\n        return cls(**data)\n\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/concrete/__init__.py",
        "content": "```swarmauri/standard/documents/concrete/__init__.py\nfrom .Document import Document\nfrom .EmbeddedDocument import EmbeddedDocument\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/concrete/EmbeddedDocument.py",
        "content": "```swarmauri/standard/documents/concrete/EmbeddedDocument.py\nfrom typing import Optional, Any\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.documents.base.EmbeddedBase import EmbeddedBase\n\nclass EmbeddedDocument(EmbeddedBase):\n    def __init__(self, id,  content, metadata, embedding: Optional[IVector] = None):\n        EmbeddedBase.__init__(self, id=id, content=content, metadata=metadata, embedding=embedding)\n\n```"
    },
    {
        "document_name": "swarmauri/standard/documents/concrete/Document.py",
        "content": "```swarmauri/standard/documents/concrete/Document.py\nfrom swarmauri.standard.documents.base.DocumentBase import DocumentBase\n\nclass Document(DocumentBase):\n    pass\n    \n        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/__init__.py",
        "content": "```swarmauri/standard/messages/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/base/__init__.py",
        "content": "```swarmauri/standard/messages/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/base/MessageBase.py",
        "content": "```swarmauri/standard/messages/base/MessageBase.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.messages.IMessage import IMessage\n\nclass MessageBase(IMessage, ABC):\n    \n    @abstractmethod\n    def __init__(self, role: str, content: str):\n        self._role = role\n        self._content = content\n    \n    @property\n    def role(self) -> str:\n        return self._role\n    \n    @property\n    def content(self) -> str:\n        return self._content\n\n    \n    def as_dict(self) -> dict:\n        \"\"\"\n        Dynamically return a dictionary representation of the object,\n        including all properties.\n        \"\"\"\n        result_dict = {}\n        # Iterate over all attributes\n        for attr in dir(self):\n            # Skip private attributes and anything not considered a property\n            if attr.startswith(\"_\") or callable(getattr(self, attr)):\n                continue\n            result_dict[attr] = getattr(self, attr)\n            \n        return result_dict\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Return the string representation of the ConcreteMessage.\n        \"\"\"\n        return f\"{self.__class__.__name__}(role='{self.role}')\"\n    \n    def __getattr__(self, name):\n        \"\"\"\n        Return the value of the named attribute of the instance.\n        \"\"\"\n        try:\n            return self.__dict__[name]\n        except KeyError:\n            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n\n    \n    def __setattr__(self, name, value):\n        \"\"\"\n        Set the value of the named attribute of the instance.\n        \"\"\"\n        self.__dict__[name] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/__init__.py",
        "content": "```swarmauri/standard/messages/concrete/__init__.py\nfrom .HumanMessage import HumanMessage\nfrom .AgentMessage import AgentMessage\nfrom .FunctionMessage import FunctionMessage\nfrom .SystemMessage import SystemMessage\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/AgentMessage.py",
        "content": "```swarmauri/standard/messages/concrete/AgentMessage.py\nfrom typing import Optional, Any\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\n\nclass AgentMessage(MessageBase):\n    def __init__(self, content, tool_calls: Optional[Any] = None):\n        super().__init__(role='assistant', content=content)\n        if tool_calls:\n            self.tool_calls = tool_calls\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/HumanMessage.py",
        "content": "```swarmauri/standard/messages/concrete/HumanMessage.py\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\nclass HumanMessage(MessageBase):\n    \"\"\"\n    Represents a message created by a human user.\n\n    Extends the `Message` class to specifically represent messages input by human users in a conversational\n    interface. It contains the message content and assigns the type \"HumanMessage\" to distinguish it from\n    other types of messages.\n    \"\"\"\n\n    def __init__(self, content, name=None):\n        \"\"\"\n        Initializes a new instance of HumanMessage with specified content.\n\n        Args:\n            content (str): The text content of the human-created message.\n            name (str, optional): The name of the human sender.\n        \"\"\"\n        super().__init__(role='user', content=content)\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/FunctionMessage.py",
        "content": "```swarmauri/standard/messages/concrete/FunctionMessage.py\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\n\nclass FunctionMessage(MessageBase):\n    \"\"\"\n    Represents a message created by a human user.\n\n    This class extends the `Message` class to specifically represent messages that\n    are input by human users in a conversational interface. It contains the message\n    content and assigns the type \"HumanMessage\" to distinguish it from other types\n    of messages.\n\n    Attributes:\n        content (str): The text content of the message.\n\n    Methods:\n        display: Returns a dictionary representation of the message for display,\n                 tagging it with the role \"user\".\n    \"\"\"\n\n    def __init__(self, content, name, tool_call_id):\n        super().__init__(role='tool', content=content)\n        self.name = name\n        self.tool_call_id = tool_call_id\n    \n```"
    },
    {
        "document_name": "swarmauri/standard/messages/concrete/SystemMessage.py",
        "content": "```swarmauri/standard/messages/concrete/SystemMessage.py\nfrom swarmauri.standard.messages.base.MessageBase import MessageBase\n\nclass SystemMessage(MessageBase):\n    \"\"\"\n    SystemMessage class represents a message generated by the system. \n    \n    This type of message is used to communicate system-level information such as \n    errors, notifications, or updates to the user. Inherits from the Message base class.\n    \n    Attributes:\n        content (str): The content of the system message.\n    \"\"\"\n    \n    def __init__(self, content):\n        super().__init__(role='system', content=content)\n    \n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/__init__.py",
        "content": "```swarmauri/standard/parsers/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/base/__init__.py",
        "content": "```swarmauri/standard/parsers/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/__init__.py",
        "content": "```swarmauri/standard/parsers/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/CSVParser.py",
        "content": "```swarmauri/standard/parsers/concrete/CSVParser.py\nimport csv\nfrom io import StringIO\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass CSVParser(IParser):\n    \"\"\"\n    Concrete implementation of IParser for parsing CSV formatted text into Document instances.\n\n    The parser can handle input as a CSV formatted string or from a file, with each row\n    represented as a separate Document. Assumes the first row is the header which will\n    be used as keys for document metadata.\n    \"\"\"\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the given CSV data into a list of Document instances.\n\n        Parameters:\n        - data (Union[str, Any]): The input data to parse, either as a CSV string or file path.\n\n        Returns:\n        - List[IDocument]: A list of documents parsed from the CSV data.\n        \"\"\"\n        # Prepare an in-memory string buffer if the data is provided as a string\n        if isinstance(data, str):\n            data_stream = StringIO(data)\n        else:\n            raise ValueError(\"Data provided is not a valid CSV string\")\n\n        # Create a list to hold the parsed documents\n        documents: List[IDocument] = []\n\n        # Read CSV content row by row\n        reader = csv.DictReader(data_stream)\n        for row in reader:\n            # Each row represents a document, where the column headers are metadata fields\n            document = Document(doc_id=row.get('id', None), \n                                        content=row.get('content', ''), \n                                        metadata=row)\n            documents.append(document)\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/EntityRecognitionParser.py",
        "content": "```swarmauri/standard/parsers/concrete/EntityRecognitionParser.py\nimport spacy\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass EntityRecognitionParser(IParser):\n    \"\"\"\n    EntityRecognitionParser leverages NER capabilities to parse text and \n    extract entities with their respective tags such as PERSON, LOCATION, ORGANIZATION, etc.\n    \"\"\"\n\n    def __init__(self):\n        # Load a SpaCy model. The small model is used for demonstration; larger models provide improved accuracy.\n        self.nlp = spacy.load(\"en_core_web_sm\")\n    \n    def parse(self, text: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input text, identifies entities, and returns a list of documents with entities tagged.\n\n        Parameters:\n        - text (Union[str, Any]): The input text to be parsed and analyzed for entities.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances representing the identified entities in the text.\n        \"\"\"\n        # Ensure the input is a string type before processing\n        if not isinstance(text, str):\n            text = str(text)\n        \n        # Apply the NER model\n        doc = self.nlp(text)\n\n        # Compile identified entities into documents\n        entities_docs = []\n        for ent in doc.ents:\n            # Create a document for each entity with metadata carrying entity type\n            entity_doc = Document(doc_id=ent.text, content=ent.text, metadata={\"entity_type\": ent.label_})\n            entities_docs.append(entity_doc)\n        \n        return entities_docs\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/HtmlTagStripParser.py",
        "content": "```swarmauri/standard/parsers/concrete/HtmlTagStripParser.py\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\nimport html\nimport re\n\nclass HTMLTagStripParser(IParser):\n    \"\"\"\n    A concrete parser that removes HTML tags and unescapes HTML content,\n    leaving plain text.\n    \"\"\"\n\n    def parse(self, data):\n        \"\"\"\n        Strips HTML tags from input data and unescapes HTML content.\n        \n        Args:\n            data (str): The HTML content to be parsed.\n        \n        Returns:\n            List[IDocument]: A list containing a single IDocument instance of the stripped text.\n        \"\"\"\n\n        # Ensure that input is a string\n        if not isinstance(data, str):\n            raise ValueError(\"HTMLTagStripParser expects input data to be of type str.\")\n        \n        # Remove HTML tags\n        text = re.sub('<[^<]+?>', '', data)  # Matches anything in < > and replaces it with empty string\n        \n        # Unescape HTML entities\n        text = html.unescape(text)\n\n        # Wrap the cleaned text into a Document and return it in a list\n        document = Document(doc_id=\"1\", content=text, metadata={\"original_length\": len(data)})\n        \n        return [document]\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/KeywordExtractorParser.py",
        "content": "```swarmauri/standard/parsers/concrete/KeywordExtractorParser.py\nimport yake\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass KeywordExtractorParser(IParser):\n    \"\"\"\n    Extracts keywords from text using the YAKE keyword extraction library.\n    \"\"\"\n\n    def __init__(self, lang: str = 'en', num_keywords: int = 10):\n        \"\"\"\n        Initialize the keyword extractor with specified language and number of keywords.\n\n        Parameters:\n        - lang (str): The language of the text for keyword extraction. Default is 'en' for English.\n        - num_keywords (int): The number of top keywords to extract. Default is 10.\n        \"\"\"\n        self.lang = lang\n        self.num_keywords = num_keywords\n        # Initialize YAKE extractor with specified parameters\n        self.kw_extractor = yake.KeywordExtractor(lan=lang, n=3, dedupLim=0.9, dedupFunc='seqm', windowsSize=1, top=num_keywords, features=None)\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Extract keywords from input text and return as list of IDocument instances containing keyword information.\n\n        Parameters:\n        - data (Union[str, Any]): The input text from which to extract keywords.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances, each containing information about an extracted keyword.\n        \"\"\"\n        # Ensure data is in string format for analysis\n        text = str(data) if not isinstance(data, str) else data\n\n        # Extract keywords using YAKE\n        keywords = self.kw_extractor.extract_keywords(text)\n\n        # Create Document instances for each keyword\n        documents = [Document(doc_id=str(index), content=keyword, metadata={\"score\": score}) for index, (keyword, score) in enumerate(keywords)]\n        \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/MarkdownParser.py",
        "content": "```swarmauri/standard/parsers/concrete/MarkdownParser.py\nimport re\nfrom markdown import markdown\nfrom bs4 import BeautifulSoup\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass MarkdownParser(IParser):\n    \"\"\"\n    A concrete implementation of the IParser interface that parses Markdown text.\n    \n    This parser takes Markdown formatted text, converts it to HTML using Python's\n    markdown library, and then uses BeautifulSoup to extract plain text content. The\n    resulting plain text is then wrapped into IDocument instances.\n    \"\"\"\n    \n    def parse(self, data: str) -> list[IDocument]:\n        \"\"\"\n        Parses the input Markdown data into a list of IDocument instances.\n        \n        Parameters:\n        - data (str): The input Markdown formatted text to be parsed.\n        \n        Returns:\n        - list[IDocument]: A list containing a single IDocument instance with the parsed text content.\n        \"\"\"\n        # Convert Markdown to HTML\n        html_content = markdown(data)\n        \n        # Use BeautifulSoup to extract text content from HTML\n        soup = BeautifulSoup(html_content, features=\"html.parser\")\n        plain_text = soup.get_text(separator=\" \", strip=True)\n        \n        # Generate a document ID\n        doc_id = \"1\"  # For this implementation, a simple fixed ID is used. \n                      # A more complex system might generate unique IDs for each piece of text.\n\n        # Create and return a list containing the single extracted plain text document\n        document = Document(doc_id=doc_id, content=plain_text, metadata={\"source_format\": \"markdown\"})\n        return [document]\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/OpenAPISpecParser.py",
        "content": "```swarmauri/standard/parsers/concrete/OpenAPISpecParser.py\nfrom typing import List, Union, Any\nimport yaml\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass OpenAPISpecParser(IParser):\n    \"\"\"\n    A parser that processes OpenAPI Specification files (YAML or JSON format)\n    and extracts information into structured Document instances. \n    This is useful for building documentation, APIs inventory, or analyzing the API specification.\n    \"\"\"\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses an OpenAPI Specification from a YAML or JSON string into a list of Document instances.\n\n        Parameters:\n        - data (Union[str, Any]): The OpenAPI specification in YAML or JSON format as a string.\n\n        Returns:\n        - List[IDocument]: A list of Document instances representing the parsed information.\n        \"\"\"\n        try:\n            # Load the OpenAPI spec into a Python dictionary\n            spec_dict = yaml.safe_load(data)\n        except yaml.YAMLError as e:\n            raise ValueError(f\"Failed to parse the OpenAPI specification: {e}\")\n        \n        documents = []\n        # Iterate over paths in the OpenAPI spec to extract endpoint information\n        for path, path_item in spec_dict.get(\"paths\", {}).items():\n            for method, operation in path_item.items():\n                # Create a Document instance for each operation\n                doc_id = f\"{path}_{method}\"\n                content = yaml.dump(operation)\n                metadata = {\n                    \"path\": path,\n                    \"method\": method.upper(),\n                    \"operationId\": operation.get(\"operationId\", \"\")\n                }\n                document = Document(doc_id=doc_id, content=content, metadata=metadata)\n                documents.append(document)\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/PhoneNumberExtractorParser.py",
        "content": "```swarmauri/standard/parsers/concrete/PhoneNumberExtractorParser.py\nimport re\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass PhoneNumberExtractorParser(IParser):\n    \"\"\"\n    A parser that extracts phone numbers from the input text.\n    Utilizes regular expressions to identify phone numbers in various formats.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the PhoneNumberExtractorParser.\n        \"\"\"\n        super().__init__()\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input data, looking for phone numbers employing a regular expression.\n        Each phone number found is contained in a separate IDocument instance.\n\n        Parameters:\n        - data (Union[str, Any]): The input text to be parsed for phone numbers.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances, each containing a phone number.\n        \"\"\"\n        # Define a regular expression for phone numbers.\n        # This is a simple example and might not capture all phone number formats accurately.\n        phone_regex = r'\\+?\\d[\\d -]{8,}\\d'\n\n        # Find all occurrences of phone numbers in the text\n        phone_numbers = re.findall(phone_regex, str(data))\n\n        # Create a new IDocument for each phone number found\n        documents = [Document(doc_id=str(index), content=phone_number, metadata={}) for index, phone_number in enumerate(phone_numbers)]\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/PythonParser.py",
        "content": "```swarmauri/standard/parsers/concrete/PythonParser.py\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\nimport ast\nimport uuid\n\nclass PythonParser(IParser):\n    \"\"\"\n    A parser that processes Python source code to extract structural elements\n    such as functions, classes, and their docstrings.\n    \n    This parser utilizes the `ast` module to parse the Python code into an abstract syntax tree (AST)\n    and then walks the tree to extract relevant information.\n    \"\"\"\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the given Python source code to extract structural elements.\n\n        Args:\n            data (Union[str, Any]): The input Python source code as a string.\n\n        Returns:\n            List[IDocument]: A list of IDocument objects, each representing a structural element \n                             extracted from the code along with its metadata.\n        \"\"\"\n        if not isinstance(data, str):\n            raise ValueError(\"PythonParser expects a string input.\")\n        \n        documents = []\n        tree = ast.parse(data)\n        \n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef) or isinstance(node, ast.ClassDef):\n                element_name = node.name\n                docstring = ast.get_docstring(node)\n                \n                # Generate a unique ID for each element\n                doc_id = str(uuid.uuid4())\n                \n                # Create a metadata dictionary\n                metadata = {\n                    \"type\": \"function\" if isinstance(node, ast.FunctionDef) else \"class\",\n                    \"name\": element_name,\n                    \"docstring\": docstring\n                }\n                \n                # Create a Document for each structural element\n                document = Document(doc_id=doc_id, content=docstring, metadata=metadata)\n                documents.append(document)\n                \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/RegExParser.py",
        "content": "```swarmauri/standard/parsers/concrete/RegExParser.py\nimport re\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass RegExParser(IParser):\n    \"\"\"\n    A parser that uses a regular expression to extract information from text.\n    \"\"\"\n\n    def __init__(self, pattern: str):\n        \"\"\"\n        Initializes the RegExParser with a specific regular expression pattern.\n\n        Parameters:\n        - pattern (str): The regular expression pattern used for parsing the text.\n        \"\"\"\n        self.pattern = pattern\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input data using the specified regular expression pattern and\n        returns a list of IDocument instances containing the extracted information.\n\n        Parameters:\n        - data (Union[str, Any]): The input data to be parsed. It can be a string or any format \n                                   that the concrete implementation can handle.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances containing the parsed information.\n        \"\"\"\n        # Ensure data is a string\n        if not isinstance(data, str):\n            data = str(data)\n\n        # Use the regular expression pattern to find all matches in the text\n        matches = re.findall(self.pattern, data)\n\n        # Create a Document for each match and collect them into a list\n        documents = [Document(doc_id=str(i+1), content=match, metadata={}) for i, match in enumerate(matches)]\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/TextBlobNounParser.py",
        "content": "```swarmauri/standard/parsers/concrete/TextBlobNounParser.py\nfrom typing import List, Union, Any\nfrom textblob import TextBlob\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass TextBlobNounParser(IParser):\n    \"\"\"\n    A concrete implementation of IParser using TextBlob for Natural Language Processing tasks.\n    \n    This parser leverages TextBlob's functionalities such as noun phrase extraction, \n    sentiment analysis, classification, language translation, and more for parsing texts.\n    \"\"\"\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input data using TextBlob to perform basic NLP tasks \n        and returns a list of documents with the parsed information.\n        \n        Parameters:\n        - data (Union[str, Any]): The input data to parse, expected to be text data for this parser.\n        \n        Returns:\n        - List[IDocument]: A list of documents with metadata generated from the parsing process.\n        \"\"\"\n        # Ensure the data is a string\n        if not isinstance(data, str):\n            raise ValueError(\"TextBlobParser expects a string as input data.\")\n        \n        # Use TextBlob for NLP tasks\n        blob = TextBlob(data)\n        \n        # Extracts noun phrases to demonstrate one of TextBlob's capabilities. \n        # In practice, this parser could be expanded to include more sophisticated processing.\n        noun_phrases = list(blob.noun_phrases)\n        \n        # Example: Wrap the extracted noun phrases into an IDocument instance\n        # In real scenarios, you might want to include more details, like sentiment, POS tags, etc.\n        document = Document(doc_id=\"0\", content=data, metadata={\"noun_phrases\": noun_phrases})\n        \n        return [document]\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/TextBlobSentenceParser.py",
        "content": "```swarmauri/standard/parsers/concrete/TextBlobSentenceParser.py\nfrom textblob import TextBlob\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\nfrom typing import List, Union, Any\n\nclass TextBlobParser(IParser):\n    \"\"\"\n    A parser that leverages TextBlob to break text into sentences.\n\n    This parser uses the natural language processing capabilities of TextBlob\n    to accurately identify sentence boundaries within large blocks of text.\n    \"\"\"\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses the input text into sentence-based document chunks using TextBlob.\n\n        Args:\n            data (Union[str, Any]): The input text to be parsed.\n\n        Returns:\n            List[IDocument]: A list of IDocument instances, each representing a sentence.\n        \"\"\"\n        # Ensure the input is a string\n        if not isinstance(data, str):\n            data = str(data)\n\n        # Utilize TextBlob for sentence tokenization\n        blob = TextBlob(data)\n        sentences = blob.sentences\n\n        # Create a document instance for each sentence\n        documents = [\n            Document(doc_id=str(index), content=str(sentence), metadata={'parser': 'TextBlobParser'})\n            for index, sentence in enumerate(sentences)\n        ]\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/TFIDFParser.py",
        "content": "```swarmauri/standard/parsers/concrete/TFIDFParser.py\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom swarmauri.core.parsers.IParser import IParser\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.Document import Document\n\nclass TFIDFParser(IParser):\n    def __init__(self):\n        self.vectorizer = TfidfVectorizer()\n        super().__init__()\n\n    def parse(self, data):\n        # Assuming `data` is a list of strings (documents)\n        tfidf_matrix = self.vectorizer.fit_transform(data)\n        # Depending on how you want to use the output, you could return Document objects\n        # For demonstration, let's return a list of IDocument with vectorized content\n        documents = [Document(doc_id=str(i), content=vector, metadata={}) for i, vector in enumerate(tfidf_matrix.toarray())]\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/URLExtractorParser.py",
        "content": "```swarmauri/standard/parsers/concrete/URLExtractorParser.py\nfrom typing import List, Union, Any\nfrom urllib.parse import urlparse\nimport re\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass URLExtractorParser(IParser):\n    \"\"\"\n    A concrete implementation of IParser that extracts URLs from text.\n    \n    This parser scans the input text for any URLs and creates separate\n    documents for each extracted URL. It utilizes regular expressions\n    to identify URLs within the given text.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the URLExtractorParser.\n        \"\"\"\n        super().__init__()\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parse input data (string) and extract URLs, each URL is then represented as a document.\n        \n        Parameters:\n        - data (Union[str, Any]): The input data to be parsed for URLs.\n        \n        Returns:\n        - List[IDocument]: A list of documents, each representing an extracted URL.\n        \"\"\"\n        if not isinstance(data, str):\n            raise ValueError(\"URLExtractorParser expects input data to be of type str.\")\n\n        # Regular expression for finding URLs\n        url_regex = r\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\"\n        \n        # Find all matches in the text\n        urls = re.findall(url_regex, data)\n        \n        # Create a document for each extracted URL\n        documents = [Document(doc_id=str(i), content=url, metadata={\"source\": \"URLExtractor\"}) for i, url in enumerate(urls)]\n        \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/XMLParser.py",
        "content": "```swarmauri/standard/parsers/concrete/XMLParser.py\nimport xml.etree.ElementTree as ET\nfrom typing import List, Union, Any\nfrom ....core.parsers.IParser import IParser\nfrom ....core.documents.IDocument import IDocument\nfrom ....standard.documents.concrete.Document import Document\n\nclass XMLParser(IParser):\n    \"\"\"\n    A parser that extracts information from XML data and converts it into IDocument objects.\n    This parser assumes a simple use-case where each targeted XML element represents a separate document.\n    \"\"\"\n\n    def __init__(self, element_tag: str):\n        \"\"\"\n        Initialize the XMLParser with the tag name of the XML elements to be extracted as documents.\n\n        Parameters:\n        - element_tag (str): The tag name of XML elements to parse into documents.\n        \"\"\"\n        self.element_tag = element_tag\n\n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Parses XML data and converts elements with the specified tag into IDocument instances.\n\n        Parameters:\n        - data (Union[str, Any]): The XML data as a string to be parsed.\n\n        Returns:\n        - List[IDocument]: A list of IDocument instances created from the XML elements.\n        \"\"\"\n        if isinstance(data, str):\n            root = ET.fromstring(data)  # Parse the XML string into an ElementTree element\n        else:\n            raise TypeError(\"Data for XMLParser must be a string containing valid XML.\")\n\n        documents = []\n        for element in root.findall(self.element_tag):\n            # Extracting content and metadata from each element\n            content = \"\".join(element.itertext())  # Get text content\n            metadata = {child.tag: child.text for child in element}  # Extract child elements as metadata\n\n            # Create a Document instance for each element\n            doc = Document(doc_id=None, content=content, metadata=metadata)\n            documents.append(doc)\n\n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/parsers/concrete/BERTEmbeddingParser.py",
        "content": "```swarmauri/standard/parsers/concrete/BERTEmbeddingParser.py\nfrom typing import List, Union, Any\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom swarmauri.core.parsers.IParser import IParser\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.Document import Document\n\nclass BERTEmbeddingParser(IParser):\n    \"\"\"\n    A parser that transforms input text into document embeddings using BERT.\n    \n    This parser tokenizes the input text, passes it through a pre-trained BERT model,\n    and uses the resulting embeddings as the document content.\n    \"\"\"\n\n    def __init__(self, model_name: str = 'bert-base-uncased'):\n        \"\"\"\n        Initializes the BERTEmbeddingParser with a specific BERT model.\n        \n        Parameters:\n        - model_name (str): The name of the pre-trained BERT model to use.\n        \"\"\"\n        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n        self.model = BertModel.from_pretrained(model_name)\n        self.model.eval()  # Set model to evaluation mode\n\n    \n    def parse(self, data: Union[str, Any]) -> List[IDocument]:\n        \"\"\"\n        Tokenizes input data and generates embeddings using a BERT model.\n\n        Parameters:\n        - data (Union[str, Any]): Input data, expected to be a single string or batch of strings.\n\n        Returns:\n        - List[IDocument]: A list containing a single IDocument instance with BERT embeddings as content.\n        \"\"\"\n        \n        # Tokenization\n        inputs = self.tokenizer(data, return_tensors='pt', padding=True, truncation=True, max_length=512)\n\n        # Generate embeddings\n        with torch.no_grad():\n            outputs = self.model(**inputs)\n\n        # Use the last hidden state as document embeddings (batch_size, sequence_length, hidden_size)\n        embeddings = outputs.last_hidden_state\n        \n        # Convert to list of numpy arrays\n        embeddings = embeddings.detach().cpu().numpy()\n        \n        # For simplicity, let's consider the mean of embeddings across tokens to represent the document\n        doc_embeddings = embeddings.mean(axis=1)\n        \n        # Creating document object(s)\n        documents = [Document(doc_id=str(i), content=emb, metadata={\"source\": \"BERTEmbeddingParser\"}) for i, emb in enumerate(doc_embeddings)]\n        \n        return documents\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/__init__.py",
        "content": "```swarmauri/standard/prompts/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/base/__init__.py",
        "content": "```swarmauri/standard/prompts/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/base/BasePromptMatrix.py",
        "content": "```swarmauri/standard/prompts/base/BasePromptMatrix.py\n# swarmauri/standard/prompts/base/BasePromptMatrix.py\nfrom typing import List, Tuple, Optional, Any\nfrom core.prompts.IPromptMatrix import IPromptMatrix\n\nclass BasePromptMatrix(IPromptMatrix):\n    def __init__(self):\n        self._matrix = []\n\n    @property\n    def matrix(self) -> List[List[Optional[str]]]:\n        return self._matrix\n\n    @matrix.setter\n    def matrix(self, value: List[List[Optional[str]]]) -> None:\n        self._matrix = value\n\n    def get_shape(self) -> Tuple[int, int]:\n        if self._matrix:\n            return len(self._matrix), len(self._matrix[0])\n        return 0, 0\n\n    def add_prompt_sequence(self, sequence: List[Optional[str]]) -> None:\n        if not self._matrix or (self._matrix and len(sequence) == len(self._matrix[0])):\n            self._matrix.append(sequence)\n        else:\n            raise ValueError(\"Sequence length does not match the prompt matrix dimensions.\")\n\n    def remove_prompt_sequence(self, index: int) -> None:\n        if 0 <= index < len(self._matrix):\n            self._matrix.pop(index)\n        else:\n            raise IndexError(\"Index out of range.\")\n\n    def get_prompt_sequence(self, index: int) -> List[Optional[str]]:\n        if 0 <= index < len(self._matrix):\n            return self._matrix[index]\n        else:\n            raise IndexError(\"Index out of range.\")\n\n    def show_matrix(self) -> List[List[Optional[str]]]:\n        return self._matrix\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/__init__.py",
        "content": "```swarmauri/standard/prompts/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/Prompt.py",
        "content": "```swarmauri/standard/prompts/concrete/Prompt.py\nfrom swarmauri.core.prompts.IPrompt import IPrompt\n\nclass Prompt(IPrompt):\n    \"\"\"\n    The ChatPrompt class represents a simple, chat-like prompt system where a \n    message can be set and retrieved as needed. It's particularly useful in \n    applications involving conversational agents, chatbots, or any system that \n    requires dynamic text-based interactions.\n    \"\"\"\n\n    def __init__(self, prompt: str = \"\"):\n        \"\"\"\n        Initializes an instance of ChatPrompt with an optional initial message.\n        \n        Parameters:\n        - message (str, optional): The initial message for the prompt. Defaults to an empty string.\n        \"\"\"\n        self.prompt = prompt\n\n    def __call__(self, prompt):\n        \"\"\"\n        Enables the instance to be callable, allowing direct retrieval of the message. \n        This method facilitates intuitive access to the prompt's message, mimicking callable \n        behavior seen in functional programming paradigms.\n        \n        Returns:\n        - str: The current message stored in the prompt.\n        \"\"\"\n        return self.prompt\n\n    def set_prompt(self, prompt: str):\n        \"\"\"\n        Updates the internal message of the chat prompt. This method provides a way to change \n        the content of the prompt dynamically, reflecting changes in the conversational context \n        or user inputs.\n        \n        Parameters:\n        - message (str): The new message to set for the prompt.\n        \"\"\"\n        self.prompt = prompt\n\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/PromptTemplate.py",
        "content": "```swarmauri/standard/prompts/concrete/PromptTemplate.py\nfrom typing import Dict, List\nfrom swarmauri.core.prompts.IPrompt import IPrompt\nfrom swarmauri.core.prompts.ITemplate import ITemplate\n\nclass PromptTemplate(IPrompt, ITemplate):\n    \"\"\"\n    A class for generating prompts based on a template and variables.\n    Implements the IPrompt for generating prompts and ITemplate for template manipulation.\n    \"\"\"\n\n    def __init__(self, template: str = \"\", variables: List[Dict[str, str]] = []):\n        self._template = template\n        self._variables_list = variables\n\n    @property\n    def template(self) -> str:\n        \"\"\"\n        Get the current prompt template.\n        \"\"\"\n        return self._template\n\n    @template.setter\n    def template(self, value: str) -> None:\n        \"\"\"\n        Set a new template string for the prompt.\n        \"\"\"\n        self._template = value\n\n    @property\n    def variables(self) -> List[Dict[str, str]]:\n        \"\"\"\n        Get the current set of variables for the template.\n        \"\"\"\n        return self._variables_list \n\n    @variables.setter\n    def variables(self, value: List[Dict[str, str]]) -> None:\n        if not isinstance(value, list):\n            raise ValueError(\"Variables must be a list of dictionaries.\")\n        self._variables_list = value\n\n    def set_template(self, template: str) -> None:\n        \"\"\"\n        Sets or updates the current template string.\n        \"\"\"\n        self._template = template\n\n    def set_variables(self, variables: Dict[str, str]) -> None:\n        \"\"\"\n        Sets or updates the variables to be substituted into the template.\n        \"\"\"\n        self._variables_list = variables\n\n    def generate_prompt(self, variables: List[Dict[str, str]] = None) -> str:\n        variables = variables.pop(0) or (self._variables_list.pop(0) if self._variables_list else {})\n        return self._template.format(**variables)\n\n    def __call__(self, variables: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Generates a prompt using the current template and provided keyword arguments for substitution.\n        \"\"\"\n        return self.generate_prompt(variables)\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/PromptGenerator.py",
        "content": "```swarmauri/standard/prompts/concrete/PromptGenerator.py\nfrom typing import Dict, List, Generator\nfrom swarmauri.core.prompts.IPrompt import IPrompt\nfrom swarmauri.core.prompts.ITemplate import ITemplate\n\n\nclass PromptGenerator(IPrompt, ITemplate):\n    \"\"\"\n    A class that generates prompts based on a template and a list of variable sets.\n    It implements the IPrompt and ITemplate interfaces.\n    \"\"\"\n\n    def __init__(self, template: str = \"\", variables: List[Dict[str, str]] = []):\n        self._template = template\n        self._variables_list = variables\n\n    @property\n    def template(self) -> str:\n        return self._template\n\n    @template.setter\n    def template(self, value: str) -> None:\n        self._template = value\n\n    @property\n    def variables(self) -> List[Dict[str, str]]:\n        return self._variables_list\n\n    @variables.setter\n    def variables(self, value: List[Dict[str, str]]) -> None:\n        if not isinstance(value, list):\n            raise ValueError(\"Expected a list of dictionaries for variables.\")\n        self._variables_list = value\n\n    def set_template(self, template: str) -> None:\n        self._template = template\n\n    def set_variables(self, variables: List[Dict[str, str]]) -> None:\n        self.variables = variables\n\n    def generate_prompt(self, **kwargs) -> str:\n        \"\"\"\n        Generates a prompt using the provided variables if any, \n        else uses the next variables set in the list.\n        \"\"\"\n        variables = kwargs if kwargs else self.variables.pop(0) if self.variables else {}\n        return self._template.format(**variables)\n\n    def __call__(self) -> Generator[str, None, None]:\n        \"\"\"\n        Returns a generator that yields prompts constructed from the template and \n        each set of variables in the variables list.\n        \"\"\"\n        for variables_set in self._variables_list:\n            yield self.generate_prompt(**variables_set)\n        self._variables_list = []  # Reset the list after all prompts have been generated.\n```"
    },
    {
        "document_name": "swarmauri/standard/prompts/concrete/PromptMatrix.py",
        "content": "```swarmauri/standard/prompts/concrete/PromptMatrix.py\n# swarmauri/standard/prompts/concrete/PromptMatrix.py\nfrom standard.prompts.base.BasePromptMatrix import BasePromptMatrix\n\nclass PromptMatrix(BasePromptMatrix):\n    # If any additional methods or overrides are needed, they can be added here.\n    pass\n```"
    },
    {
        "document_name": "swarmauri/standard/states/__init__.py",
        "content": "```swarmauri/standard/states/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/states/base/__init__.py",
        "content": "```swarmauri/standard/states/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/states/concrete/__init__.py",
        "content": "```swarmauri/standard/states/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/__init__.py",
        "content": "```swarmauri/standard/swarms/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/base/__init__.py",
        "content": "```swarmauri/standard/swarms/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/base/SwarmComponentBase.py",
        "content": "```swarmauri/standard/swarms/base/SwarmComponentBase.py\nfrom swarmauri.core.swarms.ISwarmComponent import ISwarmComponent\n\nclass SwarmComponentBase(ISwarmComponent):\n    \"\"\"\n    Interface for defining basics of any component within the swarm system.\n    \"\"\"\n    def __init__(self, key: str, name: str, superclass: str, module: str, class_name: str, args=None, kwargs=None):\n        self.key = key\n        self.name = name\n        self.superclass = superclass\n        self.module = module\n        self.class_name = class_name\n        self.args = args or []\n        self.kwargs = kwargs or {}\n    \n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/concrete/__init__.py",
        "content": "```swarmauri/standard/swarms/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/swarms/concrete/SimpleSwarmFactory.py",
        "content": "```swarmauri/standard/swarms/concrete/SimpleSwarmFactory.py\nimport json\nimport pickle\nfrom typing import List\nfrom swarmauri.core.chains.ISwarmFactory import (\n    ISwarmFactory , \n    CallableChainItem, \n    AgentDefinition, \n    FunctionDefinition\n)\nclass SimpleSwarmFactory(ISwarmFactory):\n    def __init__(self):\n        self.swarms = []\n        self.callable_chains = []\n\n    def create_swarm(self, agents=[]):\n        swarm = {\"agents\": agents}\n        self.swarms.append(swarm)\n        return swarm\n\n    def create_agent(self, agent_definition: AgentDefinition):\n        # For simplicity, agents are stored in a list\n        # Real-world usage might involve more sophisticated management and instantiation based on type and configuration\n        agent = {\"definition\": agent_definition._asdict()}\n        self.agents.append(agent)\n        return agent\n\n    def create_callable_chain(self, chain_definition: List[CallableChainItem]):\n        chain = {\"definition\": [item._asdict() for item in chain_definition]}\n        self.callable_chains.append(chain)\n        return chain\n\n    def register_function(self, function_definition: FunctionDefinition):\n        if function_definition.identifier in self.functions:\n            raise ValueError(f\"Function {function_definition.identifier} is already registered.\")\n        \n        self.functions[function_definition.identifier] = function_definition\n    \n    def export_configuration(self, format_type: str = 'json'):\n        # Now exporting both swarms and callable chains\n        config = {\"swarms\": self.swarms, \"callable_chains\": self.callable_chains}\n        if format_type == \"json\":\n            return json.dumps(config)\n        elif format_type == \"pickle\":\n            return pickle.dumps(config)\n\n    def load_configuration(self, config_data, format_type: str = 'json'):\n        # Loading both swarms and callable chains\n        config = json.loads(config_data) if format_type == \"json\" else pickle.loads(config_data)\n        self.swarms = config.get(\"swarms\", [])\n        self.callable_chains = config.get(\"callable_chains\", [])\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/__init__.py",
        "content": "```swarmauri/standard/toolkits/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/base/__init__.py",
        "content": "```swarmauri/standard/toolkits/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/base/ToolkitBase.py",
        "content": "```swarmauri/standard/toolkits/base/ToolkitBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nfrom ....core.toolkits.IToolkit import IToolkit\nfrom ....core.tools.ITool import ITool  \n\nclass ToolkitBase(IToolkit, ABC):\n    \"\"\"\n    A class representing a toolkit used by Swarm Agents.\n    Tools are maintained in a dictionary keyed by the tool's name.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, initial_tools: Dict[str, ITool] = None):\n        \"\"\"\n        Initialize the Toolkit with an optional dictionary of initial tools.\n        \"\"\"\n        # If initial_tools is provided, use it; otherwise, use an empty dictionary\n        self._tools = initial_tools if initial_tools is not None else {}\n\n    @property\n    def tools(self) -> Dict[str, ITool]:\n        return [self._tools[tool].as_dict() for tool in self._tools]\n\n    def add_tools(self, tools: Dict[str, ITool]):\n        \"\"\"\n        Add multiple tools to the toolkit.\n\n        Parameters:\n            tools (Dict[str, Tool]): A dictionary of tool objects keyed by their names.\n        \"\"\"\n        self._tools.update(tools)\n\n    def add_tool(self, tool: ITool):\n        \"\"\"\n        Add a single tool to the toolkit.\n\n        Parameters:\n            tool (Tool): The tool instance to be added to the toolkit.\n        \"\"\"\n        self._tools[tool.function['name']] = tool\n\n    def remove_tool(self, tool_name: str):\n        \"\"\"\n        Remove a tool from the toolkit by name.\n\n        Parameters:\n            tool_name (str): The name of the tool to be removed from the toolkit.\n        \"\"\"\n        if tool_name in self._tools:\n            del self._tools[tool_name]\n        else:\n            raise ValueError(f\"Tool '{tool_name}' not found in the toolkit.\")\n\n    def get_tool_by_name(self, tool_name: str) -> ITool:\n        \"\"\"\n        Get a tool from the toolkit by name.\n\n        Parameters:\n            tool_name (str): The name of the tool to retrieve.\n\n        Returns:\n            Tool: The tool instance with the specified name.\n        \"\"\"\n        if tool_name in self._tools:\n            return self._tools[tool_name]\n        else:\n            raise ValueError(f\"Tool '{tool_name}' not found in the toolkit.\")\n\n    def __len__(self) -> int:\n        \"\"\"\n        Returns the number of tools in the toolkit.\n\n        Returns:\n            int: The number of tools in the toolkit.\n        \"\"\"\n        return len(self._tools)\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/concrete/__init__.py",
        "content": "```swarmauri/standard/toolkits/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/toolkits/concrete/Toolkit.py",
        "content": "```swarmauri/standard/toolkits/concrete/Toolkit.py\nfrom typing import Dict\nfrom ..base.ToolkitBase import ToolkitBase\nfrom ....core.tools.ITool import ITool\n\nclass Toolkit(ToolkitBase):\n    \"\"\"\n    A class representing a toolkit used by Swarm Agents.\n    Tools are maintained in a dictionary keyed by the tool's name.\n    \"\"\"\n\n    def __init__(self, initial_tools: Dict[str, ITool] = None):\n        \"\"\"\n        Initialize the Toolkit with an optional dictionary of initial tools.\n        \"\"\"\n        \n        super().__init__(initial_tools)\n    \n```"
    },
    {
        "document_name": "swarmauri/standard/tools/__init__.py",
        "content": "```swarmauri/standard/tools/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/base/__init__.py",
        "content": "```swarmauri/standard/tools/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/base/ToolBase.py",
        "content": "```swarmauri/standard/tools/base/ToolBase.py\nfrom typing import Optional, List, Any\nfrom abc import ABC, abstractmethod\nimport json\nfrom swarmauri.core.tools.ITool import ITool\n        \nclass ToolBase(ITool, ABC):\n    \n    @abstractmethod\n    def __init__(self, name, description, parameters=[]):\n        self._name = name\n        self._description = description\n        self._parameters = parameters\n        self.type = \"function\"\n        self.function = {\n            \"name\": name,\n            \"description\": description,\n        }\n        \n        # Dynamically constructing the parameters schema\n        properties = {}\n        required = []\n        \n        for param in parameters:\n            properties[param.name] = {\n                \"type\": param.type,\n                \"description\": param.description,\n            }\n            if param.enum:\n                properties[param.name]['enum'] = param.enum\n\n            if param.required:\n                required.append(param.name)\n        \n        self.function['parameters'] = {\n            \"type\": \"object\",\n            \"properties\": properties,\n        }\n        \n        if required:  # Only include 'required' if there are any required parameters\n            self.function['parameters']['required'] = required\n\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def description(self):\n        return self._description\n\n    @property\n    def parameters(self):\n        return self._parameters\n\n    def __iter__(self):\n        yield ('type', self.type)\n        yield ('function', self.function)\n        \n\n    def as_dict(self):\n        return {'type': self.type, 'function': self.function}\n        # return self.__dict__\n\n    def to_json(obj):\n        return json.dumps(obj, default=lambda obj: obj.__dict__)\n\n    def __getstate__(self):\n        return {'type': self.type, 'function': self.function}\n\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"\n        Placeholder method for executing the functionality of the tool.\n        Subclasses should override this method to define specific tool behaviors.\n\n        Parameters:\n        - *args: Variable length argument list.\n        - **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement the call_function method.\")\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/__init__.py",
        "content": "```swarmauri/standard/tools/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/TestTool.py",
        "content": "```swarmauri/standard/tools/concrete/TestTool.py\nimport json\nimport subprocess as sp\nfrom ..base.ToolBase import ToolBase\nfrom .Parameter import Parameter\n\nclass TestTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"program\",\n                type=\"string\",\n                description=\"The program that the user wants to open ('notepad' or 'calc' or 'mspaint')\",\n                required=True,\n                enum=[\"notepad\", \"calc\", \"mspaint\"]\n            )\n        ]\n        \n        super().__init__(name=\"TestTool\", \n                         description=\"This opens a program based on the user's request.\", \n                         parameters=parameters)\n\n    def __call__(self, program) -> str:\n        # sp.check_output(program)\n        # Here you would implement the actual logic for fetching the weather information.\n        # For demonstration, let's just return the parameters as a string.\n        return f\"Program Opened: {program}\\n\"\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/WeatherTool.py",
        "content": "```swarmauri/standard/tools/concrete/WeatherTool.py\nimport json\nfrom ..base.ToolBase import ToolBase\nfrom .Parameter import Parameter\n\nclass WeatherTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"location\",\n                type=\"string\",\n                description=\"The location for which to fetch weather information\",\n                required=True\n            ),\n            Parameter(\n                name=\"unit\",\n                type=\"string\",\n                description=\"The unit for temperature ('fahrenheit' or 'celsius')\",\n                required=True,\n                enum=[\"fahrenheit\", \"celsius\"]\n            )\n        ]\n        \n        super().__init__(name=\"WeatherTool\", description=\"Fetch current weather info for a location\", parameters=parameters)\n\n    def __call__(self, location, unit=\"fahrenheit\") -> str:\n        weather_info = (location, unit)\n        # Here you would implement the actual logic for fetching the weather information.\n        # For demonstration, let's just return the parameters as a string.\n        return f\"Weather Info: {weather_info}\\n\"\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/Parameter.py",
        "content": "```swarmauri/standard/tools/concrete/Parameter.py\nfrom typing import Optional, List, Any\nimport json\nfrom swarmauri.core.tools.IParameter import IParameter\n\nclass Parameter(IParameter):\n    \"\"\"\n    A class to represent a parameter for a tool.\n\n    Attributes:\n        name (str): Name of the parameter.\n        type (str): Data type of the parameter (e.g., 'int', 'str', 'float').\n        description (str): A brief description of the parameter.\n        required (bool): Whether the parameter is required or optional.\n        enum (Optional[List[any]]): A list of acceptable values for the parameter, if any.\n    \"\"\"\n\n    def __init__(self, name: str, type: str, description: str, required: bool = True, enum: Optional[List[Any]] = None):\n        \"\"\"\n        Initializes a new instance of the Parameter class.\n\n        Args:\n            name (str): The name of the parameter.\n            type (str): The type of the parameter.\n            description (str): A brief description of what the parameter is used for.\n            required (bool, optional): Specifies if the parameter is required. Defaults to True.\n            enum (Optional[List[Any]], optional): A list of acceptable values for the parameter. Defaults to None.\n        \"\"\"\n        self._name = name\n        self._type = type\n        self._description = description\n        self._required = required\n        self._enum = enum\n        \n    @property\n    def name(self) -> str:\n        \"\"\"\n        Abstract property for getting the name of the parameter.\n        \"\"\"\n        return self._name\n\n    @name.setter\n    def name(self, value: str):\n        \"\"\"\n        Abstract setter for setting the name of the parameter.\n        \"\"\"\n        self._name = value\n\n    @property\n    def type(self) -> str:\n        \"\"\"\n        Abstract property for getting the type of the parameter.\n        \"\"\"\n        return self._type\n\n    @type.setter\n    def type(self, value: str):\n        \"\"\"\n        Abstract setter for setting the type of the parameter.\n        \"\"\"\n        self._type = value\n\n    @property\n    def description(self) -> str:\n        \"\"\"\n        Abstract property for getting the description of the parameter.\n        \"\"\"\n        return self._description\n\n    @description.setter\n    def description(self, value: str):\n        \"\"\"\n        Abstract setter for setting the description of the parameter.\n        \"\"\"\n        self._description = value\n\n    @property\n    def required(self) -> bool:\n        \"\"\"\n        Abstract property for getting the required status of the parameter.\n        \"\"\"\n        return self._required\n\n    @required.setter\n    def required(self, value: bool):\n        \"\"\"\n        Abstract setter for setting the required status of the parameter.\n        \"\"\"\n        self._required = value\n\n    @property\n    def enum(self) -> Optional[List[Any]]:\n        \"\"\"\n        Abstract property for getting the enum list of the parameter.\n        \"\"\"\n        return self._enum\n\n    @enum.setter\n    def enum(self, value: Optional[List[Any]]):\n        \"\"\"\n        Abstract setter for setting the enum list of the parameter.\n        \"\"\"\n        self._enum = value\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/AdditionTool.py",
        "content": "```swarmauri/standard/tools/concrete/AdditionTool.py\nfrom ..base.ToolBase import ToolBase\nfrom .Parameter import Parameter\n\nclass AdditionTool(ToolBase):\n    \n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"x\",\n                type=\"integer\",\n                description=\"The left operand\",\n                required=True\n            ),\n            Parameter(\n                name=\"y\",\n                type=\"integer\",\n                description=\"The right operand\",\n                required=True\n            )\n        ]\n        super().__init__(name=\"TestTool\", \n                         description=\"This opens a program based on the user's request.\", \n                         parameters=parameters)\n\n    def __call__(self, x: int, y: int) -> int:\n        \"\"\"\n        Add two numbers x and y and return the sum.\n\n        Parameters:\n        - x (int): The first number.\n        - y (int): The second number.\n\n        Returns:\n        - int: The sum of x and y.\n        \"\"\"\n        return x + y\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/CodeInterpreterTool.py",
        "content": "```swarmauri/standard/tools/concrete/CodeInterpreterTool.py\nimport sys\nimport io\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase  # Adjust the import path as necessary\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter  # Assuming a parameter structure is used\n\nclass CodeInterpreterTool(ToolBase):\n    def __init__(self):\n        # Example of initializing the tool with parameters if necessary\n        parameters = [\n            Parameter(\n                name=\"user_code\",\n                type=\"string\",\n                description=(\"Executes the provided Python code snippet in a secure sandbox environment. \"\n                             \"This tool is designed to interpret the execution of the python code snippet.\"\n                             \"Returns the output\"),\n                required=True\n            )\n        ]\n        super().__init__(name=\"CodeInterpreterTool\", \n                         description=\"Executes provided Python code and captures its output.\",\n                         parameters=parameters)\n\n    def __call__(self, user_code: str) -> str:\n        \"\"\"\n        Executes the provided user code and captures its stdout output.\n        \n        Parameters:\n            user_code (str): Python code to be executed.\n        \n        Returns:\n            str: Captured output or error message from the executed code.\n        \"\"\"\n        return self.execute_code(user_code)\n    \n    def execute_code(self, user_code: str) -> str:\n        \"\"\"\n        Executes the provided user code and captures its stdout output.\n\n        Args:\n            user_code (str): Python code to be executed.\n\n        Returns:\n            str: Captured output or error message from the executed code.\n        \"\"\"\n        old_stdout = sys.stdout\n        redirected_output = sys.stdout = io.StringIO()\n\n        try:\n            # Note: Consider security implications of using 'exec'\n            builtins = globals().copy()\n            exec(user_code, builtins)\n            sys.stdout = old_stdout\n            captured_output = redirected_output.getvalue()\n            return str(captured_output)\n        except Exception as e:\n            sys.stdout = old_stdout\n            return f\"An error occurred: {str(e)}\"\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/CalculatorTool.py",
        "content": "```swarmauri/standard/tools/concrete/CalculatorTool.py\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase  # Adjust the import path as necessary\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\nclass CalculatorTool(ToolBase):\n    def __init__(self):\n        parameters = [\n            Parameter(\n                name=\"operation\",\n                type=\"string\",\n                description=\"The arithmetic operation to perform ('add', 'subtract', 'multiply', 'divide').\",\n                required=True,\n                enum=[\"add\", \"subtract\", \"multiply\", \"divide\"]\n            ),\n            Parameter(\n                name=\"x\",\n                type=\"number\",\n                description=\"The left operand for the operation.\",\n                required=True\n            ),\n            Parameter(\n                name=\"y\",\n                type=\"number\",\n                description=\"The right operand for the operation.\",\n                required=True\n            )\n        ]\n        super().__init__(name=\"CalculatorTool\", \n                         description=\"Performs basic arithmetic operations.\",\n                         parameters=parameters)\n\n    def __call__(self, operation: str, x: float, y: float) -> str:\n        \"\"\"\n        Executes the specified arithmetic operation on the given operands.\n        \n        Parameters:\n            operation (str): The arithmetic operation to perform.\n            x (float): The left operand.\n            y (float): The right operand.\n        \n        Returns:\n            str: Result of the arithmetic operation.\n        \"\"\"\n        try:\n            if operation == \"add\":\n                result = x + y\n            elif operation == \"subtract\":\n                result = x - y\n            elif operation == \"multiply\":\n                result = x * y\n            elif operation == \"divide\":\n                if y == 0:\n                    return \"Error: Division by zero.\"\n                result = x / y\n            else:\n                return \"Error: Unknown operation.\"\n            return str(result)\n        except Exception as e:\n            return f\"An error occurred: {str(e)}\"\n```"
    },
    {
        "document_name": "swarmauri/standard/tools/concrete/ImportMemoryModuleTool.py",
        "content": "```swarmauri/standard/tools/concrete/ImportMemoryModuleTool.py\n# standard/tools/concrete/ImportMemoryModuleTool.py\nimport sys\nimport types\nimport importlib\nfrom swarmauri.standard.tools.base.ToolBase import ToolBase\nfrom swarmauri.standard.tools.concrete.Parameter import Parameter\n\n\nclass ImportMemoryModuleTool(ToolBase):\n    def __init__(self):\n        # Define the parameters required by the tool\n        parameters = [\n            Parameter(\n                name=\"name\",\n                type=\"string\",\n                description=\"Name of the new module.\",\n                required=True\n            ),\n            Parameter(\n                name=\"code\",\n                type=\"string\",\n                description=\"Python code snippet to include in the module.\",\n                required=True\n            ),\n            Parameter(\n                name=\"package_path\",\n                type=\"string\",\n                description=\"Dot-separated package path where the new module should be inserted.\",\n                required=True\n            )\n        ]\n        \n        # Call the ToolBase initializer\n        super().__init__(name=\"ImportMemoryModuleTool\", \n                         description=\"Dynamically imports a module from memory into a specified package path.\",\n                         parameters=parameters)\n\n    def __call__(self, name: str, code: str, package_path: str) -> str:\n        \"\"\"\n        Dynamically creates a module from a code snippet and inserts it into the specified package path.\n\n        Args:\n            name (str): Name of the new module.\n            code (str): Python code snippet to include in the module.\n            package_path (str): Dot-separated package path where the new module should be inserted.\n        \"\"\"\n        # Implementation adapted from the provided snippet\n        # Ensure the package structure exists\n        current_package = self.ensure_module(package_path)\n        \n        # Create a new module\n        module = types.ModuleType(name)\n        \n        # Execute code in the context of this new module\n        exec(code, module.__dict__)\n        \n        # Insert the new module into the desired location\n        setattr(current_package, name, module)\n        sys.modules[package_path + '.' + name] = module\n        return f\"{name} has been successfully imported into {package_path}\"\n\n    @staticmethod\n    def ensure_module(package_path: str):\n        package_parts = package_path.split('.')\n        module_path = \"\"\n        current_module = None\n\n        for part in package_parts:\n            if module_path:\n                module_path += \".\" + part\n            else:\n                module_path = part\n                \n            if module_path not in sys.modules:\n                try:\n                    # Try importing the module; if it exists, this will add it to sys.modules\n                    imported_module = importlib.import_module(module_path)\n                    sys.modules[module_path] = imported_module\n                except ImportError:\n                    # If the module doesn't exist, create a new placeholder module\n                    new_module = types.ModuleType(part)\n                    if current_module:\n                        setattr(current_module, part, new_module)\n                    sys.modules[module_path] = new_module\n            current_module = sys.modules[module_path]\n\n        return current_module\n```"
    },
    {
        "document_name": "swarmauri/standard/apis/__init__.py",
        "content": "```swarmauri/standard/apis/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/apis/base/__init__.py",
        "content": "```swarmauri/standard/apis/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/apis/concrete/__init__.py",
        "content": "```swarmauri/standard/apis/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/__init__.py",
        "content": "```swarmauri/standard/vector_stores/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/__init__.py",
        "content": "```swarmauri/standard/vector_stores/base/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/VectorDocumentStoreBase.py",
        "content": "```swarmauri/standard/vector_stores/base/VectorDocumentStoreBase.py\nimport json\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.vector_stores.IVectorStore import IVectorStore\n\nclass VectorDocumentStoreBase(IVectorStore, ABC):\n    \"\"\"\n    Abstract base class for document stores, implementing the IVectorStore interface.\n\n    This class provides a standard API for adding, updating, getting, and deleting documents in a vector store.\n    The specifics of storing (e.g., in a database, in-memory, or file system) are to be implemented by concrete subclasses.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Add a single document to the document store.\n\n        Parameters:\n        - document (IDocument): The document to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Add multiple documents to the document store in a batch operation.\n\n        Parameters:\n        - documents (List[IDocument]): A list of documents to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Optional[IDocument]:\n        \"\"\"\n        Retrieve a single document by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to retrieve.\n\n        Returns:\n        - Optional[IDocument]: The requested document if found; otherwise, None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieve all documents stored in the document store.\n\n        Returns:\n        - List[IDocument]: A list of all documents in the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Update a document in the document store.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to update.\n        - updated_document (IDocument): The updated document instance.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Delete a document from the document store by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n\n    def clear_documents(self) -> None:\n        \"\"\"\n        Deletes all documents from the vector store\n\n        \"\"\"\n        self.documents = []\n    \n    def document_count(self):\n        return len(self.documents)\n    \n    def document_dumps(self) -> str:\n        return json.dumps([each.to_dict() for each in self.documents])\n\n    def document_dump(self, file_path: str) -> None:\n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump([each.to_dict() for each in self.documents], \n                f,\n                ensure_ascii=False, \n                indent=4)  \n\n    def document_loads(self, json_data: str) -> None:\n        self.documents = [globals()[each['type']].from_dict(each) for each in json.loads(json_data)]\n\n    def document_load(self, file_path: str) -> None:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            self.documents = [globals()[each['type']].from_dict(each) for each in json.load(file_path)]\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/VectorDocumentStoreRetrieveBase.py",
        "content": "```swarmauri/standard/vector_stores/base/VectorDocumentStoreRetrieveBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.vector_stores.IVectorRetrieve import IVectorRetrieve\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreBase import VectorDocumentStoreBase\n\nclass VectorDocumentStoreRetrieveBase(VectorDocumentStoreBase, IVectorRetrieve, ABC):\n        \n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the top_k most relevant documents based on the given query.\n        \n        Args:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n        \n        Returns:\n            List[IDocument]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/base/SaveLoadStoreBase.py",
        "content": "```swarmauri/standard/vector_stores/base/SaveLoadStoreBase.py\nfrom typing import List\nimport os\nimport json\nimport glob\nimport importlib \nfrom swarmauri.core.vector_stores.ISaveLoadStore import ISaveLoadStore\nfrom swarmauri.standard.documents import DocumentBase\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\n\nclass SaveLoadStoreBase(ISaveLoadStore):\n    \"\"\"\n    Base class for vector stores with built-in support for saving and loading\n    the vectorizer's model and the documents.\n    \"\"\"\n    \n    def __init__(self, vectorizer: IVectorize, documents: List[DocumentBase]):\n        self.vectorizer = vectorizer\n        self.documents = documents\n    \n    def save_store(self, directory_path: str) -> None:\n        \"\"\"\n        Saves both the vectorizer's model and the documents.\n        \"\"\"\n        # Ensure the directory exists\n        if not os.path.exists(directory_path):\n            os.makedirs(directory_path)\n            \n        # Save the vectorizer model\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        self.vectorizer.save_model(model_path)\n        \n        # Save documents\n        documents_path = os.path.join(directory_path, \"documents.json\")\n        with open(documents_path, 'w', encoding='utf-8') as f:\n            json.dump([each.to_dict() for each in self.documents], \n                f,\n                ensure_ascii=False, \n                indent=4)\n\n    \n    def load_store(self, directory_path: str) -> None:\n        \"\"\"\n        Loads both the vectorizer's model and the documents.\n        \"\"\"\n        # Load the vectorizer model\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        self.vectorizer.load_model(model_path)\n        \n        # Load documents\n        documents_path = os.path.join(directory_path, \"documents.json\")\n        with open(documents_path, 'r', encoding='utf-8') as f:\n            self.documents = [self._load_document(each) for each in json.load(f)]\n\n    def _load_document(self, data):\n        document_type = data.pop(\"type\") \n        if document_type:\n            module = importlib.import_module(f\"swarmauri.standard.documents.concrete.{document_type}\")\n            document_class = getattr(module, document_type)\n            document = document_class.from_dict(data)\n            return document\n        else:\n            raise ValueError(\"Unknown document type\")\n\n    def save_parts(self, directory_path: str, chunk_size: int = 10485760) -> None:\n        \"\"\"\n        Splits the file into parts if it's too large and saves those parts individually.\n        \"\"\"\n        file_number = 1\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        parts_directory = os.path.join(directory_path, \"parts\")\n        \n        if not os.path.exists(parts_directory):\n            os.makedirs(parts_directory)\n\n\n\n        with open(f\"{model_path}/model.safetensors\", 'rb') as f:\n            chunk = f.read(chunk_size)\n            while chunk:\n                with open(f\"{parts_directory}/model.safetensors.part{file_number:03}\", 'wb') as chunk_file:\n                    chunk_file.write(chunk)\n                file_number += 1\n                chunk = f.read(chunk_size)\n\n        # Split the documents into parts and save them\n        documents_dir = os.path.join(directory_path, \"documents\")\n\n        self._split_json_file(directory_path, chunk_size=chunk_size)\n\n\n    def _split_json_file(self, directory_path: str, max_records=100, chunk_size: int = 10485760):    \n        # Read the input JSON file\n        combined_documents_file_path = os.path.join(directory_path, \"documents.json\")\n\n        # load the master JSON file\n        with open(combined_documents_file_path , 'r') as file:\n            data = json.load(file)\n\n        # Set and Create documents parts folder if it does not exist\n        documents_dir = os.path.join(directory_path, \"documents\")\n        if not os.path.exists(documents_dir):\n            os.makedirs(documents_dir)\n        current_batch = []\n        file_index = 1\n        current_size = 0\n        \n        for record in data:\n            current_batch.append(record)\n            current_size = len(json.dumps(current_batch).encode('utf-8'))\n            \n            # Check if current batch meets the splitting criteria\n            if len(current_batch) >= max_records or current_size >= chunk_size:\n                # Write current batch to a new file\n                output_file = f'document_part_{file_index}.json'\n                output_file = os.path.join(documents_dir, output_file)\n                with open(output_file, 'w') as outfile:\n                    json.dump(current_batch, outfile)\n                \n                # Prepare for the next batch\n                current_batch = []\n                current_size = 0\n                file_index += 1\n\n        # Check if there's any remaining data to be written\n        if current_batch:\n            output_file = f'document_part_{file_index}.json'\n            output_file = os.path.join(documents_dir, output_file)\n            with open(output_file, 'w') as outfile:\n                json.dump(current_batch, outfile)\n\n    def load_parts(self, directory_path: str, file_pattern: str = '*.part*') -> None:\n        \"\"\"\n        Combines file parts from a directory back into a single file and loads it.\n        \"\"\"\n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        parts_directory = os.path.join(directory_path, \"parts\")\n        output_file_path = os.path.join(model_path, \"model.safetensors\")\n\n        parts = sorted(glob.glob(os.path.join(parts_directory, file_pattern)))\n        with open(output_file_path, 'wb') as output_file:\n            for part in parts:\n                with open(part, 'rb') as file_part:\n                    output_file.write(file_part.read())\n\n        # Load the combined_model now        \n        model_path = os.path.join(directory_path, \"vectorizer_model\")\n        self.vectorizer.load_model(model_path)\n\n        # Load document files\n        self._load_documents(directory_path)\n        \n\n    def _load_documents(self, directory_path: str) -> None:\n        \"\"\"\n        Loads the documents from parts stored in the given directory.\n        \"\"\"\n        part_paths = glob.glob(os.path.join(directory_path, \"documents/*.json\"))\n        for part_path in part_paths:\n            with open(part_path, \"r\") as f:\n                part_documents = json.load(f)\n                for document_data in part_documents:\n                    document_type = document_data.pop(\"type\")\n                    document_module = importlib.import_module(f\"swarmauri.standard.documents.concrete.{document_type}\")\n                    document_class = getattr(document_module, document_type)\n                    document = document_class.from_dict(document_data)\n                    self.documents.append(document)\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/__init__.py",
        "content": "```swarmauri/standard/vector_stores/concrete/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/TFIDFVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/TFIDFVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.vectorizers.concrete.TFIDFVectorizer import TFIDFVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase\n\nclass TFIDFVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = TFIDFVectorizer()\n        self.metric = CosineDistance()\n        self.documents = []\n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)\n      \n\n    def add_document(self, document: IDocument) -> None:\n        self.documents.append(document)\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        self.documents.extend(documents)\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def get_document(self, doc_id: str) -> Union[IDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n\n    def get_all_documents(self) -> List[IDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [doc for doc in self.documents if doc.id != doc_id]\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        for i, document in enumerate(self.documents):\n            if document.id == doc_id:\n                self.documents[i] = updated_document\n                break\n\n        # Recalculate TF-IDF matrix for the current set of documents\n        self.vectorizer.fit([doc.content for doc in self.documents])\n\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        transform_matrix = self.vectorizer.fit_transform(query, self.documents)\n\n        # The inferred vector is the last vector in the transformed_matrix\n        # The rest of the matrix is what we are comparing\n        distances = self.metric.distances(transform_matrix[-1], transform_matrix[:-1])  \n\n        # Get the indices of the top_k most similar (least distant) documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        return [self.documents[i] for i in top_k_indices]\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/Doc2VecVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/Doc2VecVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vectorizers.concrete.Doc2VecVectorizer import Doc2VecVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase    \n\n\nclass Doc2VecVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = Doc2VecVectorizer()\n        self.metric = CosineDistance()\n        self.documents = []      \n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)\n\n    def add_document(self, document: IDocument) -> None:\n        self.documents.append(document)\n        self._recalculate_embeddings()\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        self.documents.extend(documents)\n        self._recalculate_embeddings()\n\n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n\n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [doc for doc in self.documents if doc.id != doc_id]\n        self._recalculate_embeddings()\n\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        for i, document in enumerate(self.documents):\n            if document.id == doc_id:\n                self.documents[i] = updated_document\n                break\n        self._recalculate_embeddings()\n\n    def _recalculate_embeddings(self):\n        # Recalculate document embeddings for the current set of documents\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count]) for _count, _d in enumerate(self.documents)\n            if _d.content]\n\n        self.documents = embedded_documents\n\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        query_vector = self.vectorizer.infer_vector(query)\n        document_vectors = [_d.embedding for _d in self.documents if _d.content]\n\n        distances = self.metric.distances(query_vector, document_vectors)\n\n        # Get the indices of the top_k least distant (most similar) documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        \n        return [self.documents[i] for i in top_k_indices]\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/MLMVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/MLMVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vectorizers.concrete.MLMVectorizer import MLMVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase    \n\nclass MLMVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = MLMVectorizer()  # Assuming this is already implemented\n        self.metric = CosineDistance()\n        self.documents: List[EmbeddedDocument] = []\n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)      \n\n    def add_document(self, document: IDocument) -> None:\n        self.documents.append(document)\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count])\n\n        for _count, _d in enumerate(self.documents) if _d.content]\n\n        self.documents = embedded_documents\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        self.documents.extend(documents)\n        documents_text = [_d.content for _d in self.documents if _d.content]\n        embeddings = self.vectorizer.fit_transform(documents_text)\n\n        embedded_documents = [EmbeddedDocument(id=_d.id, \n            content=_d.content, \n            metadata=_d.metadata, \n            embedding=embeddings[_count]) for _count, _d in enumerate(self.documents) \n            if _d.content]\n\n        self.documents = embedded_documents\n\n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n        \n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [_d for _d in self.documents if _d.id != doc_id]\n\n    def update_document(self, doc_id: str) -> None:\n        raise NotImplementedError('Update_document not implemented on BERTDocumentStore class.')\n        \n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        query_vector = self.vectorizer.infer_vector(query)\n        document_vectors = [_d.embedding for _d in self.documents if _d.content]\n        distances = self.metric.distances(query_vector, document_vectors)\n        \n        # Get the indices of the top_k most similar documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        \n        return [self.documents[i] for i in top_k_indices]\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vector_stores/concrete/SpatialDocVectorStore.py",
        "content": "```swarmauri/standard/vector_stores/concrete/SpatialDocVectorStore.py\nfrom typing import List, Union\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\nfrom swarmauri.standard.vectorizers.concrete.SpatialDocVectorizer import SpatialDocVectorizer\nfrom swarmauri.standard.distances.concrete.CosineDistance import CosineDistance\nfrom swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\nfrom swarmauri.standard.vector_stores.base.SaveLoadStoreBase import SaveLoadStoreBase    \n\nclass SpatialDocVectorStore(VectorDocumentStoreRetrieveBase, SaveLoadStoreBase):\n    def __init__(self):\n        self.vectorizer = SpatialDocVectorizer()  # Assuming this is already implemented\n        self.metric = CosineDistance()\n        self.documents: List[EmbeddedDocument] = []\n        SaveLoadStoreBase.__init__(self, self.vectorizer, self.documents)      \n\n    def add_document(self, document: IDocument) -> None:\n        self.add_documents([document])  # Reuse the add_documents logic for batch processing\n\n    def add_documents(self, documents: List[IDocument]) -> None:\n        chunks = [doc.content for doc in documents]\n        # Prepare a list of metadata dictionaries for each document based on the required special tokens\n        metadata_list = [{ \n            'dir': doc.metadata.get('dir', ''),\n            'type': doc.metadata.get('type', ''),\n            'section': doc.metadata.get('section', ''),\n            'path': doc.metadata.get('path', ''),\n            'paragraph': doc.metadata.get('paragraph', ''),\n            'subparagraph': doc.metadata.get('subparagraph', ''),\n            'chapter': doc.metadata.get('chapter', ''),\n            'title': doc.metadata.get('title', ''),\n            'subsection': doc.metadata.get('subsection', ''),\n        } for doc in documents]\n\n        # Use vectorize_document to process all documents with their corresponding metadata\n        embeddings = self.vectorizer.vectorize_document(chunks, metadata_list=metadata_list)\n        \n        # Create EmbeddedDocument instances for each document with the generated embeddings\n        for doc, embedding in zip(documents, embeddings):\n            embedded_doc = EmbeddedDocument(\n                id=doc.id, \n                content=doc.content, \n                metadata=doc.metadata, \n                embedding=embedding\n            )\n            self.documents.append(embedded_doc)\n\n    def get_document(self, doc_id: str) -> Union[EmbeddedDocument, None]:\n        for document in self.documents:\n            if document.id == doc_id:\n                return document\n        return None\n        \n    def get_all_documents(self) -> List[EmbeddedDocument]:\n        return self.documents\n\n    def delete_document(self, doc_id: str) -> None:\n        self.documents = [_d for _d in self.documents if _d.id != doc_id]\n\n    def update_document(self, doc_id: str) -> None:\n        raise NotImplementedError('Update_document not implemented on SpatialDocVectorStore class.')\n        \n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        query_vector = self.vectorizer.infer_vector(query)\n        document_vectors = [_d.embedding for _d in self.documents if _d.content]\n        distances = self.metric.distances(query_vector, document_vectors)\n        \n        # Get the indices of the top_k most similar documents\n        top_k_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:top_k]\n        \n        return [self.documents[i] for i in top_k_indices]\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/__init__.py",
        "content": "```swarmauri/standard/document_stores/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/base/__init__.py",
        "content": "```swarmauri/standard/document_stores/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/base/DocumentStoreBase.py",
        "content": "```swarmauri/standard/document_stores/base/DocumentStoreBase.py\nimport json\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.core.document_stores.IDocumentStore import IDocumentStore\n\nclass DocumentStoreBase(IDocumentStore, ABC):\n    \"\"\"\n    Abstract base class for document stores, implementing the IDocumentStore interface.\n\n    This class provides a standard API for adding, updating, getting, and deleting documents in a store.\n    The specifics of storing (e.g., in a database, in-memory, or file system) are to be implemented by concrete subclasses.\n    \"\"\"\n\n    @abstractmethod\n    def add_document(self, document: IDocument) -> None:\n        \"\"\"\n        Add a single document to the document store.\n\n        Parameters:\n        - document (IDocument): The document to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_documents(self, documents: List[IDocument]) -> None:\n        \"\"\"\n        Add multiple documents to the document store in a batch operation.\n\n        Parameters:\n        - documents (List[IDocument]): A list of documents to be added to the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_document(self, doc_id: str) -> Optional[IDocument]:\n        \"\"\"\n        Retrieve a single document by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to retrieve.\n\n        Returns:\n        - Optional[IDocument]: The requested document if found; otherwise, None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_documents(self) -> List[IDocument]:\n        \"\"\"\n        Retrieve all documents stored in the document store.\n\n        Returns:\n        - List[IDocument]: A list of all documents in the store.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_document(self, doc_id: str, updated_document: IDocument) -> None:\n        \"\"\"\n        Update a document in the document store.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to update.\n        - updated_document (IDocument): The updated document instance.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_document(self, doc_id: str) -> None:\n        \"\"\"\n        Delete a document from the document store by its identifier.\n\n        Parameters:\n        - doc_id (str): The unique identifier of the document to delete.\n        \"\"\"\n        pass\n    \n    def document_count(self):\n        return len(self.documents)\n    \n    def dump(self, file_path):\n        with open(file_path, 'w') as f:\n            json.dumps([each.__dict__ for each in self.documents], f, indent=4)\n            \n    def load(self, file_path):\n        with open(file_path, 'r') as f:\n            self.documents = json.loads(f)\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/base/DocumentStoreRetrieveBase.py",
        "content": "```swarmauri/standard/document_stores/base/DocumentStoreRetrieveBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom swarmauri.core.document_stores.IDocumentRetrieve import IDocumentRetrieve\nfrom swarmauri.core.documents.IDocument import IDocument\nfrom swarmauri.standard.document_stores.base.DocumentStoreBase import DocumentStoreBase\n\nclass DocumentStoreRetrieveBase(DocumentStoreBase, IDocumentRetrieve, ABC):\n\n        \n    @abstractmethod\n    def retrieve(self, query: str, top_k: int = 5) -> List[IDocument]:\n        \"\"\"\n        Retrieve the top_k most relevant documents based on the given query.\n        \n        Args:\n            query (str): The query string used for document retrieval.\n            top_k (int): The number of top relevant documents to retrieve.\n        \n        Returns:\n            List[IDocument]: A list of the top_k most relevant documents.\n        \"\"\"\n        pass\n```"
    },
    {
        "document_name": "swarmauri/standard/document_stores/concrete/__init__.py",
        "content": "```swarmauri/standard/document_stores/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/__init__.py",
        "content": "```swarmauri/standard/chunkers/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/base/__init__.py",
        "content": "```swarmauri/standard/chunkers/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/__init__.py",
        "content": "```swarmauri/standard/chunkers/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/SlidingWindowChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/SlidingWindowChunker.py\nfrom typing import List\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass SlidingWindowChunker(IChunker):\n    \"\"\"\n    A concrete implementation of IChunker that uses sliding window technique\n    to break the text into chunks.\n    \"\"\"\n    \n    def __init__(self, window_size: int, step_size: int, overlap: bool = True):\n        \"\"\"\n        Initialize the SlidingWindowChunker with specific window and step sizes.\n        \n        Parameters:\n        - window_size (int): The size of the window for each chunk (in terms of number of words).\n        - step_size (int): The step size for the sliding window (in terms of number of words).\n        - overlap (bool, optional): Whether the windows should overlap. Default is True.\n        \"\"\"\n        self.window_size = window_size\n        self.step_size = step_size if overlap else window_size  # Non-overlapping if window size equals step size.\n           \n    def chunk_text(self, text: str, *args, **kwargs) -> List[str]:\n        \"\"\"\n        Splits the input text into chunks based on the sliding window technique.\n        \n        Parameters:\n        - text (str): The input text to be chunked.\n        \n        Returns:\n        - List[str]: A list of text chunks.\n        \"\"\"\n        words = text.split()  # Tokenization by whitespaces. More sophisticated tokenization might be necessary.\n        chunks = []\n        \n        for i in range(0, len(words) - self.window_size + 1, self.step_size):\n            chunk = ' '.join(words[i:i+self.window_size])\n            chunks.append(chunk)\n        \n        return chunks\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/DelimiterBasedChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/DelimiterBasedChunker.py\nfrom typing import List, Union, Any\nimport re\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass DelimiterBasedChunker(IChunker):\n    \"\"\"\n    A concrete implementation of IChunker that splits text into chunks based on specified delimiters.\n    \"\"\"\n\n    def __init__(self, delimiters: List[str] = None):\n        \"\"\"\n        Initializes the chunker with a list of delimiters.\n\n        Parameters:\n        - delimiters (List[str], optional): A list of strings that will be used as delimiters for splitting the text.\n                                            If not specified, a default list of sentence-ending punctuation is used.\n        \"\"\"\n        if delimiters is None:\n            delimiters = ['.', '!', '?']  # Default delimiters\n        # Create a regex pattern that matches any of the specified delimiters.\n        # The pattern uses re.escape on each delimiter to ensure special regex characters are treated literally.\n        self.delimiter_pattern = f\"({'|'.join(map(re.escape, delimiters))})\"\n    \n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[str]:\n        \"\"\"\n        Chunks the given text based on the delimiters specified during initialization.\n\n        Parameters:\n        - text (Union[str, Any]): The input text to be chunked.\n\n        Returns:\n        - List[str]: A list of text chunks split based on the specified delimiters.\n        \"\"\"\n        # Split the text based on the delimiter pattern, including the delimiters in the result\n        chunks = re.split(self.delimiter_pattern, text)\n        # Combine delimiters with the preceding text chunk since re.split() separates them\n        combined_chunks = []\n        for i in range(0, len(chunks) - 1, 2):  # Step by 2 to process text chunk with its following delimiter\n            combined_chunks.append(chunks[i] + (chunks[i + 1] if i + 1 < len(chunks) else ''))\n        return combined_chunks\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/FixedLengthChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/FixedLengthChunker.py\nfrom typing import List, Union, Any\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass FixedLengthChunker(IChunker):\n    \"\"\"\n    Concrete implementation of IChunker that divides text into fixed-length chunks.\n    \n    This chunker breaks the input text into chunks of a specified size, making sure \n    that each chunk has exactly the number of characters specified by the chunk size, \n    except for possibly the last chunk.\n    \"\"\"\n\n    def __init__(self, chunk_size: int):\n        \"\"\"\n        Initializes a new instance of the FixedLengthChunker class with a specific chunk size.\n\n        Parameters:\n        - chunk_size (int): The fixed size (number of characters) for each chunk.\n        \"\"\"\n        self.chunk_size = chunk_size\n\n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[str]:\n        \"\"\"\n        Splits the input text into fixed-length chunks.\n\n        Parameters:\n        - text (Union[str, Any]): The input text to be chunked.\n        \n        Returns:\n        - List[str]: A list of text chunks, each of a specified fixed length.\n        \"\"\"\n        # Check if the input is a string, if not, attempt to convert to a string.\n        if not isinstance(text, str):\n            text = str(text)\n        \n        # Using list comprehension to split text into chunks of fixed size\n        chunks = [text[i:i+self.chunk_size] for i in range(0, len(text), self.chunk_size)]\n        \n        return chunks\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/SimpleSentenceChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/SimpleSentenceChunker.py\nimport re\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass SimpleSentenceChunker(IChunker):\n    \"\"\"\n    A simple implementation of the IChunker interface to chunk text into sentences.\n    \n    This class uses basic punctuation marks (., !, and ?) as indicators for sentence boundaries.\n    \"\"\"\n    \n    def chunk_text(self, text, *args, **kwargs):\n        \"\"\"\n        Chunks the given text into sentences using basic punctuation.\n\n        Args:\n            text (str): The input text to be chunked into sentences.\n        \n        Returns:\n            List[str]: A list of sentence chunks.\n        \"\"\"\n        # Split text using a simple regex pattern that looks for periods, exclamation marks, or question marks.\n        # Note: This is a very simple approach and might not work well with abbreviations or other edge cases.\n        sentence_pattern = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s'\n        sentences = re.split(sentence_pattern, text)\n        \n        # Filter out any empty strings that may have resulted from the split operation\n        sentences = [sentence.strip() for sentence in sentences if sentence]\n        \n        return sentences\n```"
    },
    {
        "document_name": "swarmauri/standard/chunkers/concrete/MdSnippetChunker.py",
        "content": "```swarmauri/standard/chunkers/concrete/MdSnippetChunker.py\nfrom typing import List, Union, Any, Optional\nimport re\nfrom swarmauri.core.chunkers.IChunker import IChunker\n\nclass MdSnippetChunker(IChunker):\n    def __init__(self, language: Optional[str] = None):\n        \"\"\"\n        Initializes the MdSnippetChunker with a specific programming language\n        to look for within Markdown fenced code blocks.\n        \"\"\"\n        self.language = language\n    \n    def chunk_text(self, text: Union[str, Any], *args, **kwargs) -> List[tuple]:\n        \"\"\"\n        Extracts paired comments and code blocks from Markdown content based on the \n        specified programming language.\n        \"\"\"\n        if self.language:\n            # If language is specified, directly extract the corresponding blocks\n            pattern = fr'```{self.language}\\s*(.*?)```'\n            scripts = re.findall(pattern, text, re.DOTALL)\n            comments_temp = re.split(pattern, text, flags=re.DOTALL)\n        else:\n            # Extract blocks and languages dynamically if no specific language is provided\n            scripts = []\n            languages = []\n            for match in re.finditer(r'```(\\w+)?\\s*(.*?)```', text, re.DOTALL):\n                if match.group(1) is not None:  # Checks if a language identifier is present\n                    languages.append(match.group(1))\n                    scripts.append(match.group(2))\n                else:\n                    languages.append('')  # Default to an empty string if no language is found\n                    scripts.append(match.group(2))\n            comments_temp = re.split(r'```.*?```', text, flags=re.DOTALL)\n\n        comments = [comment.strip() for comment in comments_temp]\n\n        if text.strip().startswith('```'):\n            comments = [''] + comments\n        if text.strip().endswith('```'):\n            comments.append('')\n\n        if self.language:\n            structured_output = [(comments[i], self.language, scripts[i].strip()) for i in range(len(scripts))]\n        else:\n            structured_output = [(comments[i], languages[i], scripts[i].strip()) for i in range(len(scripts))]\n\n        return structured_output\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/__init__.py",
        "content": "```swarmauri/standard/vectors/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/base/__init__.py",
        "content": "```swarmauri/standard/vectors/base/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/base/VectorBase.py",
        "content": "```swarmauri/standard/vectors/base/VectorBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\nimport json\nimport numpy as np\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass VectorBase(IVector, ABC):\n    def __init__(self, data: List[float]):\n        self._data = data\n\n    @property\n    def data(self) -> List[float]:\n        \"\"\"\n        Returns the vector's data.\n        \"\"\"\n        return self._data\n\n    def to_numpy(self) -> np.ndarray:\n        \"\"\"\n        Converts the vector into a numpy array.\n\n        Returns:\n            np.ndarray: The numpy array representation of the vector.\n        \"\"\"\n        return np.array(self._data)\n    \n    def __repr__(self):\n        return str(self.data)\n    \n    def __len__(self):\n        return len(self.data)\n\n    def to_dict(self) -> dict:\n        \"\"\"\n        Converts the vector into a dictionary suitable for JSON serialization.\n        This method needs to be called explicitly for conversion.\n        \"\"\"\n        return {'type': self.__class__.__name__,'data': self.data}\n\n    @classmethod\n    def from_dict(cls, data):\n        return cls(**data)\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/concrete/SimpleVector.py",
        "content": "```swarmauri/standard/vectors/concrete/SimpleVector.py\nfrom typing import List\nfrom swarmauri.standard.vectors.base.VectorBase import VectorBase\n\nclass SimpleVector(VectorBase):\n    def __init__(self, data: List[float]):\n        super().__init__(data)\n        \n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/concrete/__init__.py",
        "content": "```swarmauri/standard/vectors/concrete/__init__.py\n# -*- coding: utf-8 -*-\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/vectors/concrete/VectorProduct.py",
        "content": "```swarmauri/standard/vectors/concrete/VectorProduct.py\nimport numpy as np\nfrom typing import List\n\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.core.vectors.IVectorProduct import IVectorProduct\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\n\nclass VectorProduct(IVectorProduct):\n    def dot_product(self, vector_a: IVector, vector_b: IVector) -> float:\n        a = np.array(vector_a.data).flatten()\n        b = np.array(vector_b.data).flatten()\n        return np.dot(a, b)\n    \n    def cross_product(self, vector_a: IVector, vector_b: IVector) -> IVector:\n        if len(vector_a.data) != 3 or len(vector_b.data) != 3:\n            raise ValueError(\"Cross product is only defined for 3-dimensional vectors\")\n        a = np.array(vector_a.data)\n        b = np.array(vector_b.data)\n        cross = np.cross(a, b)\n        return SimpleVector(cross.tolist())\n    \n    def vector_triple_product(self, vector_a: IVector, vector_b: IVector, vector_c: IVector) -> IVector:\n        a = np.array(vector_a.data)\n        b = np.array(vector_b.data)\n        c = np.array(vector_c.data)\n        result = np.cross(a, np.cross(b, c))\n        return SimpleVector(result.tolist())\n    \n    def scalar_triple_product(self, vector_a: IVector, vector_b: IVector, vector_c: IVector) -> float:\n        a = np.array(vector_a.data)\n        b = np.array(vector_b.data)\n        c = np.array(vector_c.data)\n        return np.dot(a, np.cross(b, c))\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/__init__.py",
        "content": "```swarmauri/standard/vectorizers/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/base/__init__.py",
        "content": "```swarmauri/standard/vectorizers/base/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/__init__.py",
        "content": "```swarmauri/standard/vectorizers/concrete/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/Doc2VecVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/Doc2VecVectorizer.py\nfrom typing import List, Union, Any\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\nclass Doc2VecVectorizer(IVectorize, IFeature, ISaveModel):\n    def __init__(self):\n        self.model = Doc2Vec(vector_size=2000, window=10, min_count=1, workers=5)\n\n    def extract_features(self):\n        return list(self.model.wv.key_to_index.keys())\n\n    def fit(self, documents: List[str], labels=None) -> None:\n        tagged_data = [TaggedDocument(words=_d.split(), \n            tags=[str(i)]) for i, _d in enumerate(documents)]\n\n        self.model.build_vocab(tagged_data)\n        self.model.train(tagged_data, total_examples=self.model.corpus_count, epochs=self.model.epochs)\n\n    def transform(self, documents: List[str]) -> List[IVector]:\n        vectors = [self.model.infer_vector(doc.split()) for doc in documents]\n        return [SimpleVector(vector) for vector in vectors]\n\n    def fit_transform(self, documents: List[Union[str, Any]], **kwargs) -> List[IVector]:\n        \"\"\"\n        Fine-tunes the MLM and generates embeddings for the provided documents.\n        \"\"\"\n        self.fit(documents, **kwargs)\n        return self.transform(documents)\n\n    def infer_vector(self, data: str) -> IVector:\n        vector = self.model.infer_vector(data.split())\n        return SimpleVector(vector.squeeze().tolist())\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the Doc2Vec model to the specified path.\n        \"\"\"\n        self.model.save(path)\n    \n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads a Doc2Vec model from the specified path.\n        \"\"\"\n        self.model = Doc2Vec.load(path)\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/MLMVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/MLMVectorizer.py\nfrom typing import List, Union, Any\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset\n\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\nclass MLMVectorizer(IVectorize, IFeature, ISaveModel):\n    \"\"\"\n    IVectorize implementation that fine-tunes a Masked Language Model (MLM).\n    \"\"\"\n\n    def __init__(self, model_name='bert-base-uncased', \n        batch_size = 32, \n        learning_rate = 5e-5, \n        masking_ratio: float = 0.15, \n        randomness_ratio: float = 0.10,\n        add_new_tokens: bool = False):\n        \"\"\"\n        Initializes the vectorizer with a pre-trained MLM model and tokenizer for fine-tuning.\n        \n        Parameters:\n        - model_name (str): Identifier for the pre-trained model and tokenizer.\n        \"\"\"\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForMaskedLM.from_pretrained(model_name)\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(self.device)\n        self.epochs = 0\n        self.batch_size = batch_size\n        self.learning_rate = learning_rate\n        self.masking_ratio = masking_ratio\n        self.randomness_ratio = randomness_ratio\n        self.add_new_tokens = add_new_tokens\n        self.mask_token_id = self.tokenizer.convert_tokens_to_ids([self.tokenizer.mask_token])[0]\n\n    def extract_features(self):\n        raise NotImplementedError('Extract_features not implemented on MLMVectorizer.')\n\n    def _mask_tokens(self, encodings):\n        input_ids = encodings.input_ids.to(self.device)\n        attention_mask = encodings.attention_mask.to(self.device)\n\n        labels = input_ids.detach().clone()\n\n        probability_matrix = torch.full(labels.shape, self.masking_ratio, device=self.device)\n        special_tokens_mask = [\n            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n        ]\n        probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool, device=self.device), value=0.0)\n        masked_indices = torch.bernoulli(probability_matrix).bool()\n\n        labels[~masked_indices] = -100\n        \n        indices_replaced = torch.bernoulli(torch.full(labels.shape, self.masking_ratio, device=self.device)).bool() & masked_indices\n        input_ids[indices_replaced] = self.mask_token_id\n\n        indices_random = torch.bernoulli(torch.full(labels.shape, self.randomness_ratio, device=self.device)).bool() & masked_indices & ~indices_replaced\n        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long, device=self.device)\n        input_ids[indices_random] = random_words[indices_random]\n\n        return input_ids, attention_mask, labels\n\n    def fit(self, documents: List[Union[str, Any]]):\n        # Check if we need to add new tokens\n        if self.add_new_tokens:\n            new_tokens = self.find_new_tokens(documents)\n            if new_tokens:\n                num_added_toks = self.tokenizer.add_tokens(new_tokens)\n                if num_added_toks > 0:\n                    print(f\"Added {num_added_toks} new tokens.\")\n                    self.model.resize_token_embeddings(len(self.tokenizer))\n\n        encodings = self.tokenizer(documents, return_tensors='pt', padding=True, truncation=True, max_length=512)\n        input_ids, attention_mask, labels = self._mask_tokens(encodings)\n        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n        dataset = TensorDataset(input_ids, attention_mask, labels)\n        data_loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n\n        self.model.train()\n        for batch in data_loader:\n            batch = {k: v.to(self.device) for k, v in zip(['input_ids', 'attention_mask', 'labels'], batch)}\n            outputs = self.model(**batch)\n            loss = outputs.loss\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        self.epochs += 1\n        print(f\"Epoch {self.epochs} complete. Loss {loss.item()}\")\n\n    def find_new_tokens(self, documents):\n        # Identify unique words in documents that are not in the tokenizer's vocabulary\n        unique_words = set()\n        for doc in documents:\n            tokens = set(doc.split())  # Simple whitespace tokenization\n            unique_words.update(tokens)\n        existing_vocab = set(self.tokenizer.get_vocab().keys())\n        new_tokens = list(unique_words - existing_vocab)\n        return new_tokens if new_tokens else None\n\n    def transform(self, documents: List[Union[str, Any]]) -> List[IVector]:\n        \"\"\"\n        Generates embeddings for a list of documents using the fine-tuned MLM.\n        \"\"\"\n        self.model.eval()\n        embedding_list = []\n        \n        for document in documents:\n            inputs = self.tokenizer(document, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n            with torch.no_grad():\n                outputs = self.model(**inputs)\n            # Extract embedding (for simplicity, averaging the last hidden states)\n            if hasattr(outputs, 'last_hidden_state'):\n                embedding = outputs.last_hidden_state.mean(1)\n            else:\n                # Fallback or corrected attribute access\n                embedding = outputs['logits'].mean(1)\n            embedding = embedding.cpu().numpy()\n            embedding_list.append(SimpleVector(embedding.squeeze().tolist()))\n\n        return embedding_list\n\n    def fit_transform(self, documents: List[Union[str, Any]], **kwargs) -> List[IVector]:\n        \"\"\"\n        Fine-tunes the MLM and generates embeddings for the provided documents.\n        \"\"\"\n        self.fit(documents, **kwargs)\n        return self.transform(documents)\n\n    def infer_vector(self, data: Union[str, Any], *args, **kwargs) -> IVector:\n        \"\"\"\n        Generates an embedding for the input data.\n\n        Parameters:\n        - data (Union[str, Any]): The input data, expected to be a textual representation.\n                                  Could be a single string or a batch of strings.\n        \"\"\"\n        # Tokenize the input data and ensure the tensors are on the correct device.\n        self.model.eval()\n        inputs = self.tokenizer(data, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n\n        # Generate embeddings using the model\n        with torch.no_grad():\n            outputs = self.model(**inputs)\n\n        if hasattr(outputs, 'last_hidden_state'):\n            # Access the last layer and calculate the mean across all tokens (simple pooling)\n            embedding = outputs.last_hidden_state.mean(dim=1)\n        else:\n            embedding = outputs['logits'].mean(1)\n        # Move the embeddings back to CPU for compatibility with downstream tasks if necessary\n        embedding = embedding.cpu().numpy()\n\n        return SimpleVector(embedding.squeeze().tolist())\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the model and tokenizer to the specified directory.\n        \"\"\"\n        self.model.save_pretrained(path)\n        self.tokenizer.save_pretrained(path)\n\n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads the model and tokenizer from the specified directory.\n        \"\"\"\n        self.model = AutoModelForMaskedLM.from_pretrained(path)\n        self.tokenizer = AutoTokenizer.from_pretrained(path)\n        self.model.to(self.device)  # Ensure the model is loaded to the correct device\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/TFIDFVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/TFIDFVectorizer.py\nfrom typing import List, Union, Any\nimport joblib\nfrom sklearn.feature_extraction.text import TfidfVectorizer as SklearnTfidfVectorizer\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\n\nclass TFIDFVectorizer(IVectorize, IFeature, ISaveModel):\n    def __init__(self):\n        # Using scikit-learn's TfidfVectorizer as the underlying mechanism\n        self.model = SklearnTfidfVectorizer()\n        super().__init__()\n        \n    def extract_features(self):\n        return self.model.get_feature_names_out()\n\n    def fit(self, data: Union[str, Any]) -> List[IVector]:\n        \"\"\"\n        Vectorizes the input data using the TF-IDF scheme.\n\n        Parameters:\n        - data (Union[str, Any]): The input data to be vectorized. Expected to be a single string (document)\n                                  or a list of strings (corpus).\n\n        Returns:\n        - List[IVector]: A list containing IVector instances, each representing a document's TF-IDF vector.\n        \"\"\"\n        if isinstance(data, str):\n            data = [data]  # Convert a single string into a list for the vectorizer\n        \n        self.fit_matrix = self.model.fit_transform(data)\n\n        # Convert the sparse matrix rows into SimpleVector instances\n        vectors = [SimpleVector(vector.toarray().flatten()) for vector in self.fit_matrix]\n\n        return vectors\n\n    def fit_transform(self, data: Union[str, Any], documents) -> List[IVector]:\n        documents = [doc.content for doc in documents]\n        if isinstance(data, str):\n            data = [data]  # Convert a single string into a list for the vectorizer\n        documents.extend(data)\n\n        transform_matrix = self.model.fit_transform(documents)\n\n        # Convert the sparse matrix rows into SimpleVector instances\n        vectors = [SimpleVector(vector.toarray().flatten()) for vector in transform_matrix]\n        return vectors\n    \n    def transform(self, data: Union[str, Any], documents) -> List[IVector]:\n        raise NotImplementedError('Transform not implemented on TFIDFVectorizer.')\n\n    def infer_vector(self, data: str, documents) -> IVector:\n        documents = [doc.content for doc in documents]\n        documents.append(data)\n        tmp_tfidf_matrix = self.transform(documents)\n        query_vector = tmp_tfidf_matrix[-1]\n        return query_vector\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the TF-IDF model to the specified path using joblib.\n        \"\"\"\n        joblib.dump(self.model, path)\n    \n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads a TF-IDF model from the specified path using joblib.\n        \"\"\"\n        self.model = joblib.load(path)\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/NMFVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/NMFVectorizer.py\nimport joblib\n\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\nclass NMFVectorizer(IVectorize, IFeature, ISaveModel):\n    def __init__(self, n_components=10):\n        # Initialize TF-IDF Vectorizer\n        self.tfidf_vectorizer = TfidfVectorizer()\n        # Initialize NMF with the desired number of components\n        self.model = NMF(n_components=n_components)\n        self.feature_names = []\n\n    def fit(self, data):\n        \"\"\"\n        Fit the NMF model to data.\n\n        Args:\n            data (Union[str, Any]): The text data to fit.\n        \"\"\"\n        # Transform data into TF-IDF matrix\n        tfidf_matrix = self.tfidf_vectorizer.fit_transform(data)\n        # Fit the NMF model\n        self.model.fit(tfidf_matrix)\n        # Store feature names\n        self.feature_names = self.tfidf_vectorizer.get_feature_names_out()\n\n    def transform(self, data):\n        \"\"\"\n        Transform new data into NMF feature space.\n\n        Args:\n            data (Union[str, Any]): Text data to transform.\n\n        Returns:\n            List[IVector]: A list of vectors representing the transformed data.\n        \"\"\"\n        # Transform data into TF-IDF matrix\n        tfidf_matrix = self.tfidf_vectorizer.transform(data)\n        # Transform TF-IDF matrix into NMF space\n        nmf_features = self.model.transform(tfidf_matrix)\n\n        # Wrap NMF features in SimpleVector instances and return\n        return [SimpleVector(features.tolist()) for features in nmf_features]\n\n    def fit_transform(self, data):\n        \"\"\"\n        Fit the model to data and then transform it.\n        \n        Args:\n            data (Union[str, Any]): The text data to fit and transform.\n\n        Returns:\n            List[IVector]: A list of vectors representing the fitted and transformed data.\n        \"\"\"\n        self.fit(data)\n        return self.transform(data)\n\n    def infer_vector(self, data):\n        \"\"\"\n        Convenience method for transforming a single data point.\n        \n        Args:\n            data (Union[str, Any]): Single text data to transform.\n\n        Returns:\n            IVector: A vector representing the transformed single data point.\n        \"\"\"\n        return self.transform([data])[0]\n    \n    def extract_features(self):\n        \"\"\"\n        Extract the feature names from the TF-IDF vectorizer.\n        \n        Returns:\n            The feature names.\n        \"\"\"\n        return self.feature_names\n\n    def save_model(self, path: str) -> None:\n        \"\"\"\n        Saves the NMF model and TF-IDF vectorizer using joblib.\n        \"\"\"\n        # It might be necessary to save both tfidf_vectorizer and model\n        # Consider using a directory for 'path' or appended identifiers for each model file\n        joblib.dump(self.tfidf_vectorizer, f\"{path}_tfidf.joblib\")\n        joblib.dump(self.model, f\"{path}_nmf.joblib\")\n\n    def load_model(self, path: str) -> None:\n        \"\"\"\n        Loads the NMF model and TF-IDF vectorizer from paths using joblib.\n        \"\"\"\n        self.tfidf_vectorizer = joblib.load(f\"{path}_tfidf.joblib\")\n        self.model = joblib.load(f\"{path}_nmf.joblib\")\n        # Dependending on your implementation, you might need to refresh the feature_names\n        self.feature_names = self.tfidf_vectorizer.get_feature_names_out()\n```"
    },
    {
        "document_name": "swarmauri/standard/vectorizers/concrete/SpatialDocVectorizer.py",
        "content": "```swarmauri/standard/vectorizers/concrete/SpatialDocVectorizer.py\nimport numpy as np\n\nimport torch\nfrom torch import nn\nfrom transformers import BertTokenizer, BertModel\n\nfrom swarmauri.core.vectorizers.IVectorize import IVectorize\nfrom swarmauri.core.vectorizers.IFeature import IFeature\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.SimpleVector import SimpleVector\nfrom swarmauri.core.vectorizers.ISaveModel import ISaveModel\n\n\nclass SpatialDocVectorizer(IVectorize, ISaveModel, IFeature):\n    def __init__(self, special_tokens_dict=None):\n        self.special_tokens_dict = special_tokens_dict or {\n            'additional_special_tokens': [\n                '[DIR]', '[TYPE]', '[SECTION]', '[PATH]',\n                '[PARAGRAPH]', '[SUBPARAGRAPH]', '[CHAPTER]', '[TITLE]', '[SUBSECTION]'\n            ]\n        }\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        self.tokenizer.add_special_tokens(self.special_tokens_dict)\n        self.model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n        self.model.resize_token_embeddings(len(self.tokenizer))\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(self.device)\n\n    def add_metadata(self, text, metadata_dict):\n        metadata_components = []\n        for key, value in metadata_dict.items():\n            if f\"[{key.upper()}]\" in self.special_tokens_dict['additional_special_tokens']:\n                token = f\"[{key.upper()}={value}]\"\n                metadata_components.append(token)\n        metadata_str = ' '.join(metadata_components)\n        return metadata_str + ' ' + text if metadata_components else text\n\n    def tokenize_and_encode(self, text):\n        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        # Move the input tensors to the same device as the model\n        inputs = {key: value.to(self.device) for key, value in inputs.items()}\n        outputs = self.model(**inputs)\n        return outputs.pooler_output\n\n    def enhance_embedding_with_positional_info(self, embeddings, doc_position, total_docs):\n        position_effect = torch.sin(torch.tensor(doc_position / total_docs, dtype=torch.float))\n        enhanced_embeddings = embeddings + position_effect\n        return enhanced_embeddings\n\n    def vectorize_document(self, chunks, metadata_list=None):\n        all_embeddings = []\n        total_chunks = len(chunks)\n        if not metadata_list:\n            # Default empty metadata if none provided\n            metadata_list = [{} for _ in chunks]\n        \n        for i, (chunk, metadata) in enumerate(zip(chunks, metadata_list)):\n            # Use add_metadata to include any available metadata dynamically\n            embedded_text = self.add_metadata(chunk, metadata)\n            embeddings = self.tokenize_and_encode(embedded_text)\n            enhanced_embeddings = self.enhance_embedding_with_positional_info(embeddings, i, total_chunks)\n            all_embeddings.append(enhanced_embeddings)\n\n        return all_embeddings\n\n\n    def vectorize(self, text):\n        inputs = self.tokenize_and_encode(text)\n        return SimpleVector(data=inputs.cpu().detach().numpy().tolist())\n\n    def fit(self, data):\n        # Although this vectorizer might not need to be fitted in the traditional sense,\n        # this method placeholder allows integration into pipelines that expect a fit method.\n        return self\n\n    def transform(self, data):\n        if isinstance(data, list):\n            return [self.vectorize(text).data for text in data]\n        else:\n            return self.vectorize(data).data\n\n    def fit_transform(self, data):\n        self.fit(data)\n        return self.transform(data)\n\n    def infer_vector(self, data, *args, **kwargs):\n        return self.vectorize(data)\n\n    def save_model(self, path):\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'tokenizer': self.tokenizer\n        }, path)\n    \n    def load_model(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.tokenizer = checkpoint['tokenizer']\n\n    def extract_features(self, text):\n        inputs = self.tokenize_and_encode(text)\n        return SimpleVector(data=inputs.cpu().detach().numpy().tolist())\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/__init__.py",
        "content": "```swarmauri/standard/tracing/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/base/__init__.py",
        "content": "```swarmauri/standard/tracing/base/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/SimpleTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/SimpleTracer.py\nfrom datetime import datetime\nimport uuid\nfrom typing import Dict, Any, Optional\n\nfrom swarmauri.core.tracing.ITracer import ITracer\nfrom swarmauri.standard.tracing.concrete.SimpleTraceContext import SimpleTraceContext\n\nclass SimpleTracer(ITracer):\n    _instance = None  # Singleton instance placeholder\n\n    @classmethod\n    def instance(cls):\n        if cls._instance is None:\n            cls._instance = cls()\n        return cls._instance\n\n    def __init__(self):\n        if SimpleTracer._instance is not None:\n            raise RuntimeError(\"SimpleTracer is a singleton. Use SimpleTracer.instance().\")\n        self.trace_stack = []\n\n    def start_trace(self, name: str, initial_attributes: Optional[Dict[str, Any]] = None) -> SimpleTraceContext:\n        trace_id = str(uuid.uuid4())\n        trace_context = SimpleTraceContext(trace_id, name, initial_attributes)\n        self.trace_stack.append(trace_context)\n        return trace_context\n\n    def end_trace(self):\n        if self.trace_stack:\n            completed_trace = self.trace_stack.pop()\n            completed_trace.close()\n            # Example of simply printing the completed trace; in practice, you might log it or store it elsewhere\n            print(f\"Trace Completed: {completed_trace.name}, Duration: {completed_trace.start_time} to {completed_trace.end_time}, Attributes: {completed_trace.attributes}\")\n\n    def annotate_trace(self, key: str, value: Any):\n        if not self.trace_stack:\n            print(\"No active trace to annotate.\")\n            return\n        current_trace = self.trace_stack[-1]\n        current_trace.add_attribute(key, value)\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/TracedVariable.py",
        "content": "```swarmauri/standard/tracing/concrete/TracedVariable.py\nfrom typing import Any\nfrom swarmauri.standard.tracing.concrete.SimpleTracer import SimpleTracer  # Assuming this is the path to the tracer\n\nclass TracedVariable:\n    \"\"\"\n    Wrapper class to trace multiple changes to a variable within the context manager.\n    \"\"\"\n    def __init__(self, name: str, value: Any, tracer: SimpleTracer):\n        self.name = name\n        self._value = value\n        self._tracer = tracer\n        self._changes = []  # Initialize an empty list to track changes\n\n    @property\n    def value(self) -> Any:\n        return self._value\n\n    @value.setter\n    def value(self, new_value: Any):\n        # Record the change before updating the variable's value\n        change_annotation = {\"from\": self._value, \"to\": new_value}\n        self._changes.append(change_annotation)\n        \n        # Update the trace by appending the latest change to the list under a single key\n        # Note that the key is now constant and does not change with each update\n        self._tracer.annotate_trace(key=f\"{self.name}_changes\", value=self._changes)\n        \n        self._value = new_value\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/ChainTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/ChainTracer.py\nfrom swarmauri.core.tracing.IChainTracer import IChainTracer\nfrom typing import Callable, List, Tuple, Dict, Any   \n        \nclass ChainTracer(IChainTracer):\n    def __init__(self):\n        self.traces = []\n\n    def process_chain(self, chain: List[Tuple[Callable[..., Any], List[Any], Dict[str, Any]]]) -> \"ChainTracer\":\n        \"\"\"\n        Processes each item in the operation chain by executing the specified external function\n        with its args and kwargs. Logs starting, annotating, and ending the trace based on tuple position.\n\n        Args:\n            chain (List[Tuple[Callable[..., Any], List[Any], Dict[str, Any]]]): A list where each tuple contains:\n                - An external function to execute.\n                - A list of positional arguments for the function.\n                - A dictionary of keyword arguments for the function.\n        \"\"\"\n        for i, (func, args, kwargs) in enumerate(chain):\n            # Infer operation type and log\n            \n            if i == 0:\n                operation = \"Start\"\n                self.start_trace(*args, **kwargs)\n            elif i == len(chain) - 1:\n                operation = \"End\"\n                self.end_trace(*args, **kwargs)\n            else:\n                operation = \"Annotate\"\n                self.annotate_trace(*args, **kwargs)\n                \n            # For the actual external function call\n            result = func(*args, **kwargs)\n            print(f\"Function '{func.__name__}' executed with result: {result}\")\n\n            self.traces.append((operation, func, args, kwargs, result))\n\n        return self\n\n    def start_trace(self, *args, **kwargs) -> None:\n        print(f\"Starting trace with args: {args}, kwargs: {kwargs}\")\n        \n    def annotate_trace(self, *args, **kwargs) -> None:\n        print(f\"Annotating trace with args: {args}, kwargs: {kwargs}\")\n\n    def end_trace(self, *args, **kwargs) -> None:\n        print(f\"Ending trace with args: {args}, kwargs: {kwargs}\")\n\n    def show(self) -> None:\n        for entry in self.traces:\n            print(entry)\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/SimpleTraceContext.py",
        "content": "```swarmauri/standard/tracing/concrete/SimpleTraceContext.py\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\n\nfrom swarmauri.core.tracing.ITraceContext import ITraceContext\n\nclass SimpleTraceContext(ITraceContext):\n    def __init__(self, trace_id: str, name: str, initial_attributes: Optional[Dict[str, Any]] = None):\n        self.trace_id = trace_id\n        self.name = name\n        self.attributes = initial_attributes if initial_attributes else {}\n        self.start_time = datetime.now()\n        self.end_time = None\n\n    def get_trace_id(self) -> str:\n        return self.trace_id\n\n    def add_attribute(self, key: str, value: Any):\n        self.attributes[key] = value\n\n    def close(self):\n        self.end_time = datetime.now()\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/VariableTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/VariableTracer.py\nfrom contextlib import contextmanager\n\nfrom swarmauri.standard.tracing.concrete.TracedVariable import TracedVariable\nfrom swarmauri.standard.tracing.concrete.SimpleTracer import SimpleTracer\n\n# Initialize a global instance of SimpleTracer for use across the application\nglobal_tracer = SimpleTracer()\n\n@contextmanager\ndef VariableTracer(name: str, initial_value=None):\n    \"\"\"\n    Context manager for tracing the declaration, modification, and usage of a variable.\n    \"\"\"\n    trace_context = global_tracer.start_trace(name=f\"Variable: {name}\", initial_attributes={\"initial_value\": initial_value})\n    traced_variable = TracedVariable(name, initial_value, global_tracer)\n    \n    try:\n        yield traced_variable\n    finally:\n        # Optionally record any final value or state of the variable before it goes out of scope\n        global_tracer.annotate_trace(key=f\"{name}_final\", value={\"final_value\": traced_variable.value})\n        # End the trace, marking the variable's lifecycle\n        global_tracer.end_trace()\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/CallableTracer.py",
        "content": "```swarmauri/standard/tracing/concrete/CallableTracer.py\nimport functools\nfrom swarmauri.standard.tracing.concrete.SimpleTracer import SimpleTracer  # Import SimpleTracer from the previously defined path\n\n# Initialize the global tracer object\ntracer = SimpleTracer()\n\ndef CallableTracer(func):\n    \"\"\"\n    A decorator to trace function or method calls, capturing inputs, outputs, and the caller.\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Trying to automatically identify the caller details; practical implementations \n        # might need to adjust based on specific requirements or environment.\n        caller_info = f\"{func.__module__}.{func.__name__}\"\n        \n        # Start a new trace context for this callable\n        trace_context = tracer.start_trace(name=caller_info, initial_attributes={'args': args, 'kwargs': kwargs})\n        \n        try:\n            # Call the actual function/method\n            result = func(*args, **kwargs)\n            tracer.annotate_trace(key=\"result\", value=result)\n            return result\n        except Exception as e:\n            # Optionally annotate the trace with the exception details\n            tracer.annotate_trace(key=\"exception\", value=str(e))\n            raise  # Re-raise the exception to not interfere with the program's flow\n        finally:\n            # End the trace after the function call is complete\n            tracer.end_trace()\n    return wrapper\n```"
    },
    {
        "document_name": "swarmauri/standard/tracing/concrete/__init__.py",
        "content": "```swarmauri/standard/tracing/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/__init__.py",
        "content": "```swarmauri/standard/chains/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/__init__.py",
        "content": "```swarmauri/standard/chains/base/__init__.py\n#\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/ChainBase.py",
        "content": "```swarmauri/standard/chains/base/ChainBase.py\nfrom typing import List, Dict, Any\nfrom swarmauri.core.chains.IChain import IChain\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass ChainBase(IChain):\n    \"\"\"\n    A base implementation of the IChain interface.\n    \"\"\"\n\n    def __init__(self, \n                 steps: List[IChainStep] = None,\n                 **configs):\n        self.steps = steps if steps is not None else []\n        self.configs = configs\n\n    def add_step(self, step: IChainStep) -> None:\n        self.steps.append(step)\n\n    def remove_step(self, step: IChainStep) -> None:\n        \"\"\"\n        Removes an existing step from the chain. This alters the chain's execution sequence\n        by excluding the specified step from subsequent executions of the chain.\n\n        Parameters:\n            step (IChainStep): The Callable representing the step to remove from the chain.\n        \"\"\"\n\n        raise NotImplementedError('this is not yet implemented')\n\n    def execute(self, *args, **kwargs) -> Any:\n        raise NotImplementedError('this is not yet implemented')\n\n    def get_schema_info(self) -> Dict[str, Any]:\n        # Return a serialized version of the Chain instance's configuration\n        return {\n            \"steps\": [str(step) for step in self.steps],\n            \"configs\": self.configs\n        }\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/ChainStepBase.py",
        "content": "```swarmauri/standard/chains/base/ChainStepBase.py\nfrom typing import Any, Callable, List, Dict\nfrom swarmauri.core.chains.IChainStep import IChainStep\n\nclass ChainStepBase(IChainStep):\n    \"\"\"\n    Represents a single step within an execution chain.\n    \"\"\"\n    \n    def __init__(self, \n        key: str, \n        method: Callable, \n        args: List[Any] = None, \n        kwargs: Dict[str, Any] = None, \n        ref: str = None):\n        \"\"\"\n        Initialize a chain step.\n\n        Args:\n            key (str): Unique key or identifier for the step.\n            method (Callable): The callable object (function or method) to execute in this step.\n            args (List[Any], optional): Positional arguments for the callable.\n            kwargs (Dict[str, Any], optional): Keyword arguments for the callable.\n            ref (str, optional): Reference to another component or context variable, if applicable.\n        \"\"\"\n        self.key = key\n        self.method = method\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.ref = ref\n        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/ChainContextBase.py",
        "content": "```swarmauri/standard/chains/base/ChainContextBase.py\nfrom typing import Any, Callable, Dict, List\nimport re\n\nfrom swarmauri.core.chains.IChainContext import IChainContext\n\nclass ChainContextBase(IChainContext):\n    def __init__(self):\n        self._steps = []\n        self._context = {}\n\n    @property\n    def context(self) -> Dict[str, Any]:\n        return self._context\n\n    @context.setter\n    def context(self, value: Dict[str, Any]) -> None:\n        self._context = value\n\n    def update(self, **kwargs):\n        self.state.update(kwargs)\n\n    def get_value(self, key: str) -> Any:\n        return self._context.get(key)\n\n    def _resolve_fstring(self, template: str) -> str:\n        pattern = re.compile(r'{([^}]+)}')\n        def replacer(match):\n            expression = match.group(1)\n            try:\n                return str(eval(expression, {}, self._context))\n            except Exception as e:\n                print(f\"Failed to resolve expression: {expression}. Error: {e}\")\n                return f\"{{{expression}}}\"\n        return pattern.sub(replacer, template)\n\n    def _resolve_placeholders(self, value: Any) -> Any:\n        if isinstance(value, str):\n            return self._resolve_fstring(value)\n        elif isinstance(value, dict):\n            return {k: self._resolve_placeholders(v) for k, v in value.items()}\n        elif isinstance(value, list):\n            return [self._resolve_placeholders(v) for v in value]\n        else:\n            return value\n\n    def _resolve_ref(self, value: Any) -> Any:\n        if isinstance(value, str) and value.startswith('$'):\n            placeholder = value[1:]\n            return placeholder\n        return value\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/base/PromptContextChainBase.py",
        "content": "```swarmauri/standard/chains/base/PromptContextChainBase.py\n# swarmaurui/standard/chains/base/PromptStateChainBase.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Optional\nfrom collections import defaultdict, deque\nimport re\n\n\nfrom swarmaurui.standard.chains.concrete.ChainStep import ChainStep\nfrom swarmaurui.standard.chains.base.ChainContextBase import ChainContextBase\nfrom swarmaurui.standard.chains.base.ChainStateBase import ChainStateBase\nfrom swarmaurui.core.agents.IAgent import IAgent\nfrom swarmaurui.core.prompts.IPromptMatrix import IPromptMatrix\nfrom swarmaurui.core.chains.IChainDependencyResolver import IChainDependencyResolver\n\nclass PromptStateChainBase(ABC, ChainContextBase, ChainStateBase, IChainDependencyResolver):\n    def __init__(self, \n        prompt_matrix: IPromptMatrix, \n        agents: List[IAgent] = [], \n        context: Dict = {},\n        model_kwargs: Dict[str, Any] = {}):\n        ChainContextBase.__init__(self)\n        ChainStateBase.__init__(self)\n        self.prompt_matrix = prompt_matrix\n        self.response_matrix = [[None for _ in range(prompt_matrix.shape[1])] for _ in range(prompt_matrix.shape[0])]\n        self.agents = agents\n        self.context = context \n        self.model_kwargs = model_kwargs\n\n    @property\n    def context(self) -> Dict[str, Any]:\n        return self._context\n\n    @context.setter\n    def context(self, value: Dict[str, Any]) -> None:\n        self._context = value\n\n    def execute(self) -> None:\n        \"\"\"\n        Execute the chain of prompts based on the state of the prompt matrix.\n        Iterates through each sequence in the prompt matrix, resolves dependencies, \n        and executes prompts in the resolved order.\n        \"\"\"\n        steps = self.build_dependencies()\n        for step in steps:\n            method = step.method\n            args = step.args\n            ref = step.ref\n            result = method(*args)\n            self.context[ref] = result\n            self._update_response_matrix(args[0], result)\n\n    def _execute_prompt(self, agent_index: int, prompt: str, ref: str):\n        \"\"\"\n        Executes a given prompt using the specified agent and updates the response.\n        \"\"\"\n        formatted_prompt = prompt.format(**self.context)  # Using context for f-string formatting\n        agent = self.agents[agent_index]\n        response = agent.exec(formatted_prompt, model_kwargs=self.model_kwargs)\n        self.context[ref] = response\n        self._update_response_matrix(agent_index, response)\n        return response\n\n    def _update_response_matrix(self, agent_index: int, response: Any):\n        self.response_matrix[agent_index].append(response)\n    \n    def build_dependencies(self) -> List[ChainStep]:\n        \"\"\"\n        Build the chain steps in the correct order by resolving dependencies first.\n        \"\"\"\n        steps = []\n        for i, sequence in enumerate(self.prompt_matrix.matrix):\n            execution_order = self.resolve_dependencies(matrix=self.prompt_matrix.matrix, sequence_index=i)\n            for j in execution_order:\n                prompt = sequence[j]\n                if prompt:\n                    ref = f\"Agent_{i}_Step_{j}_response\"  # Using a unique reference string\n                    step = ChainStep(\n                        key=f\"Agent_{i}_Step_{j}\",\n                        method=self._execute_prompt,\n                        args=[i, prompt, ref],\n                        ref=ref\n                    )\n                    steps.append(step)\n        return steps\n\n    def resolve_dependencies(self, matrix: List[List[Optional[str]]], sequence_index: int) -> List[int]:\n        \"\"\"\n        Resolve dependencies within a specific sequence of the prompt matrix.\n        \n        Args:\n            matrix (List[List[Optional[str]]]): The prompt matrix.\n            sequence_index (int): The index of the sequence to resolve dependencies for.\n\n        Returns:\n            List[int]: The execution order of the agents for the given sequence.\n        \"\"\"\n        indegrees = defaultdict(int)\n        graph = defaultdict(list)\n        for agent_idx, prompt in enumerate(matrix[sequence_index]):\n            if prompt:\n                dependencies = re.findall(r'\\$\\d+_\\d+', prompt)\n                for dep in dependencies:\n                    # Extract index from the matched dependency pattern \"$x_y\"\n                    x = int(dep[1:])  # Remove leading \"$\" and convert to int\n                    graph[x].append(agent_idx)\n                    indegrees[agent_idx] += 1\n                if not dependencies:\n                    indegrees[agent_idx] = 0\n            else:\n                indegrees[agent_idx] = 0  # Ensure nodes without dependencies are in the graph\n        \n        queue = deque([idx for idx in indegrees if indegrees[idx] == 0])\n        execution_order = []\n        while queue:\n            current = queue.popleft()\n            execution_order.append(current)\n            for dependent in graph[current]:\n                indegrees[dependent] -= 1\n                if indegrees[dependent] == 0:\n                    queue.append(dependent)\n        if len(execution_order) != len(indegrees):\n            raise RuntimeError(\"There's a cyclic dependency or unresolved dependency in your prompt matrix.\")\n        return execution_order\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/__init__.py",
        "content": "```swarmauri/standard/chains/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/CallableChain.py",
        "content": "```swarmauri/standard/chains/concrete/CallableChain.py\nfrom typing import Any, Callable, List, Dict, Optional\nfrom swarmauri.core.chains.ICallableChain import ICallableChain, CallableDefinition\n\n\nclass CallableChain(ICallableChain):\n    def __init__(self, callables: Optional[List[CallableDefinition]] = None):\n        \n        self.callables = callables if callables is not None else []\n\n    def __call__(self, *initial_args, **initial_kwargs):\n        result = None\n        for func, args, kwargs in self.callables:\n            if result is not None:\n                # If there was a previous result, use it as the first argument for the next function\n                args = [result] + list(args)\n            result = func(*args, **kwargs)\n        return result\n    \n    def add_callable(self, func: Callable[[Any], Any], args: List[Any] = None, kwargs: Dict[str, Any] = None) -> None:\n        # Add a new callable to the chain\n        self.callables.append((func, args or [], kwargs or {}))\n    \n    def __or__(self, other: \"CallableChain\") -> \"CallableChain\":\n        if not isinstance(other, CallableChain):\n            raise TypeError(\"Operand must be an instance of CallableChain\")\n        \n        new_chain = CallableChain(self.callables + other.callables)\n        return new_chain\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/ChainStep.py",
        "content": "```swarmauri/standard/chains/concrete/ChainStep.py\nfrom typing import Any, Callable, List, Dict\nfrom swarmauri.core.chains.IChainStep import IChainStep\nfrom swarmauri.standard.chains.base.ChainStepBase import ChainStepBase\n\nclass ChainStep(ChainStepBase):\n    \"\"\"\n    Represents a single step within an execution chain.\n    \"\"\"\n    \n    def __init__(self, \n        key: str, \n        method: Callable, \n        args: List[Any] = None, \n        kwargs: Dict[str, Any] = None, \n        ref: str = None):\n        \"\"\"\n        Initialize a chain step.\n\n        Args:\n            key (str): Unique key or identifier for the step.\n            method (Callable): The callable object (function or method) to execute in this step.\n            args (List[Any], optional): Positional arguments for the callable.\n            kwargs (Dict[str, Any], optional): Keyword arguments for the callable.\n            ref (str, optional): Reference to another component or context variable, if applicable.\n        \"\"\"\n        self.key = key\n        self.method = method\n        self.args = args \n        self.kwargs = kwargs\n        self.ref = ref\n        \n\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/ContextChain.py",
        "content": "```swarmauri/standard/chains/concrete/ContextChain.py\n# standard/chains/concrete/ContextChain.py\nfrom typing import Any, Dict, List, Callable\nfrom swarmauri.standard.chains.base.ChainContextBase import ChainContextBase\nfrom swarmauri.standard.chains.base.ChainStep import ChainStep\nfrom swarmauri.core.chains.IChain import IChain\n\nclass ContextChain(IChain, ChainContextBase):\n    \"\"\"\n    Enhanced to support ChainSteps with return parameters, storing return values as instance state variables.\n    Implements the IChain interface including get_schema_info and remove_step methods.\n    \"\"\"\n    def __init__(self):\n        ChainContextBase.__init__(self)\n        self._steps: List[ChainStep] = []\n\n    def add_step(self, key: str, method: Callable[..., Any], *args, ref: str = None, **kwargs):\n        # Directly store args, kwargs, and optionally a return_key without resolving them\n        step = ChainStep(key, method, args=args, kwargs=kwargs, ref=ref)  # Note the use of 'ref' as 'return_key'\n        self._steps.append(step)\n\n    def remove_step(self, step: ChainStep) -> None:\n        self._steps = [s for s in self._steps if s.key != step.key]\n\n    def execute(self, *args, **kwargs) -> Any:\n        # Execute the chain and manage result storage based on return_key\n        for step in self._steps:\n            resolved_args = [self._resolve_placeholders(arg) for arg in step.args]\n            resolved_kwargs = {k: self._resolve_placeholders(v) for k, v in step.kwargs.items() if k != 'ref'}\n            result = step.method(*resolved_args, **resolved_kwargs)\n            if step.ref:  # step.ref is used here as the return_key analogy\n                resolved_ref = self._resolve_ref(step.ref)\n                self.context[resolved_ref] = result\n                self.update(**{resolved_ref: result})  # Update context with new state value\n        return self.context  # or any specific result you intend to return\n\n    def get_schema_info(self) -> Dict[str, Any]:\n        # Implementing required method from IChain; \n        # Adapt the return structure to your needs\n        return {\n            \"steps\": [step.key for step in self._steps],\n            \"state_keys\": list(self.context.keys())\n        }\n```"
    },
    {
        "document_name": "swarmauri/standard/chains/concrete/PromptContextChain.py",
        "content": "```swarmauri/standard/chains/concrete/PromptContextChain.py\nfrom typing import List, Dict, Any\nfrom core.prompts.IPromptMatrix import IPromptMatrix\nfrom standard.chains.base.PromptStateChainBase import PromptStateChainBase\n\nclass PromptContextChain(PromptStateChainBase):\n    def __init__(self, prompt_matrix: IPromptMatrix, \n        agents: List[IAgent] = [], context: Dict = {},\n        model_kwargs: Dict[str, Any] = {}\n        ):\n\n        PromptStateChainBase.__init__(self, prompt_matrix=prompt_matrix, agents=agents, \n            context=context, model_kwargs=model_kwargs)\n\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/__init__.py",
        "content": "```swarmauri/standard/distances/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/base/__init__.py",
        "content": "```swarmauri/standard/distances/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/ChiSquaredDistance.py",
        "content": "```swarmauri/standard/distances/concrete/ChiSquaredDistance.py\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass ChiSquaredDistance(IDistanceSimilarity):\n    \"\"\"\n    Implementation of the IDistanceSimilarity interface using Chi-squared distance metric.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Chi-squared distance between two vectors.\n        \"\"\"\n        if len(vector_a.data) != len(vector_b.data):\n            raise ValueError(\"Vectors must have the same dimensionality.\")\n\n        chi_squared_distance = 0\n        for a, b in zip(vector_a.data, vector_b.data):\n            if (a + b) != 0:\n                chi_squared_distance += (a - b) ** 2 / (a + b)\n\n        return 0.5 * chi_squared_distance\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the similarity between two vectors based on the Chi-squared distance.\n        \"\"\"\n        return 1 / (1 + self.distance(vector_a, vector_b))\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/CosineDistance.py",
        "content": "```swarmauri/standard/distances/concrete/CosineDistance.py\nfrom numpy.linalg import norm\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\nfrom swarmauri.standard.vectors.concrete.VectorProduct import VectorProduct\n\nclass CosineDistance(IDistanceSimilarity, VectorProduct):\n    \"\"\"\n    Implements cosine distance calculation as an IDistanceSimiliarity interface.\n    Cosine distance measures the cosine of the angle between two non-zero vectors\n    of an inner product space, capturing the orientation rather than the magnitude \n    of these vectors.\n    \"\"\"\n       \n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\" \n        Computes the cosine distance between two vectors: 1 - cosine similarity.\n    \n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n    \n        Returns:\n            float: The computed cosine distance between vector_a and vector_b.\n                   It ranges from 0 (completely similar) to 2 (completely dissimilar).\n        \"\"\"\n        norm_a = norm(vector_a.data)\n        norm_b = norm(vector_b.data)\n    \n        # Check if either of the vector norms is close to zero\n        if norm_a < 1e-10 or norm_b < 1e-10:\n            return 1.0  # Return maximum distance for cosine which varies between -1 to 1, so 1 indicates complete dissimilarity\n    \n        # Compute the cosine similarity between the vectors\n        cos_sim = self.dot_product(vector_a, vector_b) / (norm_a * norm_b)\n    \n        # Covert cosine similarity to cosine distance\n        cos_distance = 1 - cos_sim\n    \n        return cos_distance\n    \n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the cosine similarity between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The cosine similarity between vector_a and vector_b.\n        \"\"\"\n        return 1 - self.distance(vector_a, vector_b)\n\n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/EuclideanDistance.py",
        "content": "```swarmauri/standard/distances/concrete/EuclideanDistance.py\nfrom math import sqrt\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\n\nclass EuclideanDistance(IDistanceSimilarity):\n    \"\"\"\n    Class to compute the Euclidean distance between two vectors.\n    Implements the IDistanceSimiliarity interface.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Euclidean distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The computed Euclidean distance between vector_a and vector_b.\n        \"\"\"\n        if len(vector_a.data) != len(vector_b.data):\n            raise ValueError(\"Vectors do not have the same dimensionality.\")\n        \n        distance = sqrt(sum((a - b) ** 2 for a, b in zip(vector_a.data, vector_b.data)))\n        return distance\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the similarity score as the inverse of the Euclidean distance between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector in the comparison.\n            vector_b (IVector): The second vector in the comparison.\n\n        Returns:\n            float: The similarity score between vector_a and vector_b.\n        \"\"\"\n        distance = self.distance(vector_a, vector_b)\n        return 1 / (1 + distance)\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/JaccardIndexDistance.py",
        "content": "```swarmauri/standard/distances/concrete/JaccardIndexDistance.py\nfrom typing import List\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass JaccardIndexDistance(IDistanceSimilarity):\n    \"\"\"\n    A class implementing Jaccard Index as a similarity and distance metric between two vectors.\n    \"\"\"\n\n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Jaccard distance between two vectors.\n\n        The Jaccard distance, which is 1 minus the Jaccard similarity,\n        measures dissimilarity between sample sets. It's defined as\n        1 - (the intersection of the sets divided by the union of the sets).\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector.\n\n        Returns:\n            float: The Jaccard distance between vector_a and vector_b.\n        \"\"\"\n        set_a = set(vector_a.data)\n        set_b = set(vector_b.data)\n\n        # Calculate the intersection and union of the two sets.\n        intersection = len(set_a.intersection(set_b))\n        union = len(set_a.union(set_b))\n\n        # In the special case where the union is zero, return 1.0 which implies complete dissimilarity.\n        if union == 0:\n            return 1.0\n\n        # Compute Jaccard similarity and then return the distance as 1 - similarity.\n        jaccard_similarity = intersection / union\n        return 1 - jaccard_similarity\n\n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Computes the Jaccard similarity between two vectors.\n\n        Args:\n            vector_a (IVector): The first vector.\n            vector_b (IVector): The second vector.\n\n        Returns:\n            float: Jaccard similarity score between vector_a and vector_b.\n        \"\"\"\n        set_a = set(vector_a.data)\n        set_b = set(vector_b.data)\n\n        # Calculate the intersection and union of the two sets.\n        intersection = len(set_a.intersection(set_b))\n        union = len(set_a.union(set_b))\n\n        # In case the union is zero, which means both vectors have no elements, return 1.0 implying identical sets.\n        if union == 0:\n            return 1.0\n\n        # Compute and return Jaccard similarity.\n        return intersection / union\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/LevenshteinDistance.py",
        "content": "```swarmauri/standard/distances/concrete/LevenshteinDistance.py\nfrom typing import List\nimport numpy as np\nfrom swarmauri.core.distances.IDistanceSimilarity import IDistanceSimilarity\nfrom swarmauri.core.vectors.IVector import IVector\n\nclass LevenshteinDistance(IDistanceSimilarity):\n    \"\"\"\n    Implements the IDistance interface to calculate the Levenshtein distance between two vectors.\n    The Levenshtein distance between two strings is given by the minimum number of operations needed to transform\n    one string into the other, where an operation is an insertion, deletion, or substitution of a single character.\n    \"\"\"\n    \n    def distance(self, vector_a: IVector, vector_b: IVector) -> float:\n        \"\"\"\n        Compute the Levenshtein distance between two vectors.\n\n        Note: Since Levenshtein distance is typically calculated between strings,\n        it is assumed that the vectors represent strings where each element of the\n        vector corresponds to the ASCII value of a character in the string.\n\n        Args:\n            vector_a (List[float]): The first vector in the comparison.\n            vector_b (List[float]): The second vector in the comparison.\n\n        Returns:\n           float: The computed Levenshtein distance between vector_a and vector_b.\n        \"\"\"\n        string_a = ''.join([chr(int(round(value))) for value in vector_a.data])\n        string_b = ''.join([chr(int(round(value))) for value in vector_b.data])\n        \n        return self.levenshtein(string_a, string_b)\n    \n    def levenshtein(self, seq1: str, seq2: str) -> float:\n        \"\"\"\n        Calculate the Levenshtein distance between two strings.\n        \n        Args:\n            seq1 (str): The first string.\n            seq2 (str): The second string.\n        \n        Returns:\n            float: The Levenshtein distance between seq1 and seq2.\n        \"\"\"\n        size_x = len(seq1) + 1\n        size_y = len(seq2) + 1\n        matrix = np.zeros((size_x, size_y))\n        \n        for x in range(size_x):\n            matrix[x, 0] = x\n        for y in range(size_y):\n            matrix[0, y] = y\n\n        for x in range(1, size_x):\n            for y in range(1, size_y):\n                if seq1[x-1] == seq2[y-1]:\n                    matrix[x, y] = min(matrix[x-1, y] + 1, matrix[x-1, y-1], matrix[x, y-1] + 1)\n                else:\n                    matrix[x, y] = min(matrix[x-1, y] + 1, matrix[x-1, y-1] + 1, matrix[x, y-1] + 1)\n        \n        return matrix[size_x - 1, size_y - 1]\n    \n    def similarity(self, vector_a: IVector, vector_b: IVector) -> float:\n        string_a = ''.join([chr(int(round(value))) for value in vector_a.data])\n        string_b = ''.join([chr(int(round(value))) for value in vector_b.data])\n        return 1 - self.levenshtein(string_a, string_b) / max(len(vector_a), len(vector_b))\n    \n    def distances(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        distances = [self.distance(vector_a, vector_b) for vector_b in vectors_b]\n        return distances\n    \n    def similarities(self, vector_a: IVector, vectors_b: List[IVector]) -> List[float]:\n        similarities = [self.similarity(vector_a, vector_b) for vector_b in vectors_b]\n        return similarities\n```"
    },
    {
        "document_name": "swarmauri/standard/distances/concrete/__init__.py",
        "content": "```swarmauri/standard/distances/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/__init__.py",
        "content": "```swarmauri/standard/metrics/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/__init__.py",
        "content": "```swarmauri/standard/metrics/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/MetricBase.py",
        "content": "```swarmauri/standard/metrics/base/MetricBase.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.metrics.IMetric import IMetric\n\nclass MetricBase(IMetric, ABC):\n    \"\"\"\n    A base implementation of the IMetric interface that provides the foundation\n    for specific metric implementations.\n    \"\"\"\n\n    def __init__(self, name: str, unit: str):\n        \"\"\"\n        Initializes the metric with a name and unit of measurement.\n\n        Args:\n            name (str): The name of the metric.\n            unit (str): The unit of measurement for the metric (e.g., 'seconds', 'accuracy').\n        \"\"\"\n        self._name = name\n        self._unit = unit\n        self._value = None  # Initialize with None, or a default value as appropriate\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        The metric's name identifier.\n        \"\"\"\n        return self._name\n\n    @property\n    def value(self) -> Any:\n        \"\"\"\n        The current value of the metric.\n        \"\"\"\n        return self._value\n\n    @property\n    def unit(self) -> str:\n        \"\"\"\n        The unit of measurement for the metric.\n        \"\"\"\n        return self._unit\n\n    @unit.setter\n    def unit(self, value: str) -> None:\n        \"\"\"\n        Set the unit of measurement for the metric.\n        \"\"\"\n        self._unit = value\n\n    @abstractmethod\n    def __call__(self, **kwargs) -> Any:\n        \"\"\"\n        Retrieves the current value of the metric.\n\n        Returns:\n            The current value of the metric.\n        \"\"\"\n        return self.value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/CalculateMetricBase.py",
        "content": "```swarmauri/standard/metrics/base/CalculateMetricBase.py\nfrom typing import Any\nfrom abc import ABC, abstractmethod\nfrom swarmauri.core.metrics.IMetric import IMetric\nfrom swarmauri.core.metrics.ICalculateMetric import ICalculateMetric\n\nclass CalculateMetricBase(IMetric, ICalculateMetric, ABC):\n    \"\"\"\n    A base implementation of the IMetric interface that provides the foundation\n    for specific metric implementations.\n    \"\"\"\n\n    def __init__(self, name: str, unit: str):\n        \"\"\"\n        Initializes the metric with a name and unit of measurement.\n\n        Args:\n            name (str): The name of the metric.\n            unit (str): The unit of measurement for the metric (e.g., 'seconds', 'accuracy').\n        \"\"\"\n        self._name = name\n        self._unit = unit\n        self._value = None  # Initialize with None, or a default value as appropriate\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        The metric's name identifier.\n        \"\"\"\n        return self._name\n\n    @property\n    def value(self):\n        \"\"\"\n        The current value of the metric.\n        \"\"\"\n        return self._value\n\n    @property\n    def unit(self) -> str:\n        \"\"\"\n        The unit of measurement for the metric.\n        \"\"\"\n        return self._unit\n\n    @unit.setter\n    def unit(self, value: str) -> None:\n        \"\"\"\n        Set the unit of measurement for the metric.\n        \"\"\"\n        self._unit = value\n\n    @abstractmethod\n    def calculate(self, **kwargs) -> Any:\n        \"\"\"\n        Calculate the metric based on the provided data.\n        This method must be implemented by subclasses to define specific calculation logic.\n        \"\"\"\n        raise NotImplementedError('calculate is not implemented yet.')\n\n    def update(self, value) -> None:\n        \"\"\"\n        Update the metric value based on new information.\n        This should be used internally by the `calculate` method or other logic.\n        \"\"\"\n        self._value = value\n\n    def __call__(self, **kwargs) -> Any:\n        \"\"\"\n        Calculates the metric, updates the value, and returns the current value.\n        \"\"\"\n        self.calculate(**kwargs)\n        return self.value\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/AggregateMetricBase.py",
        "content": "```swarmauri/standard/metrics/base/AggregateMetricBase.py\nfrom typing import List, Any\nfrom abc import ABC, abstractmethod\nfrom swarmauri.standard.metrics.base.CalculateMetricBase import CalculateMetricBase\nfrom swarmauri.core.metrics.IAggMeasurements import IAggMeasurements\n\nclass AggregateMetricBase(CalculateMetricBase, IAggMeasurements, ABC):\n    \"\"\"\n    An abstract base class that implements the IMetric interface, providing common \n    functionalities and properties for metrics within SwarmAURI.\n    \"\"\"\n    def __init__(self, name: str, unit: str):\n        CalculateMetricBase.__init__(name, unit)\n        self._measurements = []\n\n    @abstractmethod\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds measurement to the internal store of measurements.\n        \"\"\"\n        self._measurements.append(measurement)\n\n    @property\n    def measurements(self) -> List[Any]:\n        return self._measurements\n\n    @measurements.setter\n    def measurements(self, value) -> None:\n        self._measurements = value\n\n    def reset(self) -> None:\n        \"\"\"\n        Resets the metric's state/value, allowing for fresh calculations.\n        \"\"\"\n        self._measurements.clear()\n        self._value = None\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/base/ThresholdMetricBase.py",
        "content": "```swarmauri/standard/metrics/base/ThresholdMetricBase.py\nfrom abc import ABC, abstractmethod\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\nfrom swarmauri.core.metrics.IAggMeasurements import IAggMeasurements\nfrom swarmauri.core.metrics.IThreshold import IThreshold\n\nclass ThresholdMetricBase(AggregateMetricBase, IAggMeasurements, ABC):\n    \"\"\"\n    An abstract base class that implements the IMetric interface, providing common \n    functionalities and properties for metrics within SwarmAURI.\n    \"\"\"\n    def __init__(self, name: str, unit: str, k: int):\n        AggregateMetricBase.__init__(name, unit)\n        self._k = k\n\n    @property\n    @abstractmethod\n    def k(self) -> int:\n        return self._k\n\n    @k.setter\n    @abstractmethod\n    def k(self, value: int) -> None:\n        self._k = value\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/__init__.py",
        "content": "```swarmauri/standard/metrics/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/TaskSuccessRateMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/TaskSuccessRateMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass TaskSuccessRateMetric(AggregateMetricBase):\n    \"\"\"\n    Metric calculating the task success rate over all attempted tasks.\n    \"\"\"\n    \n    def __init__(self):\n        super().__init__(name=\"TaskSuccessRate\", unit=\"percentage\")\n        self.total_tasks = 0\n        self.successful_tasks = 0\n\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds a task outcome to the metrics. Measurement should be a boolean indicating task success.\n        \"\"\"\n        self.total_tasks += 1\n        if measurement:\n            self.successful_tasks += 1\n\n    def calculate(self, **kwargs) -> float:\n        \"\"\"\n        Calculate the success rate of tasks based on the total and successful tasks.\n\n        Returns:\n            float: The success rate as a percentage.\n        \"\"\"\n        if self.total_tasks == 0:\n            return 0.0\n        success_rate = (self.successful_tasks / self.total_tasks) * 100\n        self.update(success_rate)\n        return self.value\n    \n    @property\n    def measurements(self):\n        return {\"total_tasks\": self.total_tasks, \"successful_tasks\": self.successful_tasks} \n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/TimeOnTaskMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/TimeOnTaskMetric.py\nimport statistics\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass TimeOnTaskMetric(AggregateMetricBase):\n    \"\"\"\n    Metric to calculate the average time users spend on a given task.\n    \"\"\"\n    def __init__(self, name=\"Time on Task\", unit=\"seconds\"):\n        super().__init__(name, unit)\n\n    def calculate(self, **kwargs):\n        \"\"\"\n        Calculate the average time on task based on the collected measurements.\n        \"\"\"\n        if not self.measurements:\n            return 0\n        return statistics.mean(self.measurements)\n\n    def add_measurement(self, seconds: float) -> None:\n        \"\"\"\n        Adds a measurement of time (in seconds) that a user spent on a task.\n        \"\"\"\n        if seconds < 0:\n            raise ValueError(\"Time on task cannot be negative.\")\n        super().add_measurement(seconds)\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/StaticValueMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/StaticValueMetric.py\nfrom swarmauri.standard.metrics.base.MetricBase import MetricBase\n\n# Implementing a StaticValueMetric class\nclass StaticValueMetric(MetricBase):\n    \"\"\"\n    A static metric that always returns a fixed, predefined value.\n    \n    Attributes:\n        name (str): The name of the metric.\n        unit (str): The unit of measurement for the metric.\n        _value (Any): The static value of the metric.\n    \"\"\"\n    def __init__(self, name: str, unit: str, value):\n        \"\"\"\n        Initialize the static metric with its name, unit, and static value.\n\n        Args:\n            name (str): The name identifier for the metric.\n            unit (str): The unit of measurement for the metric.\n            value: The static value for this metric.\n        \"\"\"\n        # Initialize attributes from the base class\n        super().__init__(name, unit)\n        # Assign the static value\n        self._value = value\n\n    # Overriding the 'value' property to always return the static value\n    @property\n    def value(self):\n        \"\"\"\n        Overridden to return the predefined static value for this metric.\n        \"\"\"\n        return self._value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/MeanMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/MeanMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass MeanMetric(AggregateMetricBase):\n    \"\"\"\n    A metric that calculates the mean (average) of a list of numerical values.\n\n    Attributes:\n        name (str): The name of the metric.\n        unit (str): The unit of measurement for the mean (e.g., \"degrees\", \"points\").\n        _value (float): The calculated mean of the measurements.\n        _measurements (list): A list of measurements (numerical values) to average.\n    \"\"\"\n    def __init__(self, name: str, unit: str):\n        \"\"\"\n        Initialize the MeanMetric with its name and unit.\n\n        Args:\n            name (str): The name identifier for the metric.\n            unit (str): The unit of measurement for the mean.\n        \"\"\"\n        # Calling the constructor of the base class\n        super().__init__(name, unit)\n    \n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds a measurement to the internal list of measurements.\n\n        Args:\n            measurement (float): A numerical value to be added to the list of measurements.\n        \"\"\"\n        # Append the measurement to the internal list\n        self._measurements.append(measurement)\n\n    def calculate(self) -> float:\n        \"\"\"\n        Calculate the mean of all added measurements.\n        \n        Returns:\n            float: The mean of the measurements or None if no measurements have been added.\n        \"\"\"\n        if not self._measurements:\n            return None  # Return None if there are no measurements\n        # Calculate the mean\n        mean = sum(self._measurements) / len(self._measurements)\n        # Update the metric's value\n        self.update(mean)\n        # Return the calculated mean\n        return mean\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/ThresholdMeanMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/ThresholdMeanMetric.py\nfrom swarmauri.standard.metrics.base.ThresholdMetricBase import ThresholdMetricBase\n\nclass ThresholdMeanMetric(ThresholdMetricBase):\n    \"\"\"\n    Calculates the mean of measurements that fall within a specified threshold from the current mean.\n    \"\"\"\n\n    def is_within_threshold(self, measurement: float) -> bool:\n        if self._value is None:  # If there's no current value, accept the measurement\n            return True\n        return abs(measurement - self._value) <= self.threshold\n    \n    def calculate(self) -> float:\n        # Filtering the measurements based on the threshold\n        filtered_measurements = [m for m in self._measurements if self.is_within_threshold(m)]\n\n        # Calculate the mean of filtered measurements\n        if not filtered_measurements:\n            return None  # Return None if there are no measurements within the threshold\n\n        mean_value = sum(filtered_measurements) / len(filtered_measurements)\n        self.update(mean_value)\n        return mean_value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/ZeroMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/ZeroMetric.py\nfrom swarmauri.standard.metrics.base.MetricBase import MetricBase\n\nclass ZeroMetric(MetricBase):\n    \"\"\"\n    A concrete implementation of MetricBase that statically represents the value 0.\n    This can be used as a placeholder or default metric where dynamic calculation is not required.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(name=\"ZeroMetric\", unit=\"unitless\")\n\n    @property\n    def value(self):\n        \"\"\"\n        Overrides the value property to always return 0.\n        \"\"\"\n        return 0\n\n\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/SystemUsabilityScaleMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/SystemUsabilityScaleMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass SystemUsabilityScaleMetric(AggregateMetricBase):\n    \"\"\"\n    Metric calculating the System Usability Scale (SUS) score based on a set of questionnaire responses.\n    \"\"\"\n    \n    def __init__(self):\n        super().__init__(name=\"SystemUsabilityScale\", unit=\"SUS score\")\n\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds individual SUS questionnaire item scores (ranging from 0-4) to the measurements.\n        \"\"\"\n        if isinstance(measurement, list) and all(isinstance(item, int) and 0 <= item <= 4 for item in measurement):\n            self._measurements.extend(measurement)\n        else:\n            raise ValueError(\"Each measurement must be a list of integers between 0 and 4.\")\n\n    def calculate(self, **kwargs) -> float:\n        \"\"\"\n        Calculate the SUS score from the current measurements.\n        \n        Returns:\n            float: The calculated SUS score.\n        \"\"\"\n        if len(self._measurements) != 10:\n            raise ValueError(\"Exactly 10 measurements are required to calculate the SUS score.\")\n        \n        # Adjust scores for negative items: subtract each score from 4\n        adjusted_scores = [self._measurements[i] if i % 2 == 0 else 4 - self._measurements[i] for i in range(10)]\n        \n        # Calculate the SUS score: multiply the sum of scores by 2.5\n        sus_score = sum(adjusted_scores) * 2.5\n        self.update(sus_score)\n        return self.value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/FirstImpressionMetric.py",
        "content": "```swarmauri/standard/metrics/concrete/FirstImpressionMetric.py\nfrom swarmauri.standard.metrics.base.AggregateMetricBase import AggregateMetricBase\n\nclass FirstImpressionMetric(AggregateMetricBase):\n    \"\"\"\n    Metric for capturing the first impression score from a set of scores.\n    \"\"\"\n\n    def __init__(self, name=\"FirstImpressionScore\", unit=\"points\"):\n        super().__init__(name=name, unit=unit)\n        self._first_impression = None\n\n    def add_measurement(self, measurement) -> None:\n        \"\"\"\n        Adds a new score as a measurement. Only the first score is considered as the first impression.\n        \"\"\"\n        if self._first_impression is None:\n            if isinstance(measurement, (int, float)):\n                self._first_impression = measurement\n                self._measurements.append(measurement)\n            else:\n                raise ValueError(\"Measurement must be a numerical value.\")\n    \n    def calculate(self) -> float:\n        \"\"\"\n        Returns the first impression score.\n\n        Returns:\n            float: The first impression score.\n        \"\"\"\n        if self._first_impression is None:\n            raise ValueError(\"No measurement added. Unable to calculate first impression score.\")\n        \n        self.update(self._first_impression)\n        return self.value\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/HitRateAtK.py",
        "content": "```swarmauri/standard/metrics/concrete/HitRateAtK.py\nfrom typing import List, Tuple, Any\nfrom swarmauri.standard.metrics.base.ThresholdMetricBase import ThresholdMetricBase\n\nclass HitRateAtK(ThresholdMetricBase):\n    \"\"\"\n    Hit Rate at K (HR@K) metric calculates the proportion of times an item of interest \n    appears in the top-K recommendations.\n    \"\"\"\n\n    def __init__(self, name=\"HitRate@K\", unit=\"ratio\", k: int = 5):\n        \"\"\"\n        Initializes the Hit Rate at K metric with a specified k value, name, and unit \n        of measurement.\n        \n        Args:\n            k (int): The k value for the top-K recommendations.\n            name (str): The name of the metric.\n            unit (str): The unit of measurement for the metric.\n        \"\"\"\n        super().__init__(name=name, unit=unit, k=k)\n\n    def add_measurement(self, measurement: Tuple[List[Any], Any]) -> None:\n        \"\"\"\n        Adds a measurement for HR@K calculation. The measurement should be a tuple\n        (recommendations, target), where recommendations is a list of recommended items, \n        and target is the item of interest.\n\n        Args:\n            measurement (Tuple[List[Any], Any]): List of recommended items and the target item.\n        \"\"\"\n        if len(measurement) != 2 or not isinstance(measurement[0], list):\n            raise ValueError(\"Measurement must be a tuple (recommendations, target).\")\n        self._measurements.append(measurement)\n\n    def calculate(self) -> Any:\n        \"\"\"\n        Calculate the HR@K based on the provided measurements.\n\n        Returns:\n            Any: The HR@K score as a floating point number.\n        \"\"\"\n        if not self._measurements:\n            raise ValueError(\"No measurements added to calculate HR@K.\")\n\n        hits = 0\n        for recommendations, target in self._measurements:\n            hits += 1 if target in recommendations[:self.k] else 0\n\n        hit_rate_at_k = hits / len(self._measurements)\n\n        self.update(hit_rate_at_k)\n        return self.value\n\n    def reset(self) -> None:\n        \"\"\"\n        Resets the metric's state/value, allowing for fresh calculations.\n        \"\"\"\n        super().reset()\n```"
    },
    {
        "document_name": "swarmauri/standard/metrics/concrete/ImpressionAtK.py",
        "content": "```swarmauri/standard/metrics/concrete/ImpressionAtK.py\nfrom swarmauri.standard.metrics.base.ThresholdMetricBase import ThresholdMetricBase\n\nclass ImpressionAtKMetric(ThresholdMetricBase):\n    def __init__(self, k: int):\n        super().__init__(name=\"Impression at K\", unit=\"count\", k=k)\n    \n    def calculate(self, impressions, **kwargs):\n        if not isinstance(impressions, list):\n            raise ValueError(\"Impressions should be provided as a list\")\n        \n        k_impressions = impressions[:self._k] if len(impressions) >= self._k else impressions\n\n        self._value = len([imp for imp in k_impressions if imp > 0])\n        return self._value\n\n    def reset(self):\n        self._value = 0\n    \n    def update(self, value):\n        raise NotImplementedError(\"This Metric does not support update operation directly.\")\n    \n    def __call__(self, **kwargs):\n        \"\"\"\n        Retrieves the current value of the metric.\n        \n        Returns:\n            The current value of the metric if calculated; otherwise, triggers a calculation.\n        \"\"\"\n        if 'impressions' in kwargs:\n            return self.calculate(kwargs['impressions'])\n        return self._value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/__init__.py",
        "content": "```swarmauri/standard/agent_factories/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/base/__init__.py",
        "content": "```swarmauri/standard/agent_factories/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/AgentFactory.py",
        "content": "```swarmauri/standard/agent_factories/concrete/AgentFactory.py\nimport json\nfrom datetime import datetime\nfrom typing import Callable, Dict, Any\nfrom swarmauri.core.agents.IAgent import IAgent\nfrom swarmauri.core.agentfactories.IAgentFactory import IAgentFactory\nfrom swarmauri.core.agentfactories.IExportConf import IExportConf\n\nclass AgentFactory(IAgentFactory, IExportConf):\n    def __init__(self):\n        \"\"\" Initializes the AgentFactory with an empty registry and metadata. \"\"\"\n        self._registry: Dict[str, Callable[..., IAgent]] = {}\n        self._metadata = {\n            'id': None,\n            'name': 'DefaultAgentFactory',\n            'type': 'Generic',\n            'date_created': datetime.now(),\n            'last_modified': datetime.now()\n        }\n    \n    # Implementation of IAgentFactory methods\n    def create_agent(self, agent_type: str, **kwargs) -> IAgent:\n        if agent_type not in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is not registered.\")\n        \n        constructor = self._registry[agent_type]\n        return constructor(**kwargs)\n\n    def register_agent(self, agent_type: str, constructor: Callable[..., IAgent]) -> None:\n        if agent_type in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is already registered.\")\n        self._registry[agent_type] = constructor\n        self._metadata['last_modified'] = datetime.now()\n    \n    # Implementation of IExportConf methods\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Exports the registry metadata as a dictionary.\"\"\"\n        export_data = self._metadata.copy()\n        export_data['registry'] = list(self._registry.keys())\n        return export_data\n\n    def to_json(self) -> str:\n        \"\"\"Exports the registry metadata as a JSON string.\"\"\"\n        return json.dumps(self.to_dict(), default=str, indent=4)\n\n    def export_to_file(self, file_path: str) -> None:\n        \"\"\"Exports the registry metadata to a file.\"\"\"\n        with open(file_path, 'w') as f:\n            f.write(self.to_json())\n    \n    @property\n    def id(self) -> int:\n        return self._metadata['id']\n\n    @id.setter\n    def id(self, value: int) -> None:\n        self._metadata['id'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def name(self) -> str:\n        return self._metadata['name']\n\n    @name.setter\n    def name(self, value: str) -> None:\n        self._metadata['name'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def type(self) -> str:\n        return self._metadata['type']\n\n    @type.setter\n    def type(self, value: str) -> None:\n        self._metadata['type'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def date_created(self) -> datetime:\n        return self._metadata['date_created']\n\n    @property\n    def last_modified(self) -> datetime:\n        return self._metadata['last_modified']\n\n    @last_modified.setter\n    def last_modified(self, value: datetime) -> None:\n        self._metadata['last_modified'] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/ConfDrivenAgentFactory.py",
        "content": "```swarmauri/standard/agent_factories/concrete/ConfDrivenAgentFactory.py\nimport json\nimport importlib\nfrom datetime import datetime\nfrom typing import Any, Dict, Callable\nfrom swarmauri.core.agents.IAgent import IAgent  # Replace with the correct IAgent path\nfrom swarmauri.core.agentfactories.IAgentFactory import IAgentFactory\nfrom swarmauri.core.agentfactories.IExportConf import IExportConf\n\n\nclass ConfDrivenAgentFactory(IAgentFactory, IExportConf):\n    def __init__(self, config_path: str):\n        self._config_path = config_path\n        self._config = self._load_config(config_path)\n        self._registry = {}\n        self._metadata = {\n            'id': None,\n            'name': 'ConfAgentFactory',\n            'type': 'Configurable',\n            'date_created': datetime.now(),\n            'last_modified': datetime.now()\n        }\n        \n        self._initialize_registry()\n\n    def _load_config(self, config_path: str) -> Dict[str, Any]:\n        with open(config_path, 'r') as file:\n            return json.load(file)\n    \n    def _initialize_registry(self) -> None:\n        for agent_type, agent_info in self._config.get(\"agents\", {}).items():\n            module_name, class_name = agent_info[\"class_path\"].rsplit('.', 1)\n            module = importlib.import_module(module_name)\n            cls = getattr(module, class_name)\n            self.register_agent(agent_type, cls)\n    \n    # Implementation of IAgentFactory methods\n    def create_agent(self, agent_type: str, **kwargs) -> IAgent:\n        if agent_type not in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is not registered.\")\n        \n        return self._registry[agent_type](**kwargs)\n\n    def register_agent(self, agent_type: str, constructor: Callable[..., IAgent]) -> None:\n        self._registry[agent_type] = constructor\n        self._metadata['last_modified'] = datetime.now()\n    \n    # Implementation of IExportConf methods\n    def to_dict(self) -> Dict[str, Any]:\n        return self._metadata.copy()\n\n    def to_json(self) -> str:\n        return json.dumps(self.to_dict(), default=str, indent=4)\n\n    def export_to_file(self, file_path: str) -> None:\n        with open(file_path, 'w') as f:\n            f.write(self.to_json())\n\n    # Additional methods to implement required properties and their setters\n    # Implementing getters and setters for metadata properties as needed\n    @property\n    def id(self) -> int:\n        return self._metadata['id']\n\n    @id.setter\n    def id(self, value: int) -> None:\n        self._metadata['id'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def name(self) -> str:\n        return self._metadata['name']\n\n    @name.setter\n    def name(self, value: str) -> None:\n        self._metadata['name'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def type(self) -> str:\n        return self._metadata['type']\n\n    @type.setter\n    def type(self, value: str) -> None:\n        self._metadata['type'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def date_created(self) -> datetime:\n        return self._metadata['date_created']\n\n    @property\n    def last_modified(self) -> datetime:\n        return self._metadata['last_modified']\n\n    @last_modified.setter\n    def last_modified(self, value: datetime) -> None:\n        self._metadata['last_modified'] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/ReflectiveAgentFactory.py",
        "content": "```swarmauri/standard/agent_factories/concrete/ReflectiveAgentFactory.py\nimport importlib\nfrom datetime import datetime\nimport json\nfrom typing import Callable, Dict, Type, Any\nfrom swarmauri.core.agents.IAgent import IAgent  # Update this import path as needed\nfrom swarmauri.core.agentfactories.IAgentFactory import IAgentFactory\nfrom swarmauri.core.agentfactories.IExportConf import IExportConf\n\nclass ReflectiveAgentFactory(IAgentFactory, IExportConf):\n    def __init__(self):\n        self._registry: Dict[str, Type[IAgent]] = {}\n        self._metadata = {\n            'id': None,\n            'name': 'ReflectiveAgentFactory',\n            'type': 'Reflective',\n            'date_created': datetime.now(),\n            'last_modified': datetime.now()\n        }\n\n    def create_agent(self, agent_type: str, **kwargs) -> IAgent:\n        if agent_type not in self._registry:\n            raise ValueError(f\"Agent type '{agent_type}' is not registered.\")\n        \n        agent_class = self._registry[agent_type]\n        return agent_class(**kwargs)\n\n    def register_agent(self, agent_type: str, class_path: str) -> None:\n        module_name, class_name = class_path.rsplit('.', 1)\n        module = importlib.import_module(module_name)\n        cls = getattr(module, class_name)\n        self._registry[agent_type] = cls\n        self._metadata['last_modified'] = datetime.now()\n\n    # Implementations for the IExportConf interface\n    def to_dict(self) -> Dict[str, Any]:\n        return self._metadata.copy()\n\n    def to_json(self) -> str:\n        return json.dumps(self.to_dict(), default=str, indent=4)\n\n    def export_to_file(self, file_path: str) -> None:\n        with open(file_path, 'w') as file:\n            file.write(self.to_json())\n\n    # Property implementations: id, name, type, date_created, and last_modified\n    @property\n    def id(self) -> int:\n        return self._metadata['id']\n\n    @id.setter\n    def id(self, value: int) -> None:\n        self._metadata['id'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def name(self) -> str:\n        return self._metadata['name']\n\n    @name.setter\n    def name(self, value: str) -> None:\n        self._metadata['name'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def type(self) -> str:\n        return self._metadata['type']\n\n    @type.setter\n    def type(self, value: str) -> None:\n        self._metadata['type'] = value\n        self._metadata['last_modified'] = datetime.now()\n\n    @property\n    def date_created(self) -> datetime:\n        return self._metadata['date_created']\n\n    @property\n    def last_modified(self) -> datetime:\n        return self._metadata['last_modified']\n\n    @last_modified.setter\n    def last_modified(self, value: datetime) -> None:\n        self._metadata['last_modified'] = value\n```"
    },
    {
        "document_name": "swarmauri/standard/agent_factories/concrete/__init__.py",
        "content": "```swarmauri/standard/agent_factories/concrete/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/exceptions/__init__.py",
        "content": "```swarmauri/standard/exceptions/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/exceptions/base/__init__.py",
        "content": "```swarmauri/standard/exceptions/base/__init__.py\n\n```"
    },
    {
        "document_name": "swarmauri/standard/exceptions/concrete/IndexErrorWithContext.py",
        "content": "```swarmauri/standard/exceptions/concrete/IndexErrorWithContext.py\nimport inspect\n\nclass IndexErrorWithContext(Exception):\n    def __init__(self, original_exception):\n        self.original_exception = original_exception\n        self.stack_info = inspect.stack()\n        self.handle_error()\n\n    def handle_error(self):\n        # You might want to log this information or handle it differently depending on your application's needs\n        frame = self.stack_info[1]  # Assuming the IndexError occurs one level up from where it's caught\n        error_details = {\n            \"message\": str(self.original_exception),\n            \"function\": frame.function,\n            \"file\": frame.filename,\n            \"line\": frame.lineno,\n            \"code_context\": ''.join(frame.code_context).strip() if frame.code_context else \"No context available\"\n        }\n        print(\"IndexError occurred with detailed context:\")\n        for key, value in error_details.items():\n            print(f\"{key.capitalize()}: {value}\")\n```"
    },
    {
        "document_name": "swarmauri/standard/exceptions/concrete/__init__.py",
        "content": "```swarmauri/standard/exceptions/concrete/__init__.py\nfrom .IndexErrorWithContext import IndexErrorWithContext\n```"
    }
]